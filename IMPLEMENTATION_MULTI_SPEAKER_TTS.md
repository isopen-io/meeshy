# Impl√©mentation Multi-Speaker TTS avec Pr√©servation des Silences

## Vue d'ensemble

Cette impl√©mentation ajoute le support complet de la synth√®se audio multi-locuteurs avec pr√©servation des voix individuelles et des silences naturels dans le pipeline de traduction audio.

## Architecture

### Modules cr√©√©s

#### 1. `audio_silence_manager.py`
G√®re la d√©tection, la pr√©servation et la g√©n√©ration de silences audio.

**Fonctionnalit√©s:**
- D√©tection des silences entre segments de transcription
- G√©n√©ration de fichiers audio de silence
- Concat√©nation d'audios avec pr√©servation des silences
- Option pour supprimer les silences (`preserve_silences=False`)

**Classes principales:**
- `SilenceSegment`: Repr√©sente un silence entre deux segments
- `AudioSegmentWithSilence`: Segment audio enrichi avec info de silence
- `AudioSilenceManager`: Gestionnaire principal

**Param√®tres configurables:**
- `preserve_silences`: Pr√©server (True) ou supprimer (False) les silences
- `min_silence_ms`: Dur√©e minimale d'un silence (d√©faut: 100ms)
- `max_silence_ms`: Dur√©e maximale d'un silence (d√©faut: 3000ms)
- `silence_threshold_db`: Seuil de d√©tection en dB (d√©faut: -40dB)

#### 2. `multi_speaker_synthesis.py`
G√®re la synth√®se TTS multi-locuteurs avec clonage vocal par speaker.

**Fonctionnalit√©s:**
- Cr√©ation de mappings `speaker_id ‚Üí voice_model`
- Groupement des segments par speaker
- Synth√®se TTS par segment avec la voix appropri√©e
- Concat√©nation des r√©sultats avec pr√©servation des silences

**Classes principales:**
- `SpeakerVoiceMap`: Mapping speaker ‚Üí mod√®le vocal
- `SegmentSynthesisResult`: R√©sultat de synth√®se d'un segment
- `MultiSpeakerSynthesizer`: Synth√©tiseur principal

**Pipeline de synth√®se:**
1. Analyser les segments pour identifier les speakers uniques
2. Cr√©er un voice model pour chaque speaker
3. Synth√©tiser chaque segment avec la bonne voix
4. Concat√©ner avec les silences appropri√©s

#### 3. Modifications dans `translation_stage.py`
Le `TranslationStage` a √©t√© modifi√© pour supporter le mode multi-speakers.

**Nouvelles fonctionnalit√©s:**
- D√©tection automatique du mode (mono-speaker vs multi-speaker)
- Traduction segment par segment pour multi-speakers
- Synth√®se avec pr√©servation des voix et silences
- Fallback vers synth√®se mono-speaker classique

## Utilisation

### Mode automatique

Le syst√®me d√©tecte automatiquement si l'audio est multi-speakers :

```python
# Le pipeline d√©tecte automatiquement le mode
translations = await translation_stage.process_languages(
    target_languages=['fr', 'es'],
    source_text="Hello how are you?",
    source_language='en',
    audio_hash='abc123',
    voice_model=user_voice_model,
    message_id='msg_001',
    attachment_id='att_001',
    source_audio_path='/path/to/audio.mp3',
    source_segments=segments,  # ‚Üê Segments avec speaker_id
    diarization_result=diarization  # ‚Üê R√©sultat de diarisation
)
```

**Crit√®res de d√©tection:**
- Mode **MULTI-SPEAKER** : Plus de 1 `speaker_id` unique dans les segments
- Mode **MONO-SPEAKER** : 0 ou 1 `speaker_id` unique

### Configuration des silences

```python
# Avec pr√©servation des silences (par d√©faut)
translation_stage = create_translation_stage(
    translation_service=translation_service,
    tts_service=tts_service,
    voice_clone_service=voice_clone_service,
    preserve_silences=True  # ‚Üê Pr√©server les silences naturels
)

# Sans pr√©servation des silences
translation_stage = create_translation_stage(
    translation_service=translation_service,
    tts_service=tts_service,
    voice_clone_service=voice_clone_service,
    preserve_silences=False  # ‚Üê Supprimer les silences
)
```

### Configuration avanc√©e

```python
# Configuration manuelle du silence manager
from services.audio_pipeline.audio_silence_manager import create_silence_manager

silence_manager = create_silence_manager(
    preserve_silences=True,
    min_silence_ms=100,      # Silences < 100ms ignor√©s
    max_silence_ms=3000,     # Silences > 3s capp√©s √† 3s
    silence_threshold_db=-40 # Seuil de d√©tection
)

# Configuration manuelle du multi-speaker synthesizer
from services.audio_pipeline.multi_speaker_synthesis import create_multi_speaker_synthesizer

multi_speaker_synth = create_multi_speaker_synthesizer(
    tts_service=tts_service,
    voice_clone_service=voice_clone_service,
    preserve_silences=True,
    temp_dir='/tmp/multi_speaker_tts'
)
```

## Workflow d√©taill√©

### 1. Mode MONO-SPEAKER (comportement existant)

```
1. Traduire le texte complet
2. Synth√©tiser avec une seule voix
3. Re-transcrire l'audio traduit
4. Retourner le r√©sultat
```

### 2. Mode MULTI-SPEAKER (nouveau)

```
1. D√©tecter les speakers uniques dans les segments
2. Traduire chaque segment individuellement
   ‚îî‚îÄ Cache utilis√© pour √©viter les traductions dupliqu√©es
3. Cr√©er les voice models par speaker
   ‚îú‚îÄ Utiliser le mod√®le utilisateur existant si identifi√©
   ‚îî‚îÄ Cr√©er des mod√®les temporaires pour les autres speakers
4. D√©tecter les silences entre segments
   ‚îú‚îÄ Calculer les dur√©es
   ‚îú‚îÄ Capper √† max_silence_ms
   ‚îî‚îÄ Filtrer selon min_silence_ms
5. Synth√©tiser chaque segment avec sa voix
   ‚îú‚îÄ TTS avec le voice model appropri√©
   ‚îî‚îÄ Gestion des erreurs par segment
6. Concat√©ner les audios
   ‚îú‚îÄ Ins√©rer les silences appropri√©s
   ‚îî‚îÄ Maintenir l'ordre chronologique
7. Re-transcrire l'audio final (optionnel)
8. Retourner le r√©sultat
```

## Format des segments

Les segments doivent avoir cette structure :

```python
{
    "text": "Hello",
    "start_ms": 0,          # ou "startMs"
    "end_ms": 500,          # ou "endMs"
    "speaker_id": "s0",     # ou "speakerId"
    "confidence": 0.95,
    "voice_similarity_score": 0.85  # ou "voiceSimilarityScore"
}
```

## Logs et monitoring

Le syst√®me g√©n√®re des logs d√©taill√©s :

```
[TRANSLATION_STAGE] Mode d√©tect√©: MULTI-SPEAKER (3 speaker(s) unique(s))
[TRANSLATION_STAGE] üé≠ Utilisation synth√®se MULTI-SPEAKER: 15 segments, 3 speakers
[TRANSLATION_STAGE] Traduction de 15 segments: en ‚Üí fr
[MULTI_SPEAKER_SYNTH] üé§ Cr√©ation des voice models par speaker...
[MULTI_SPEAKER_SYNTH] Speakers d√©tect√©s: 3 ‚Üí ['s0', 's1', 's2']
[MULTI_SPEAKER_SYNTH]   ‚Ä¢ s0: utilisation du mod√®le utilisateur existant
[MULTI_SPEAKER_SYNTH]   ‚Ä¢ s1: cr√©ation mod√®le temporaire (5 segments, 3500ms)
[MULTI_SPEAKER_SYNTH]   ‚Ä¢ s2: cr√©ation mod√®le temporaire (3 segments, 2100ms)
[SILENCE_MANAGER] Silences d√©tect√©s: 14 (dur√©e totale: 2800ms)
[MULTI_SPEAKER_SYNTH] üîó Concat√©nation: 15 audios, 14 silences
[MULTI_SPEAKER_SYNTH] ‚úÖ Synth√®se multi-speaker termin√©e: output.mp3 (dur√©e: 12500ms)
```

## Int√©gration dans le pipeline existant

### Modification n√©cessaire dans `audio_message_pipeline.py`

Le pipeline doit maintenant passer les segments et le r√©sultat de diarisation :

```python
# Avant
translations = await translation_stage.process_languages(
    target_languages=target_languages,
    source_text=transcription_result.text,
    source_language=source_lang,
    audio_hash=audio_hash,
    voice_model=voice_model,
    message_id=message_id,
    attachment_id=attachment_id,
    source_audio_path=audio_path
)

# Apr√®s
translations = await translation_stage.process_languages(
    target_languages=target_languages,
    source_text=transcription_result.text,
    source_language=source_lang,
    audio_hash=audio_hash,
    voice_model=voice_model,
    message_id=message_id,
    attachment_id=attachment_id,
    source_audio_path=audio_path,
    source_segments=transcription_result.segments,  # ‚Üê Ajouter
    diarization_result=diarization_result           # ‚Üê Ajouter
)
```

## D√©pendances

Le syst√®me n√©cessite `pydub` pour la manipulation audio :

```bash
pip install pydub
```

Si `pydub` n'est pas disponible, le syst√®me fonctionne en mode d√©grad√© :
- ‚ö†Ô∏è Concat√©nation d√©sactiv√©e
- ‚ö†Ô∏è G√©n√©ration de silences d√©sactiv√©e
- ‚úÖ D√©tection de silences reste fonctionnelle

## Tests et validation

### Test basique mono-speaker

```python
# Devrait utiliser le mode MONO-SPEAKER classique
segments = [
    {"text": "Hello", "start_ms": 0, "end_ms": 500, "speaker_id": "s0"}
]
```

### Test multi-speakers

```python
# Devrait utiliser le mode MULTI-SPEAKER
segments = [
    {"text": "Hello", "start_ms": 0, "end_ms": 500, "speaker_id": "s0"},
    {"text": "Hi", "start_ms": 600, "end_ms": 900, "speaker_id": "s1"},
    {"text": "How are you?", "start_ms": 1000, "end_ms": 1500, "speaker_id": "s0"}
]
```

### Test sans silences

```python
# Les silences seront supprim√©s
translation_stage = create_translation_stage(
    preserve_silences=False
)
```

## Optimisations futures

1. **Extraction audio par speaker**
   - Actuellement, on utilise l'audio complet pour cr√©er les voice models temporaires
   - TODO: Extraire uniquement les segments de chaque speaker pour un meilleur clonage

2. **Cache des voice models temporaires**
   - Les voice models temporaires sont recr√©√©s √† chaque fois
   - TODO: Cacher les embeddings par speaker pour r√©utilisation

3. **Parall√©lisation de la synth√®se par segment**
   - Actuellement s√©quentiel
   - TODO: Synth√©tiser les segments en parall√®le avec ThreadPoolExecutor

4. **Ajustement automatique des silences**
   - Les silences sont pr√©serv√©s tels quels
   - TODO: Ajuster selon le ratio de vitesse de parole (TTS vs original)

## Compatibilit√©

‚úÖ **Compatible** avec le syst√®me existant :
- D√©tection automatique du mode
- Fallback vers mono-speaker si pas de speaker_id
- Tous les param√®tres existants pr√©serv√©s

‚úÖ **R√©trocompatible** :
- Si `source_segments` non fourni ‚Üí mode mono-speaker
- Si `preserve_silences` non sp√©cifi√© ‚Üí True par d√©faut

## R√©sum√© des fichiers modifi√©s/cr√©√©s

### Nouveaux fichiers
- `services/translator/src/services/audio_pipeline/audio_silence_manager.py`
- `services/translator/src/services/audio_pipeline/multi_speaker_synthesis.py`

### Fichiers modifi√©s
- `services/translator/src/services/audio_pipeline/translation_stage.py`
- `services/translator/src/utils/smart_segment_merger.py` (correction du bug de fusion)

### Fichiers √† modifier (pour int√©gration compl√®te)
- `services/translator/src/services/audio_pipeline/audio_message_pipeline.py` (passer segments + diarization)

## Support et maintenance

En cas de probl√®me :
1. V√©rifier les logs `[TRANSLATION_STAGE]`, `[MULTI_SPEAKER_SYNTH]`, `[SILENCE_MANAGER]`
2. V√©rifier que les segments ont des `speaker_id` valides
3. V√©rifier que `pydub` est install√©
4. Tester avec `preserve_silences=False` pour isoler les probl√®mes de silences

---

**Date d'impl√©mentation**: 2026-01-20
**Version**: 1.0.0
