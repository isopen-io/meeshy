# Optimisation - R√©utilisation des Transcriptions Existantes

**Date:** 2026-01-19
**Priorit√©:** ‚ö° HAUTE (Performance & Co√ªts)
**Impact:** Chaque traduction audio refait la transcription (15-30s gaspill√©es)

---

## üîç Probl√®me Identifi√©

### Comportement Actuel

Lors de la traduction d'un audio :
1. ‚úÖ Transcription Whisper (15-30s)
2. ‚úÖ Traduction ML (1-2s)
3. ‚úÖ Synth√®se TTS (5-15s)

**Total : ~25-45 secondes**

Si l'audio est retraduit vers une autre langue :
1. ‚ùå **REFAIT la transcription** (15-30s gaspill√©es)
2. ‚úÖ Traduction ML (1-2s)
3. ‚úÖ Synth√®se TTS (5-15s)

**Total : ~25-45 secondes (alors que √ßa devrait √™tre ~7-17s)**

### Logs Observ√©s

```
2026-01-19 10:05:02 - [TRANSCRIPTION] üé§ Transcription Whisper de: /var/folders/.../tmp....wav
2026-01-19 10:05:17 - [TRANSCRIPTION] ‚úÖ Transcrit: 'Bonjour √† tous...' (18011ms)
```

La transcription prend **18 secondes** alors qu'elle existe d√©j√† dans la base de donn√©es !

---

## üìä Impact Business

### Performance
- ‚ùå **Latence inutile** : +15-30s par retraduction
- ‚ùå **Charge CPU** : Whisper consomme beaucoup de ressources
- ‚ùå **Mauvaise UX** : L'utilisateur attend 2x plus longtemps

### Co√ªts
- ‚ùå **GPU/CPU gaspill√©s** : Whisper est gourmand
- ‚ùå **Scalabilit√© r√©duite** : Moins de traductions/seconde possibles

### Cas d'Usage Impact√©s

1. **Traductions multiples** : Un audio en fran√ßais traduit vers EN, ES, DE
   - Actuellement : 3 transcriptions identiques (45-90s perdues)
   - Devrait √™tre : 1 transcription r√©utilis√©e 3 fois

2. **Messages transf√©r√©s** : Audio transf√©r√© √† plusieurs personnes
   - Actuellement : Transcription refaite pour chaque destinataire
   - Devrait √™tre : Transcription copi√©e de l'original

3. **Retraduction** : L'utilisateur change de langue cible
   - Actuellement : Retranscription compl√®te
   - Devrait √™tre : R√©utilisation imm√©diate

---

## ‚úÖ Solution

### Infrastructure Disponible

L'infrastructure pour envoyer la transcription existante est **D√âJ√Ä EN PLACE** :

#### 1. Type ZMQ (`services/gateway/src/services/zmq-translation/types.ts:97-104`)
```typescript
export interface AudioProcessRequest {
  // ... autres champs ...
  mobileTranscription?: {
    text: string;
    language: string;
    confidence: number;
    source: string;
    segments?: Array<{ text: string; startMs: number; endMs: number }>;
  };
  // ... autres champs ...
}
```

#### 2. Transmission ZMQ (`ZmqRequestSender.ts:141`)
```typescript
mobileTranscription: request.mobileTranscription,  // ‚úÖ D√©j√† transmis
```

#### 3. Base de Donn√©es Prisma
```prisma
model MessageAudioTranscription {
  id                String   @id @default(uuid())
  attachmentId      String   @unique
  messageId         String
  transcribedText   String
  language          String
  confidence        Float
  source            String   // "whisper" ou "mobile"
  segments          Json?
  audioDurationMs   Int?
  // ... autres champs ...
}
```

### Modification N√©cessaire

**Fichier** : `services/gateway/src/services/AttachmentTranslateService.ts`

#### Avant (ligne ~350)
```typescript
private async translateAudio(userId: string, attachment: any, options: TranslateOptions) {
  // ... v√©rification cache traductions ...

  // Lit le fichier audio
  const audioBuffer = await this.readAttachmentFile(attachment.filePath);
  const audioBase64 = audioBuffer.toString('base64');

  // ‚ùå N'envoie PAS la transcription existante
  const syncResult = await this.audioTranslateService.translateSync(userId, {
    audioBase64,
    targetLanguages: languagesToTranslate,
    sourceLanguage: options.sourceLanguage,
    generateVoiceClone: options.generateVoiceClone,
    originalSenderId: originalSenderId || undefined,
    existingVoiceProfile: voiceProfile || undefined,
    useOriginalVoice
  });
}
```

#### Apr√®s (√† impl√©menter)
```typescript
private async translateAudio(userId: string, attachment: any, options: TranslateOptions) {
  // ... v√©rification cache traductions ...

  // ‚úÖ NOUVEAU: R√©cup√©rer la transcription existante si disponible
  const existingTranscription = await this.prisma.messageAudioTranscription.findUnique({
    where: { attachmentId: originalAttachmentId },
    select: {
      transcribedText: true,
      language: true,
      confidence: true,
      source: true,
      segments: true,
      audioDurationMs: true
    }
  });

  // Log pour visibilit√©
  if (existingTranscription) {
    console.log(`   üìù Transcription existante trouv√©e: "${existingTranscription.transcribedText.substring(0, 50)}..."`);
    console.log(`   ‚ö° √âconomie: ~15-30s de transcription Whisper`);
  } else {
    console.log(`   üé§ Pas de transcription existante, Whisper sera utilis√©`);
  }

  // Lit le fichier audio
  const audioBuffer = await this.readAttachmentFile(attachment.filePath);
  const audioBase64 = audioBuffer.toString('base64');

  // ‚úÖ Envoyer la transcription existante au translator
  const syncResult = await this.audioTranslateService.translateSync(userId, {
    audioBase64,
    targetLanguages: languagesToTranslate,
    sourceLanguage: options.sourceLanguage,
    generateVoiceClone: options.generateVoiceClone,
    originalSenderId: originalSenderId || undefined,
    existingVoiceProfile: voiceProfile || undefined,
    useOriginalVoice,
    // ‚úÖ NOUVEAU: Passer la transcription existante
    existingTranscription: existingTranscription ? {
      text: existingTranscription.transcribedText,
      language: existingTranscription.language,
      confidence: existingTranscription.confidence,
      source: existingTranscription.source,
      segments: existingTranscription.segments as any
    } : undefined
  });
}
```

### Modification dans AudioTranslateService

**Fichier** : `services/gateway/src/services/AudioTranslateService.ts:367-390`

#### Interface AudioTranslationOptions
```typescript
export interface AudioTranslationOptions {
  audioBase64?: string;
  audioPath?: string;
  attachmentId?: string;
  targetLanguages: string[];
  sourceLanguage?: string;
  generateVoiceClone?: boolean;
  saveToDatabase?: boolean;
  originalSenderId?: string;
  existingVoiceProfile?: VoiceProfileData;
  useOriginalVoice?: boolean;
  // ‚úÖ NOUVEAU
  existingTranscription?: {
    text: string;
    language: string;
    confidence: number;
    source: string;
    segments?: Array<{ text: string; startMs: number; endMs: number }>;
  };
}
```

#### M√©thode translateSync
```typescript
async translateSync(userId: string, options: AudioTranslationOptions): Promise<VoiceTranslationResult> {
  const request: VoiceTranslateRequest = {
    type: 'voice_translate',
    taskId: randomUUID(),
    userId,
    audioBase64: options.audioBase64,
    audioPath: options.audioPath,
    targetLanguages: options.targetLanguages,
    sourceLanguage: options.sourceLanguage,
    generateVoiceClone: options.generateVoiceClone ?? true,
    // ‚úÖ NOUVEAU: Passer la transcription existante
    mobileTranscription: options.existingTranscription
  };

  // ... reste du code ...
}
```

### Modification dans ZmqTranslationClient

**Fichier** : `services/gateway/src/services/zmq-translation/ZmqTranslationClient.ts`

La m√©thode `sendVoiceAPIRequest` doit √™tre adapt√©e pour transmettre `mobileTranscription` :

```typescript
async sendVoiceAPIRequest(request: VoiceAPIRequest): Promise<void> {
  // ... code existant ...

  // Construire le message audio process
  const audioProcessRequest: AudioProcessRequest = {
    type: 'audio_process',
    messageId: request.messageId || randomUUID(),
    attachmentId: request.attachmentId || randomUUID(),
    // ... autres champs ...
    // ‚úÖ Transmettre la transcription si fournie
    mobileTranscription: (request as any).mobileTranscription,
    targetLanguages: request.targetLanguages,
    generateVoiceClone: request.generateVoiceClone
  };

  // Envoyer via ZMQ
  await this.requestSender.sendAudioProcessRequest(audioProcessRequest);
}
```

---

## üß™ Validation

### Test 1 : Premi√®re traduction (pas de transcription existante)
```bash
# Envoyer un audio en fran√ßais vers EN
POST /attachments/{id}/translate
{ "targetLanguages": ["en"] }

# Logs attendus :
[GATEWAY] üé§ Pas de transcription existante, Whisper sera utilis√©
[TRANSLATOR] üé§ Transcription Whisper de: /tmp/...
[TRANSLATOR] ‚úÖ Transcrit: "Bonjour..." (18000ms)
```

### Test 2 : Retraduction (transcription existante)
```bash
# Retraduire le m√™me audio vers ES (transcription existe d√©j√†)
POST /attachments/{id}/translate
{ "targetLanguages": ["es"] }

# Logs attendus :
[GATEWAY] üìù Transcription existante trouv√©e: "Bonjour √† tous, ceci est..."
[GATEWAY] ‚ö° √âconomie: ~15-30s de transcription Whisper
[TRANSLATOR] ‚è© Transcription fournie par gateway, skip Whisper
[TRANSLATOR] ‚úÖ Traduction: "Hola a todos..." (2000ms)
# ‚úÖ Temps total: ~7s au lieu de ~25s
```

### Test 3 : Traductions multiples simultan√©es
```bash
# Traduire vers 3 langues d'un coup
POST /attachments/{id}/translate
{ "targetLanguages": ["en", "es", "de"] }

# Comportement :
# - Transcription faite 1 seule fois (18s)
# - 3 traductions + 3 TTS en parall√®le (~15s)
# Total: ~33s au lieu de ~75s (3x 25s)
```

---

## üìà Gains Attendus

### Latence
- **Premi√®re traduction** : 25-45s (inchang√©)
- **Retraduction** : 7-17s (au lieu de 25-45s) ‚Üí **-60% √† -70%**
- **3 langues simultan√©es** : 33s (au lieu de 75s) ‚Üí **-56%**

### Ressources
- **CPU Whisper √©conomis√©** : ~80% sur les retraductions
- **Throughput** : +2-3x traductions/seconde possibles
- **Co√ªts** : R√©duction proportionnelle des co√ªts de transcription

### UX
- ‚ö° R√©ponse quasi-instantan√©e pour les retraductions
- ‚úÖ Meilleure scalabilit√© du service
- üéØ Pr√©visibilit√© des temps de r√©ponse

---

## üöÄ Impl√©mentation

### √âtapes

1. ‚úÖ **Audit de l'infrastructure existante** (FAIT)
2. ‚è≥ **Modifier AttachmentTranslateService** :
   - R√©cup√©rer `MessageAudioTranscription` avant traduction
   - Passer au param√®tre `existingTranscription`
3. ‚è≥ **Modifier AudioTranslateService** :
   - Ajouter `existingTranscription` √† `AudioTranslationOptions`
   - Transmettre √† `VoiceTranslateRequest` comme `mobileTranscription`
4. ‚è≥ **Modifier ZmqTranslationClient** :
   - S'assurer que `mobileTranscription` est bien transmis
5. ‚è≥ **V√©rifier le service Translator Python** :
   - Confirmer qu'il utilise bien `mobileTranscription` s'il est fourni
   - Skip Whisper si transcription fournie

### Tests
- Test unitaire : V√©rifier que la transcription est r√©cup√©r√©e
- Test d'int√©gration : V√©rifier que le translator la re√ßoit
- Test E2E : Mesurer les gains de temps r√©els

---

## üîó Fichiers Concern√©s

### Gateway (TypeScript)
1. `services/gateway/src/services/AttachmentTranslateService.ts:258-433`
   - M√©thode `translateAudio()` - Ajouter r√©cup√©ration transcription
2. `services/gateway/src/services/AudioTranslateService.ts:367-390`
   - Interface `AudioTranslationOptions` - Ajouter `existingTranscription`
   - M√©thode `translateSync()` - Transmettre `mobileTranscription`
3. `services/gateway/src/services/zmq-translation/ZmqTranslationClient.ts`
   - M√©thode `sendVoiceAPIRequest()` - S'assurer transmission correcte

### Translator (Python)
4. `services/translator/src/services/zmq_audio_handler.py`
   - V√©rifier utilisation de `mobileTranscription` si pr√©sent
   - Skip Whisper si fourni

---

## üìù Notes

### Comportement Attendu Translator

Le service translator devrait d√©j√† g√©rer `mobileTranscription` :

```python
# Si mobileTranscription est fourni
if request.get('mobileTranscription'):
    transcription = request['mobileTranscription']['text']
    language = request['mobileTranscription']['language']
    logger.info(f"[TRANSLATOR] ‚è© Transcription fournie, skip Whisper")
else:
    # Faire la transcription Whisper
    transcription = await whisper_transcribe(audio_path)
    logger.info(f"[TRANSLATOR] üé§ Transcription Whisper: {transcription[:50]}...")
```

### Compatibilit√©

- ‚úÖ **Backward compatible** : Le champ `mobileTranscription` est optionnel
- ‚úÖ **Pas de migration DB** : Utilise les donn√©es existantes
- ‚úÖ **Pas de breaking change** : Fonctionne avec/sans transcription fournie

---

**Cr√©√© par:** Claude Sonnet 4.5
**Date:** 2026-01-19
**Priorit√©:** ‚ö° HAUTE
