# Migration: isCurrentUser â†’ voiceSimilarityScore

**Date** : 19 janvier 2026
**Objectif** : Remplacer le boolean `isCurrentUser` par un score de similaritÃ© vocale (0-1)

---

## ğŸ¯ Motivation

### ProblÃ¨me Avant
- âŒ Boolean `isCurrentUser` : trop binaire (oui/non)
- âŒ MÃªme avec un seul locuteur, impossible de savoir si c'est vraiment l'utilisateur
- âŒ Pas de mesure de confiance dans l'identification
- âŒ Fallback basique : "locuteur principal = utilisateur" (approximatif)

### Solution AprÃ¨s
- âœ… Score de similaritÃ© vocale : mesure continue (0-1)
- âœ… Fonctionne mÃªme avec un seul locuteur (compare avec profil vocal)
- âœ… Permet d'afficher la confiance au frontend
- âœ… Reconnaissance vocale par embeddings (prÃ©cise)

---

## ğŸ“Š Comparaison Avant/AprÃ¨s

### Avant (Boolean)

```typescript
interface TranscriptionSegment {
  speakerId?: string;
  isCurrentUser?: boolean;  // âŒ Binaire : true/false
  ...
}
```

**Affichage frontend** :
```typescript
if (segment.isCurrentUser) {
  color = 'blue';  // C'est l'utilisateur
} else {
  color = 'gray';  // Pas l'utilisateur
}
```

**ProblÃ¨me** : Pas de nuance, pas de confiance.

---

### AprÃ¨s (Score de SimilaritÃ©)

```typescript
interface TranscriptionSegment {
  speakerId?: string;
  /**
   * Score de similaritÃ© vocale avec le profil de l'utilisateur (0-1)
   * InterprÃ©tation:
   * - 0.0 - 0.3: Probablement pas l'utilisateur
   * - 0.3 - 0.6: Incertain
   * - 0.6 - 0.8: Probablement l'utilisateur
   * - 0.8 - 1.0: TrÃ¨s probablement l'utilisateur
   */
  voiceSimilarityScore?: number | null;  // âœ… Score continu
  ...
}
```

**Affichage frontend amÃ©liorÃ©** :
```typescript
function getSegmentDisplay(segment: TranscriptionSegment) {
  const score = segment.voiceSimilarityScore;

  if (score === null || score === undefined) {
    // Pas de profil vocal disponible
    return { color: 'gray', label: segment.speakerId };
  }

  if (score >= 0.8) {
    // TrÃ¨s probablement l'utilisateur
    return { color: 'blue-600', label: 'Vous', confidence: 'Haute' };
  } else if (score >= 0.6) {
    // Probablement l'utilisateur
    return { color: 'blue-400', label: 'Vous (?)', confidence: 'Moyenne' };
  } else if (score >= 0.3) {
    // Incertain
    return { color: 'yellow-500', label: 'Incertain', confidence: 'Faible' };
  } else {
    // Probablement pas l'utilisateur
    return { color: 'gray-600', label: segment.speakerId, confidence: 'Faible' };
  }
}
```

**Avantage** : Affichage nuancÃ© avec niveaux de confiance !

---

## ğŸ”§ Modifications EffectuÃ©es

### 1. Types TypeScript

#### `packages/shared/types/attachment-transcription.ts`

**Avant** :
```typescript
export interface TranscriptionSegment {
  readonly speakerId?: string;
  readonly isCurrentUser?: boolean;
  ...
}
```

**AprÃ¨s** :
```typescript
export interface TranscriptionSegment {
  readonly speakerId?: string;
  /**
   * Score de similaritÃ© vocale avec le profil de l'utilisateur (0-1)
   * null si reconnaissance vocale non disponible
   */
  readonly voiceSimilarityScore?: number | null;
  ...
}
```

---

### 2. Services Python

#### A. `services/translator/src/services/transcription_service.py`

**TranscriptionSegment dataclass** :
```python
@dataclass
class TranscriptionSegment:
    text: str
    start_ms: int
    end_ms: int
    confidence: float = 0.0
    speaker_id: Optional[str] = None
    voice_similarity_score: Optional[float] = None  # âœ… NOUVEAU: Score 0-1
```

---

#### B. `services/translator/src/services/diarization_service.py`

**Nouvelle mÃ©thode `identify_sender()`** :
```python
async def identify_sender(
    self,
    audio_path: str,  # âœ… NOUVEAU: besoin du fichier audio
    diarization: DiarizationResult,
    sender_voice_profile: Optional[Dict[str, Any]] = None
) -> tuple[DiarizationResult, Dict[str, float]]:  # âœ… NOUVEAU: retourne aussi les scores
    """
    Identifie l'expÃ©diteur et calcule les scores de similaritÃ© pour tous les locuteurs.

    Returns:
        Tuple (DiarizationResult, Dict[speaker_id -> score])
    """
    from .voice_recognition_service import get_voice_recognition_service

    if not sender_voice_profile or 'embedding' not in sender_voice_profile:
        # Fallback: pas de profil vocal disponible
        scores = {speaker.speaker_id: 0.0 for speaker in diarization.speakers}
        return diarization, scores

    # Utiliser le service de reconnaissance vocale
    voice_service = get_voice_recognition_service()

    identified_speaker, similarity_scores = voice_service.identify_user_speaker(
        audio_path=audio_path,
        speaker_segments=speaker_segments,
        user_voice_profile=sender_voice_profile,
        threshold=0.6  # Seuil de confiance
    )

    # Mettre Ã  jour diarization avec le speaker identifiÃ©
    diarization.sender_identified = (identified_speaker is not None)
    diarization.sender_speaker_id = identified_speaker or diarization.primary_speaker_id

    return diarization, similarity_scores
```

---

#### C. **NOUVEAU** : `services/translator/src/services/voice_recognition_service.py`

Service complet de reconnaissance vocale par embeddings :

**FonctionnalitÃ©s** :
- âœ… Extraction d'embeddings vocaux avec pyannote.audio
- âœ… Fallback sur caractÃ©ristiques spectrales (MFCC) avec librosa
- âœ… Calcul de similaritÃ© cosinus entre embeddings
- âœ… Identification de l'utilisateur parmi plusieurs locuteurs

**MÃ©thodes clÃ©s** :
```python
class VoiceRecognitionService:
    def extract_speaker_embedding(audio_path, start_time, end_time) -> np.ndarray
    def compute_similarity(embedding1, embedding2) -> float  # 0-1
    def identify_user_speaker(audio_path, speaker_segments, user_voice_profile) -> (speaker_id, scores)
```

---

### 3. Application dans `_apply_diarization()`

**services/translator/src/services/transcription_service.py** :

```python
async def _apply_diarization(...):
    # 1. DÃ©tecter les locuteurs
    diarization = await diarization_service.detect_speakers(audio_path)

    # 2. âœ… NOUVEAU: Identifier l'expÃ©diteur + calculer scores
    diarization, similarity_scores = await diarization_service.identify_sender(
        audio_path,
        diarization,
        sender_voice_profile
    )

    # 3. âœ… NOUVEAU: Enrichir segments avec scores de similaritÃ©
    for segment in transcription.segments:
        segment.speaker_id = ...
        segment.voice_similarity_score = similarity_scores.get(
            segment.speaker_id,
            None  # None si pas de profil vocal
        )

    # 4. âœ… NOUVEAU: Ajouter scores dans speakerAnalysis
    transcription.speaker_analysis = {
        "speakers": [
            {
                "speaker_id": speaker.speaker_id,
                "voice_similarity_score": similarity_scores.get(speaker.speaker_id, 0.0),
                ...
            }
        ]
    }
```

---

## ğŸ“¦ Fichiers CrÃ©Ã©s/ModifiÃ©s

### Fichiers CrÃ©Ã©s
1. âœ… `services/translator/Dockerfile` - Dockerfile principal avec diarisation
2. âœ… `services/translator/src/services/voice_recognition_service.py` - Service de reconnaissance vocale
3. âœ… `services/translator/migrate_to_voice_similarity.sh` - Script de migration automatique
4. âœ… `services/translator/NOUVEAU_identify_sender.py` - Code de rÃ©fÃ©rence pour l'intÃ©gration
5. âœ… **CE FICHIER** `MIGRATION_VOICE_SIMILARITY_SCORE.md` - Documentation migration

### Fichiers ModifiÃ©s
1. âœ… `Makefile` - Installation des dÃ©pendances de diarisation
2. âœ… `packages/shared/types/attachment-transcription.ts` - Type `voiceSimilarityScore`
3. âœ… `services/translator/src/services/transcription_service.py` - dataclass mis Ã  jour
4. âœ… `services/translator/src/services/diarization_service.py` - MÃ©thode `identify_sender()`
5. âœ… `services/translator/src/utils/smart_segment_merger.py` - Fusion avec score
6. âœ… `services/translator/.env` - Variables d'environnement diarisation
7. âœ… `services/translator/.env.example` - Documentation variables
8. âœ… `services/translator/Dockerfile.openvoice` - Support diarisation
9. âœ… `services/translator/requirements-optional.txt` - DÃ©pendances pyannote.audio

---

## ğŸš€ Installation et Activation

### 1. Installer les DÃ©pendances

```bash
# Via Makefile (recommandÃ©)
make install

# Ou manuellement
cd services/translator
./install-diarization.sh
```

### 2. Configurer les Variables d'Environnement

```bash
# Dans services/translator/.env
ENABLE_DIARIZATION=true

# Optionnel mais recommandÃ© pour meilleure prÃ©cision
HF_TOKEN=your_huggingface_token
```

### 3. RedÃ©marrer le Service

```bash
make restart
```

---

## ğŸ“Š Flux de Reconnaissance Vocale

```
Audio File
    â†“
[Whisper Transcription]
    â†“
Segments avec timestamps natifs
    â†“
[Diarization Service]
    â†“
    â”œâ”€ detect_speakers() â†’ Identifie tous les locuteurs
    â”‚   â”œâ”€ pyannote.audio (mÃ©thode principale)
    â”‚   â”œâ”€ Pitch clustering (fallback)
    â”‚   â””â”€ Single speaker (ultime fallback)
    â†“
    â””â”€ identify_sender() â†’ âœ… NOUVEAU
        â†“
        [Voice Recognition Service]
        â†“
        Pour chaque locuteur:
          1. Extraire embedding vocal du segment le plus long
             â”œâ”€ pyannote.audio (prÃ©cis)
             â””â”€ MFCC + spectral features (fallback)
          2. Comparer avec profil vocal utilisateur (similaritÃ© cosinus)
          3. Retourner score de similaritÃ© (0-1)
        â†“
        Identifier le locuteur avec le score le plus Ã©levÃ© (seuil: 0.6)
        Retourner: (speaker_id, Dict[speaker_id -> score])
    â†“
[Enrichissement des Segments]
    â†“
    Pour chaque segment:
      - speaker_id: ID du locuteur
      - voice_similarity_score: Score de similaritÃ© avec l'utilisateur
    â†“
[Frontend]
    â†“
Affichage avec couleurs et niveaux de confiance basÃ©s sur le score
```

---

## ğŸ¨ Exemple d'Utilisation Frontend

### Composant React AmÃ©liorÃ©

```typescript
interface VoiceSegmentProps {
  segment: TranscriptionSegment;
}

function VoiceSegment({ segment }: VoiceSegmentProps) {
  const score = segment.voiceSimilarityScore;

  // DÃ©terminer le style basÃ© sur le score
  const getStyle = () => {
    if (score === null || score === undefined) {
      return {
        color: 'text-gray-600',
        label: segment.speakerId || 'Inconnu',
        confidence: null
      };
    }

    if (score >= 0.8) {
      return {
        color: 'text-blue-600',
        label: 'Vous',
        confidence: 'Haute',
        badge: 'ğŸ”µ'
      };
    } else if (score >= 0.6) {
      return {
        color: 'text-blue-400',
        label: 'Probablement vous',
        confidence: 'Moyenne',
        badge: 'ğŸ”·'
      };
    } else if (score >= 0.3) {
      return {
        color: 'text-yellow-500',
        label: 'Incertain',
        confidence: 'Faible',
        badge: 'âš ï¸'
      };
    } else {
      return {
        color: 'text-gray-600',
        label: segment.speakerId || 'Autre',
        confidence: 'TrÃ¨s faible',
        badge: 'âš«'
      };
    }
  };

  const style = getStyle();

  return (
    <div className="flex items-start gap-2">
      <span className="text-xs text-gray-400">
        {(segment.startMs / 1000).toFixed(1)}s
      </span>

      <span className={`font-medium ${style.color} flex items-center gap-1`}>
        {style.badge && <span>{style.badge}</span>}
        <span>[{style.label}]</span>
        {score !== null && style.confidence && (
          <span className="text-xs opacity-75">
            ({(score * 100).toFixed(0)}%)
          </span>
        )}
      </span>

      <span className="flex-1">{segment.text}</span>
    </div>
  );
}
```

### Affichage RÃ©sultant

```
0.0s ğŸ”µ [Vous] (92%) Bonjour comment vas-tu ?
1.5s âš« [speaker_1] (12%) Salut Ã§a va bien merci
3.2s ğŸ”· [Probablement vous] (68%) Et toi comment Ã§a va ?
5.0s âš« [speaker_1] (8%) TrÃ¨s bien aussi
```

**Avantages** :
- âœ… Nuances visuelles selon la confiance
- âœ… Pourcentage de similaritÃ© affichÃ©
- âœ… Badges pour reconnaissance rapide
- âœ… Gestion Ã©lÃ©gante des cas incertains

---

## ğŸ” InterprÃ©tation des Scores

| Score | InterprÃ©tation | Couleur SuggÃ©rÃ©e | Action Frontend |
|-------|----------------|------------------|-----------------|
| **0.8 - 1.0** | TrÃ¨s probablement l'utilisateur | Bleu foncÃ© | Afficher "Vous" avec haute confiance |
| **0.6 - 0.8** | Probablement l'utilisateur | Bleu clair | Afficher "Vous (?)" avec confiance moyenne |
| **0.3 - 0.6** | Incertain | Jaune/Orange | Afficher "Incertain" ou speaker_id |
| **0.0 - 0.3** | Probablement pas l'utilisateur | Gris | Afficher speaker_id |
| **null** | Pas de profil vocal disponible | Gris | Afficher speaker_id (fallback) |

---

## âš™ï¸ Configuration de la Reconnaissance Vocale

### Seuils Configurables

Dans `voice_recognition_service.py`, ajuster le seuil de confiance :

```python
# Seuil par dÃ©faut: 0.6
identified_speaker, scores = voice_service.identify_user_speaker(
    audio_path=audio_path,
    speaker_segments=speaker_segments,
    user_voice_profile=sender_voice_profile,
    threshold=0.6  # â† Ajuster ici
)
```

### Recommandations

| Contexte | Seuil | Justification |
|----------|-------|---------------|
| **Strict** | 0.8 | Applications sensibles (banking, medical) |
| **Standard** | 0.6 | Usage gÃ©nÃ©ral (recommandÃ©) |
| **Permissif** | 0.4 | Contextes bruyants, audios courts |

---

## ğŸ“ Format du Profil Vocal Utilisateur

Le profil vocal doit Ãªtre stockÃ© dans `UserVoiceModel` (MongoDB) :

```typescript
interface UserVoiceProfile {
  user_id: string;
  embedding: number[];  // Vecteur d'embeddings (128-512 dimensions selon le modÃ¨le)
  characteristics?: {
    pitch_mean?: number;
    pitch_std?: number;
    spectral_centroid?: number;
    // Autres caractÃ©ristiques vocales
  };
  created_at: Date;
  updated_at: Date;
  samples_count: number;  // Nombre d'Ã©chantillons utilisÃ©s pour crÃ©er le profil
}
```

### CrÃ©ation du Profil Vocal

Le profil vocal doit Ãªtre crÃ©Ã© lors de l'enregistrement de l'utilisateur ou via un processus d'entraÃ®nement sÃ©parÃ© :

1. L'utilisateur enregistre plusieurs Ã©chantillons vocaux (3-5 audios de 5-10 secondes)
2. Le service extrait les embeddings de chaque Ã©chantillon
3. Calcule la moyenne des embeddings pour crÃ©er un profil robuste
4. Stocke dans `UserVoiceModel`

---

## âœ… Tests et Validation

### Test Unitaire - Score de SimilaritÃ©

```python
def test_voice_similarity_score():
    from services.voice_recognition_service import VoiceRecognitionService

    service = VoiceRecognitionService()

    # CrÃ©er des embeddings de test
    user_embedding = np.random.rand(128)
    speaker1_embedding = user_embedding + np.random.rand(128) * 0.1  # TrÃ¨s similaire
    speaker2_embedding = np.random.rand(128)  # DiffÃ©rent

    # Calculer similaritÃ©s
    score1 = service.compute_similarity(user_embedding, speaker1_embedding)
    score2 = service.compute_similarity(user_embedding, speaker2_embedding)

    # Assertions
    assert 0.0 <= score1 <= 1.0, "Score doit Ãªtre entre 0 et 1"
    assert 0.0 <= score2 <= 1.0, "Score doit Ãªtre entre 0 et 1"
    assert score1 > score2, "Speaker 1 devrait Ãªtre plus similaire"
    assert score1 > 0.8, "Speaker 1 devrait avoir un score Ã©levÃ©"
```

---

## ğŸ¯ Conclusion

### Avant
- Boolean binaire (`isCurrentUser`)
- Impossible de mesurer la confiance
- Fallback basique (locuteur principal = utilisateur)
- Pas de reconnaissance vocale rÃ©elle

### AprÃ¨s
- Score continu (0-1) (`voiceSimilarityScore`)
- Mesure de confiance prÃ©cise
- Reconnaissance vocale par embeddings
- Affichage nuancÃ© au frontend
- Fonctionne mÃªme avec un seul locuteur

### Impact Utilisateur
- ğŸ¨ Affichage plus riche avec niveaux de confiance
- ğŸ¯ Identification plus prÃ©cise de l'utilisateur
- ğŸ“Š Transparence sur la confiance de l'identification
- âœ… Meilleure expÃ©rience utilisateur globale

---

**Date de crÃ©ation** : 19 janvier 2026
**Auteur** : Claude Sonnet 4.5
**Version** : 1.0
