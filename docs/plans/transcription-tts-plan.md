# Plan d'ImplÃ©mentation : Transcription, Traduction & Clonage Vocal pour Meeshy

## Vue d'ensemble

Ce plan dÃ©taille l'intÃ©gration d'un **pipeline audio complet** dans le service `translator` de Meeshy:
1. **Transcription** (Speech-to-Text) - avec support des mÃ©tadonnÃ©es mobiles
2. **Traduction** - vers toutes les langues des destinataires
3. **Clonage Vocal** - reproduction de la voix de l'Ã©metteur
4. **SynthÃ¨se TTS** - gÃ©nÃ©ration d'audio traduit avec voix clonÃ©e

**IMPORTANT**: Le service Translator fonctionne de maniÃ¨re **autonome** (sans dÃ©pendre du Gateway).

---

## INTÃ‰GRATION AVEC LE CODE EXISTANT

### Analyse du Code Actuel

#### 1. Structures Gateway Existantes

**AttachmentService** (`services/gateway/src/services/AttachmentService.ts`):
- Le champ `metadata` JSON dans `messageAttachment` stocke dÃ©jÃ  `audioEffectsTimeline`
- Les mÃ©tadonnÃ©es audio (duration, codec, sampleRate) sont extraites cÃ´tÃ© client (Web Audio API) ou serveur
- Format actuel des mÃ©tadonnÃ©es passÃ©es Ã  l'upload:

```typescript
// EXISTANT - services/gateway/src/services/AttachmentService.ts:469-490
metadata: {
  duration: number,           // secondes
  bitrate: number,            // bps
  sampleRate: number,         // Hz
  codec: string,
  channels: number,
  audioEffectsTimeline?: {    // Effets audio appliquÃ©s
    events: AudioEffect[]
  }
}
```

**ZMQ Translation Client** (`services/gateway/src/services/zmq-translation-client.ts`):
- Pattern PUSH/SUB sur ports 5555 (commandes) et 5558 (rÃ©sultats)
- Interface `TranslationRequest` existante:

```typescript
// EXISTANT - zmq-translation-client.ts:11-18
interface TranslationRequest {
  messageId: string;
  text: string;
  sourceLanguage: string;
  targetLanguages: string[];
  conversationId: string;
  modelType?: string;
}
```

**Message Flow** (`services/gateway/src/socketio/MeeshySocketIOManager.ts`):
- `CLIENT_EVENTS.MESSAGE_SEND_WITH_ATTACHMENTS` pour messages avec fichiers
- Broadcast via `SERVER_EVENTS.MESSAGE_NEW` avec attachments inclus
- `SERVER_EVENTS.MESSAGE_TRANSLATION` pour traductions prÃªtes

#### 2. Structures Translator Existantes

**MeeshyTranslationServer** (`services/translator/src/main.py`):
- Initialisation: Settings â†’ TranslationMLService â†’ ZMQTranslationServer â†’ TranslationAPI
- ModÃ¨les chargÃ©s en arriÃ¨re-plan (non-bloquant)
- Pattern Singleton pour TranslationMLService

**ZMQ Message Types** (`services/translator/src/services/zmq_server.py`):
- `type: "translation"` - Traduction de texte
- `type: "ping"` - Health check
- RÃ©sultats: `translation_completed`, `translation_error`, `translation_skipped`

---

### NOUVELLES STRUCTURES Ã€ AJOUTER

#### 1. Extension du champ `metadata` pour transcription mobile

**Format Ã©tendu pour `messageAttachment.metadata`**:

```typescript
// NOUVEAU - Ã€ documenter pour les clients mobiles
interface AudioAttachmentMetadata {
  // EXISTANT
  audioEffectsTimeline?: {
    events: AudioEffect[]
  };

  // NOUVEAU - Transcription faite sur mobile
  transcription?: {
    text: string;              // Texte transcrit
    language: string;          // Code langue ISO 639-1 (fr, en, es...)
    confidence: number;        // Score 0-1
    source: "ios_speech" | "android_speech" | "whisperkit" | "other";
    segments?: Array<{         // Optionnel - timestamps
      text: string;
      startMs: number;
      endMs: number;
    }>;
  };
}
```

**Modification AttachmentService** (`services/gateway/src/services/AttachmentService.ts`):

```typescript
// Ã€ AJOUTER dans uploadFile() aprÃ¨s ligne 490
if (providedMetadata.transcription) {
  console.log('ğŸ“ [AttachmentService] Mobile transcription found:', {
    text: providedMetadata.transcription.text.substring(0, 50) + '...',
    language: providedMetadata.transcription.language,
    source: providedMetadata.transcription.source
  });
  metadata.transcription = providedMetadata.transcription;
}
```

#### 2. Nouveau Type de Message ZMQ: `audio_process`

**Interface AudioProcessRequest** (Gateway â†’ Translator):

```typescript
// NOUVEAU - services/gateway/src/services/zmq-translation-client.ts
interface AudioProcessRequest {
  type: "audio_process";

  // Identifiants
  messageId: string;
  attachmentId: string;
  conversationId: string;
  senderId: string;

  // Audio source
  audioUrl: string;            // URL accessible du fichier audio
  audioPath: string;           // Chemin relatif dans uploads/
  audioDurationMs: number;

  // Transcription mobile (optionnelle)
  mobileTranscription?: {
    text: string;
    language: string;
    confidence: number;
    source: string;
  };

  // Langues cibles (extraites des membres de la conversation)
  targetLanguages: string[];

  // Options
  generateVoiceClone: boolean;  // true par dÃ©faut
  modelType: "basic" | "medium" | "premium";
}
```

**Interface AudioProcessResult** (Translator â†’ Gateway):

```typescript
// NOUVEAU - services/gateway/src/services/zmq-translation-client.ts
interface AudioProcessResult {
  type: "audio_process_completed";
  taskId: string;
  messageId: string;
  attachmentId: string;

  // Transcription
  transcription: {
    text: string;
    language: string;
    confidence: number;
    source: "mobile" | "whisper";
    segments?: TranscriptionSegment[];
  };

  // Traductions audio gÃ©nÃ©rÃ©es (une par langue)
  translatedAudios: Array<{
    targetLanguage: string;
    translatedText: string;
    audioUrl: string;          // URL accessible
    audioPath: string;         // Chemin stockage
    durationMs: number;
    voiceCloned: boolean;
    voiceQuality: number;      // 0-1
  }>;

  // MÃ©tadonnÃ©es
  voiceModelUserId: string;
  voiceModelQuality: number;
  processingTimeMs: number;
  timestamp: number;
}

interface AudioProcessError {
  type: "audio_process_error";
  taskId: string;
  messageId: string;
  attachmentId: string;
  error: string;
  errorCode: "transcription_failed" | "translation_failed" | "tts_failed" | "voice_clone_failed";
}
```

#### 3. Nouveaux Ã‰vÃ©nements Socket.IO

**Ajout dans `packages/shared/types/socketio-events.ts`**:

```typescript
// NOUVEAU - Ã‰vÃ©nements Audio
export const SERVER_EVENTS = {
  // ... existants ...

  // Audio Processing
  AUDIO_TRANSCRIPTION_READY: 'audio:transcription:ready',
  AUDIO_TRANSLATION_READY: 'audio:translation:ready',      // Ã‰mis pour chaque langue
  AUDIO_PROCESSING_COMPLETE: 'audio:processing:complete',  // Tout le pipeline terminÃ©
  AUDIO_PROCESSING_ERROR: 'audio:processing:error',

  // Voice Model
  VOICE_MODEL_CREATED: 'voice:model:created',
  VOICE_MODEL_IMPROVED: 'voice:model:improved',
  VOICE_MODEL_RECALIBRATED: 'voice:model:recalibrated',
} as const;

// Payloads
interface AudioTranscriptionReadyPayload {
  messageId: string;
  attachmentId: string;
  transcription: {
    text: string;
    language: string;
    confidence: number;
    source: "mobile" | "whisper";
  };
}

interface AudioTranslationReadyPayload {
  messageId: string;
  attachmentId: string;
  targetLanguage: string;
  translatedText: string;
  audioUrl: string;
  durationMs: number;
  voiceCloned: boolean;
}

interface AudioProcessingCompletePayload {
  messageId: string;
  attachmentId: string;
  transcription: TranscriptionData;
  translatedAudios: TranslatedAudioData[];
  processingTimeMs: number;
}
```

#### 4. DÃ©clenchement du Pipeline Audio

**Option retenue: Automatique pour les messages audio**

Modification dans `MeeshySocketIOManager.ts` aprÃ¨s crÃ©ation du message:

```typescript
// NOUVEAU - services/gateway/src/socketio/MeeshySocketIOManager.ts
// AprÃ¨s la crÃ©ation du message avec attachments (vers ligne 1950)

private async _triggerAudioProcessingIfNeeded(
  message: Message,
  attachments: MessageAttachment[],
  conversationId: string
): Promise<void> {
  // Filtrer les attachments audio
  const audioAttachments = attachments.filter(att =>
    att.mimeType.startsWith('audio/')
  );

  if (audioAttachments.length === 0) return;

  // RÃ©cupÃ©rer les langues cibles des membres
  const targetLanguages = await this._getConversationTargetLanguages(
    conversationId,
    message.senderId,
    message.originalLanguage
  );

  // Envoyer chaque audio au pipeline
  for (const attachment of audioAttachments) {
    const request: AudioProcessRequest = {
      type: "audio_process",
      messageId: message.id,
      attachmentId: attachment.id,
      conversationId: conversationId,
      senderId: message.senderId,
      audioUrl: attachment.fileUrl,
      audioPath: attachment.filePath,
      audioDurationMs: (attachment.duration || 0) * 1000,
      mobileTranscription: (attachment.metadata as any)?.transcription,
      targetLanguages: targetLanguages,
      generateVoiceClone: true,
      modelType: "medium"
    };

    await this.zmqClient.sendAudioProcessRequest(request);

    logger.info(`[Audio] Triggered processing for attachment ${attachment.id}`);
  }
}
```

#### 5. Gestion des RÃ©sultats Audio (Gateway)

**Nouveau handler dans ZMQTranslationClient**:

```typescript
// NOUVEAU - services/gateway/src/services/zmq-translation-client.ts

private _handleAudioProcessResult(event: AudioProcessResult | AudioProcessError): void {
  if (event.type === 'audio_process_completed') {
    // Ã‰mettre transcription ready
    this.emit('audioTranscriptionReady', {
      messageId: event.messageId,
      attachmentId: event.attachmentId,
      transcription: event.transcription
    });

    // Ã‰mettre chaque traduction audio
    for (const audio of event.translatedAudios) {
      this.emit('audioTranslationReady', {
        messageId: event.messageId,
        attachmentId: event.attachmentId,
        targetLanguage: audio.targetLanguage,
        translatedText: audio.translatedText,
        audioUrl: audio.audioUrl,
        durationMs: audio.durationMs,
        voiceCloned: audio.voiceCloned
      });
    }

    // Ã‰mettre processing complete
    this.emit('audioProcessingComplete', event);

  } else if (event.type === 'audio_process_error') {
    this.emit('audioProcessingError', event);
  }
}
```

**Handler Socket.IO dans MeeshySocketIOManager**:

```typescript
// NOUVEAU - Ã‰couter les Ã©vÃ©nements audio du ZMQ client
this.zmqClient.on('audioTranscriptionReady', async (data) => {
  // Sauvegarder en BDD
  await this.saveAudioTranscription(data);

  // Broadcast Ã  la conversation
  this.io.to(`conversation_${data.conversationId}`)
    .emit(SERVER_EVENTS.AUDIO_TRANSCRIPTION_READY, data);
});

this.zmqClient.on('audioTranslationReady', async (data) => {
  // Sauvegarder en BDD
  await this.saveTranslatedAudio(data);

  // Broadcast Ã  la conversation
  this.io.to(`conversation_${data.conversationId}`)
    .emit(SERVER_EVENTS.AUDIO_TRANSLATION_READY, data);
});
```

#### 6. Stockage des Audios GÃ©nÃ©rÃ©s

**Structure de fichiers**:

```
uploads/
â””â”€â”€ attachments/           # Existant - audios originaux
    â””â”€â”€ YYYY/mm/userId/
        â””â”€â”€ audio_UUID.webm

outputs/                   # NOUVEAU - audios gÃ©nÃ©rÃ©s
â””â”€â”€ audio/
    â””â”€â”€ translated/
        â””â”€â”€ YYYY/mm/
            â””â”€â”€ {messageId}_{targetLang}.mp3
    â””â”€â”€ voice_models/
        â””â”€â”€ {userId}/
            â””â”€â”€ embedding.pkl
            â””â”€â”€ metadata.json
```

**Nouvelle route pour servir les audios gÃ©nÃ©rÃ©s**:

```typescript
// NOUVEAU - services/gateway/src/routes/audio-outputs.ts
router.get('/outputs/audio/:path(*)', async (request, reply) => {
  const filePath = path.join(OUTPUTS_DIR, 'audio', request.params.path);

  if (!fs.existsSync(filePath)) {
    return reply.status(404).send({ error: 'Audio not found' });
  }

  const mimeType = getMimeType(filePath);
  return reply.type(mimeType).send(fs.createReadStream(filePath));
});
```

#### 7. Relation Prisma: Attachment â†’ TranslatedAudios

**Modification du schÃ©ma**:

```prisma
// packages/shared/prisma/schema.prisma

model MessageAttachment {
  // ... champs existants ...

  // NOUVEAU - Relation vers la transcription
  transcription    MessageAudioTranscription?

  // NOUVEAU - Relation vers les audios traduits
  translatedAudios MessageTranslatedAudio[]
}

model MessageAudioTranscription {
  id              String   @id @default(auto()) @map("_id") @db.ObjectId

  // Relation vers l'attachment source
  attachmentId    String   @unique @db.ObjectId
  attachment      MessageAttachment @relation(fields: [attachmentId], references: [id], onDelete: Cascade)

  // Relation vers le message (pour requÃªtes directes)
  messageId       String   @db.ObjectId
  message         Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)

  // DonnÃ©es de transcription
  transcribedText String
  language        String
  confidence      Float
  source          String   // "mobile" | "whisper"
  segments        Json?    // Timestamps optionnels
  audioDurationMs Int
  model           String?  // "whisper-large-v3" si serveur

  createdAt       DateTime @default(now())

  @@index([messageId])
  @@index([language])
  @@map("message_audio_transcriptions")
}

model MessageTranslatedAudio {
  id              String   @id @default(auto()) @map("_id") @db.ObjectId

  // Relation vers l'attachment source
  attachmentId    String   @db.ObjectId
  attachment      MessageAttachment @relation(fields: [attachmentId], references: [id], onDelete: Cascade)

  // Relation vers le message
  messageId       String   @db.ObjectId
  message         Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)

  // DonnÃ©es audio traduit
  targetLanguage  String
  translatedText  String
  audioPath       String
  audioUrl        String
  durationMs      Int
  format          String   @default("mp3")

  // Clonage vocal
  voiceCloned     Boolean  @default(true)
  voiceQuality    Float
  voiceModelId    String?  @db.ObjectId

  // MÃ©tadonnÃ©es
  ttsModel        String   @default("xtts")
  createdAt       DateTime @default(now())

  // Contrainte: une seule version par attachment + langue
  @@unique([attachmentId, targetLanguage])
  @@index([messageId])
  @@index([targetLanguage])
  @@map("message_translated_audios")
}
```

---

### FLOW COMPLET INTÃ‰GRÃ‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CLIENT MOBILE (iOS/Android)                                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚  a. Enregistre audio                                                          â”‚ â”‚
â”‚    â”‚  b. Transcrit localement (iOS Speech / Android Speech / WhisperKit)          â”‚ â”‚
â”‚    â”‚  c. Upload avec metadata:                                                      â”‚ â”‚
â”‚    â”‚     POST /attachments/upload                                                   â”‚ â”‚
â”‚    â”‚     FormData: {                                                                â”‚ â”‚
â”‚    â”‚       file: audio.webm,                                                        â”‚ â”‚
â”‚    â”‚       metadata_0: {                                                            â”‚ â”‚
â”‚    â”‚         duration: 5.2,                                                         â”‚ â”‚
â”‚    â”‚         codec: "opus",                                                         â”‚ â”‚
â”‚    â”‚         transcription: {        // â† NOUVEAU                                   â”‚ â”‚
â”‚    â”‚           text: "Bonjour!",                                                    â”‚ â”‚
â”‚    â”‚           language: "fr",                                                      â”‚ â”‚
â”‚    â”‚           confidence: 0.92,                                                    â”‚ â”‚
â”‚    â”‚           source: "ios_speech"                                                 â”‚ â”‚
â”‚    â”‚         }                                                                      â”‚ â”‚
â”‚    â”‚       }                                                                        â”‚ â”‚
â”‚    â”‚     }                                                                          â”‚ â”‚
â”‚    â”‚  d. Socket: MESSAGE_SEND_WITH_ATTACHMENTS { attachmentIds: [...] }            â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GATEWAY                                                                           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚  a. AttachmentService.uploadFile()                                            â”‚ â”‚
â”‚    â”‚     â†’ Stocke metadata.transcription dans messageAttachment.metadata           â”‚ â”‚
â”‚    â”‚                                                                                â”‚ â”‚
â”‚    â”‚  b. MeeshySocketIOManager._handleMessageSendWithAttachments()                 â”‚ â”‚
â”‚    â”‚     â†’ CrÃ©e Message + associe Attachments                                       â”‚ â”‚
â”‚    â”‚     â†’ Broadcast MESSAGE_NEW                                                    â”‚ â”‚
â”‚    â”‚                                                                                â”‚ â”‚
â”‚    â”‚  c. _triggerAudioProcessingIfNeeded() // â† NOUVEAU                            â”‚ â”‚
â”‚    â”‚     â†’ DÃ©tecte mimeType audio/*                                                â”‚ â”‚
â”‚    â”‚     â†’ RÃ©cupÃ¨re targetLanguages des membres                                    â”‚ â”‚
â”‚    â”‚     â†’ ZMQ PUSH: AudioProcessRequest {                                         â”‚ â”‚
â”‚    â”‚         type: "audio_process",                                                â”‚ â”‚
â”‚    â”‚         messageId, attachmentId, audioPath,                                   â”‚ â”‚
â”‚    â”‚         mobileTranscription: metadata.transcription,                          â”‚ â”‚
â”‚    â”‚         targetLanguages: ["en", "es", "de"]                                   â”‚ â”‚
â”‚    â”‚       }                                                                        â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“ ZMQ PUSH (port 5555)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. TRANSLATOR SERVICE                                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚  ZMQTranslationServer._handle_audio_process()  // â† NOUVEAU                   â”‚ â”‚
â”‚    â”‚                                                                                â”‚ â”‚
â”‚    â”‚  Ã‰TAPE 1: TRANSCRIPTION                                                       â”‚ â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚    â”‚  â”‚  if mobileTranscription:                                               â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      transcription = mobileTranscription  # RÃ©utiliser                 â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  else:                                                                 â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      transcription = TranscriptionService.transcribe(audioPath)        â”‚   â”‚ â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚    â”‚                                    â†“                                           â”‚ â”‚
â”‚    â”‚  Ã‰TAPE 2: CLONAGE VOCAL                                                       â”‚ â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚    â”‚  â”‚  voice_model = VoiceCloneService.get_or_create(                        â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      user_id=senderId,                                                 â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      audio_path=audioPath,                                             â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      duration_ms=audioDurationMs                                       â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  )                                                                     â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  # Si audio trop court â†’ agrÃ¨ge historique audios de l'utilisateur    â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  # Cache modÃ¨le 30 jours, amÃ©lioration continue                        â”‚   â”‚ â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚    â”‚                                    â†“                                           â”‚ â”‚
â”‚    â”‚  Ã‰TAPE 3: POUR CHAQUE targetLanguage                                          â”‚ â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚    â”‚  â”‚  # 3a. Traduire texte                                                  â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  translated_text = TranslationMLService.translate(                     â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      text=transcription.text,                                          â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      source=transcription.language,                                    â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      target=targetLanguage                                             â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  )                                                                     â”‚   â”‚ â”‚
â”‚    â”‚  â”‚                                                                        â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  # 3b. GÃ©nÃ©rer audio avec voix clonÃ©e                                  â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  audio_result = TTSService.synthesize_with_voice(                      â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      text=translated_text,                                             â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      voice_model=voice_model,                                          â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      language=targetLanguage                                           â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  )                                                                     â”‚   â”‚ â”‚
â”‚    â”‚  â”‚                                                                        â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  # 3c. Stocker fichier audio                                           â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  audio_path = f"outputs/audio/translated/{messageId}_{lang}.mp3"       â”‚   â”‚ â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚    â”‚                                    â†“                                           â”‚ â”‚
â”‚    â”‚  Ã‰TAPE 4: PUBLIER RÃ‰SULTAT                                                    â”‚ â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚    â”‚  â”‚  ZMQ PUB: AudioProcessResult {                                         â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      type: "audio_process_completed",                                  â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      messageId, attachmentId,                                          â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      transcription: { text, language, confidence, source },            â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      translatedAudios: [                                               â”‚   â”‚ â”‚
â”‚    â”‚  â”‚          { targetLanguage: "en", audioUrl: "...", ... },               â”‚   â”‚ â”‚
â”‚    â”‚  â”‚          { targetLanguage: "es", audioUrl: "...", ... },               â”‚   â”‚ â”‚
â”‚    â”‚  â”‚      ]                                                                 â”‚   â”‚ â”‚
â”‚    â”‚  â”‚  }                                                                     â”‚   â”‚ â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“ ZMQ PUB (port 5558)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. GATEWAY (rÃ©ception rÃ©sultat)                                                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚  ZMQTranslationClient._handleAudioProcessResult()                             â”‚ â”‚
â”‚    â”‚                                                                                â”‚ â”‚
â”‚    â”‚  a. Sauvegarder en BDD:                                                       â”‚ â”‚
â”‚    â”‚     â†’ MessageAudioTranscription                                               â”‚ â”‚
â”‚    â”‚     â†’ MessageTranslatedAudio[] (une par langue)                               â”‚ â”‚
â”‚    â”‚                                                                                â”‚ â”‚
â”‚    â”‚  b. Ã‰mettre Ã©vÃ©nements Socket.IO:                                             â”‚ â”‚
â”‚    â”‚     â†’ AUDIO_TRANSCRIPTION_READY                                               â”‚ â”‚
â”‚    â”‚     â†’ AUDIO_TRANSLATION_READY (pour chaque langue)                            â”‚ â”‚
â”‚    â”‚     â†’ AUDIO_PROCESSING_COMPLETE                                               â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â†“ Socket.IO
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. CLIENTS (tous les membres de la conversation)                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    â”‚  socket.on('audio:transcription:ready', (data) => {                           â”‚ â”‚
â”‚    â”‚      // Afficher texte transcrit sous le message audio                        â”‚ â”‚
â”‚    â”‚  });                                                                           â”‚ â”‚
â”‚    â”‚                                                                                â”‚ â”‚
â”‚    â”‚  socket.on('audio:translation:ready', (data) => {                             â”‚ â”‚
â”‚    â”‚      // Si data.targetLanguage === user.preferredLanguage                     â”‚ â”‚
â”‚    â”‚      // â†’ Afficher bouton "Ã‰couter traduction" avec audioUrl                  â”‚ â”‚
â”‚    â”‚      // â†’ Afficher texte traduit                                              â”‚ â”‚
â”‚    â”‚  });                                                                           â”‚ â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### MODIFICATIONS FICHIERS EXISTANTS (RÃ‰SUMÃ‰)

| Fichier | Modification |
|---------|-------------|
| `gateway/src/services/AttachmentService.ts` | Stocker `metadata.transcription` |
| `gateway/src/services/zmq-translation-client.ts` | Ajouter `AudioProcessRequest`, handler rÃ©sultats |
| `gateway/src/socketio/MeeshySocketIOManager.ts` | Trigger audio processing, Ã©mettre Ã©vÃ©nements |
| `shared/types/socketio-events.ts` | Nouveaux Ã©vÃ©nements `AUDIO_*` |
| `shared/prisma/schema.prisma` | Relations Attachment â†” Transcription â†” TranslatedAudio |
| `translator/src/services/zmq_server.py` | Handler `audio_process` |
| `translator/src/main.py` | Initialiser nouveaux services |

---

---

## Architecture Cible

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT (iOS/Android/Web)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Enregistrement Audio                                                   â”‚  â”‚
â”‚  â”‚  2. Transcription locale (optionnelle) â†’ metadata.transcription           â”‚  â”‚
â”‚  â”‚  3. Envoi: { audio_file, metadata: { transcription?, language? } }        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRANSLATOR SERVICE (Autonome - services/translator)                 â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    AudioMessagePipeline (NOUVEAU)                        â”‚    â”‚
â”‚  â”‚                                                                          â”‚    â”‚
â”‚  â”‚   Ã‰TAPE 1: TRANSCRIPTION                                                â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚   â”‚  Si metadata.transcription existe â†’ utiliser directement       â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  Sinon â†’ TranscriptionService (Whisper)                        â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  RÃ©sultat: { text, language, confidence, segments[] }          â”‚    â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                              â†“                                           â”‚    â”‚
â”‚  â”‚   Ã‰TAPE 2: TRADUCTION (pour chaque langue destinataire)                 â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚   â”‚  TranslationMLService.translate_with_structure()               â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  â†’ GÃ©nÃ©rer N versions traduites (1 par langue destinataire)    â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  RÃ©sultat: { "fr": "Bonjour", "en": "Hello", "es": "Hola" }   â”‚    â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                              â†“                                           â”‚    â”‚
â”‚  â”‚   Ã‰TAPE 3: CLONAGE VOCAL                                                â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚   â”‚  VoiceCloneService.get_or_create_voice_model(user_id)          â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  â†’ Charger modÃ¨le voix depuis cache                            â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  â†’ Si audio trop court: agrÃ©ger tous les audios de l'auteur    â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  â†’ AmÃ©lioration continue du modÃ¨le (mise Ã  jour mensuelle)     â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  RÃ©sultat: VoiceModel (embedding ou modÃ¨le fine-tunÃ©)          â”‚    â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                              â†“                                           â”‚    â”‚
â”‚  â”‚   Ã‰TAPE 4: SYNTHÃˆSE TTS (pour chaque langue)                            â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚   â”‚  TTSService.synthesize_with_voice(text, voice_model, lang)     â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  â†’ GÃ©nÃ©rer N fichiers audio (1 par langue destinataire)        â”‚    â”‚    â”‚
â”‚  â”‚   â”‚  RÃ©sultat: { "fr": audio_fr.mp3, "en": audio_en.mp3, ... }    â”‚    â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ TranscriptionService â”‚  â”‚ VoiceCloneService    â”‚  â”‚ TTSService             â”‚ â”‚
â”‚  â”‚ (Whisper)            â”‚  â”‚ (OpenVoice V2)       â”‚  â”‚ (XTTS + Voice Clone)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      VoiceModelCache (NOUVEAU)                            â”‚   â”‚
â”‚  â”‚  - Cache des modÃ¨les de voix par utilisateur                             â”‚   â”‚
â”‚  â”‚  - Mise Ã  jour automatique mensuelle                                      â”‚   â”‚
â”‚  â”‚  - AgrÃ©gation des audios pour amÃ©lioration continue                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           RÃ‰SULTAT FINAL                                         â”‚
â”‚                                                                                  â”‚
â”‚  AudioMessageResult {                                                            â”‚
â”‚    original: {                                                                   â”‚
â”‚      audio_url: "uploads/audio/msg_123_original.mp3",                           â”‚
â”‚      transcription: "Bonjour, comment allez-vous?",                             â”‚
â”‚      language: "fr",                                                             â”‚
â”‚      duration_ms: 3500                                                           â”‚
â”‚    },                                                                            â”‚
â”‚    translations: {                                                               â”‚
â”‚      "en": {                                                                     â”‚
â”‚        text: "Hello, how are you?",                                             â”‚
â”‚        audio_url: "outputs/audio/msg_123_en.mp3",                               â”‚
â”‚        voice_cloned: true                                                        â”‚
â”‚      },                                                                          â”‚
â”‚      "es": {                                                                     â”‚
â”‚        text: "Hola, Â¿cÃ³mo estÃ¡s?",                                              â”‚
â”‚        audio_url: "outputs/audio/msg_123_es.mp3",                               â”‚
â”‚        voice_cloned: true                                                        â”‚
â”‚      }                                                                           â”‚
â”‚    }                                                                             â”‚
â”‚  }                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pipeline Audio Complet

### Flux de Traitement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FLUX DE TRAITEMENT AUDIO                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                  â”‚
â”‚  â”‚ Audio reÃ§u  â”‚                                                                  â”‚
â”‚  â”‚ + metadata  â”‚                                                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                                  â”‚
â”‚         â”‚                                                                         â”‚
â”‚         â–¼                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚  â”‚ Transcription fournie par mobile?    â”‚                                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚         â”‚                    â”‚                                                    â”‚
â”‚        OUI                  NON                                                   â”‚
â”‚         â”‚                    â”‚                                                    â”‚
â”‚         â–¼                    â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ Utiliser        â”‚  â”‚ TranscriptionService â”‚                                    â”‚
â”‚  â”‚ metadata.text   â”‚  â”‚ (Whisper large-v3)   â”‚                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚           â”‚                      â”‚                                                â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚                      â–¼                                                            â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚           â”‚ Texte transcrit     â”‚                                                 â”‚
â”‚           â”‚ + langue dÃ©tectÃ©e   â”‚                                                 â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚                      â”‚                                                            â”‚
â”‚                      â–¼                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ RÃ©cupÃ©rer les langues de destination de tous les membres      â”‚               â”‚
â”‚  â”‚ de la conversation (User.systemLanguage ou regionalLanguage)  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚           POUR CHAQUE LANGUE DESTINATAIRE                     â”‚               â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚               â”‚
â”‚  â”‚  â”‚  1. Traduire texte â†’ TranslationMLService               â”‚  â”‚               â”‚
â”‚  â”‚  â”‚  2. Charger/crÃ©er modÃ¨le voix â†’ VoiceCloneService       â”‚  â”‚               â”‚
â”‚  â”‚  â”‚  3. GÃ©nÃ©rer audio traduit â†’ TTSService + VoiceModel     â”‚  â”‚               â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚           â”‚ Sauvegarder rÃ©sultats en BDD            â”‚                            â”‚
â”‚           â”‚ - MessageAudioTranscription             â”‚                            â”‚
â”‚           â”‚ - MessageTranslatedAudio[] (par langue) â”‚                            â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1 : TranscriptionService

### 1.1 Service de Transcription

**Fichier**: `services/translator/src/services/transcription_service.py`

```python
"""
Service de transcription audio - Singleton
Supporte les transcriptions mobiles (metadata) et serveur (Whisper)
"""

class TranscriptionService:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        self.model = None  # faster-whisper model
        self.device = "cpu"  # ou "cuda"
        self.compute_type = "float16"
        self.is_initialized = False

    async def initialize(self) -> bool:
        """Charge le modÃ¨le Whisper au dÃ©marrage"""
        from faster_whisper import WhisperModel
        self.model = WhisperModel(
            "large-v3",
            device=self.device,
            compute_type=self.compute_type
        )
        self.is_initialized = True
        return True

    async def transcribe(
        self,
        audio_path: str,
        mobile_transcription: Optional[str] = None,
        mobile_language: Optional[str] = None,
        return_timestamps: bool = True
    ) -> TranscriptionResult:
        """
        Transcrit un fichier audio.

        Si mobile_transcription est fourni, l'utilise directement.
        Sinon, utilise Whisper pour transcrire.

        Args:
            audio_path: Chemin vers le fichier audio
            mobile_transcription: Transcription fournie par le client mobile
            mobile_language: Langue dÃ©tectÃ©e par le mobile
            return_timestamps: Retourner les segments avec timestamps

        Returns:
            TranscriptionResult avec text, language, confidence, segments
        """
        # Si transcription mobile fournie, l'utiliser
        if mobile_transcription:
            return TranscriptionResult(
                text=mobile_transcription,
                language=mobile_language or "auto",
                confidence=0.85,  # Confiance par dÃ©faut pour mobile
                segments=[],
                duration_ms=await self._get_audio_duration(audio_path),
                source="mobile"
            )

        # Sinon, transcrire avec Whisper
        segments, info = self.model.transcribe(
            audio_path,
            beam_size=5,
            word_timestamps=return_timestamps
        )

        segments_list = list(segments)
        full_text = " ".join([s.text for s in segments_list])

        return TranscriptionResult(
            text=full_text,
            language=info.language,
            confidence=info.language_probability,
            segments=[
                TranscriptionSegment(
                    text=s.text,
                    start_ms=int(s.start * 1000),
                    end_ms=int(s.end * 1000),
                    confidence=s.avg_logprob
                ) for s in segments_list
            ],
            duration_ms=int(info.duration * 1000),
            source="whisper"
        )
```

### 1.2 ModÃ¨les de DonnÃ©es

```python
@dataclass
class TranscriptionResult:
    text: str
    language: str
    confidence: float
    segments: List[TranscriptionSegment]
    duration_ms: int
    source: str  # "mobile" ou "whisper"

@dataclass
class TranscriptionSegment:
    text: str
    start_ms: int
    end_ms: int
    confidence: float
```

---

## Phase 2 : VoiceCloneService (Clonage Vocal)

### 2.1 Architecture du Clonage Vocal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VoiceCloneService                                    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      VoiceModelCache                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Cache Redis/Fichier:                                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - ClÃ©: user_id                                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Valeur: { embedding, model_path, created_at, updated_at,     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚             audio_count, total_duration_ms, quality_score }      â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Logique de crÃ©ation/amÃ©lioration:                                     â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  1. get_voice_model(user_id, audio_path)                               â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ Si modÃ¨le en cache ET < 30 jours â†’ retourner                   â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ Si modÃ¨le en cache ET > 30 jours â†’ recalibrer                  â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â””â”€â†’ Si pas de modÃ¨le â†’ crÃ©er nouveau                               â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  2. create_voice_model(user_id, audio_paths[])                         â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ Si durÃ©e totale < 10s â†’ chercher plus d'audios                 â”‚ â”‚
â”‚  â”‚     â”‚   â””â”€â†’ get_user_audio_history(user_id)                            â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ ConcatÃ©ner audios â†’ audio_combined.wav                         â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ Extraire embedding voix (OpenVoice)                            â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â””â”€â†’ Sauvegarder en cache                                           â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  3. improve_voice_model(user_id, new_audio_path)                       â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ Charger modÃ¨le existant                                        â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â”œâ”€â†’ Ajouter nouvel audio aux donnÃ©es d'entraÃ®nement                â”‚ â”‚
â”‚  â”‚     â”‚                                                                   â”‚ â”‚
â”‚  â”‚     â””â”€â†’ Recalculer embedding (moyenne pondÃ©rÃ©e)                        â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Service de Clonage Vocal

**Fichier**: `services/translator/src/services/voice_clone_service.py`

```python
"""
Service de clonage vocal - Singleton
GÃ¨re les modÃ¨les de voix des utilisateurs avec cache et amÃ©lioration continue
"""

import os
import pickle
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, List
import numpy as np

class VoiceCloneService:
    _instance = None
    _lock = threading.Lock()

    # Configuration
    MIN_AUDIO_DURATION_MS = 10_000  # 10 secondes minimum pour clonage
    VOICE_MODEL_MAX_AGE_DAYS = 30   # Recalibrer aprÃ¨s 30 jours

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        self.voice_cache_dir = Path("voice_models")
        self.voice_cache_dir.mkdir(exist_ok=True)
        self.tone_color_converter = None  # OpenVoice
        self.is_initialized = False

    async def initialize(self) -> bool:
        """Initialise OpenVoice pour le clonage vocal"""
        from openvoice import se_extractor
        from openvoice.api import ToneColorConverter

        self.tone_color_converter = ToneColorConverter(
            "checkpoints/converter",
            device=self.device
        )
        self.is_initialized = True
        return True

    async def get_or_create_voice_model(
        self,
        user_id: str,
        current_audio_path: str,
        current_audio_duration_ms: int
    ) -> VoiceModel:
        """
        RÃ©cupÃ¨re ou crÃ©e un modÃ¨le de voix pour un utilisateur.

        Logique:
        1. Si modÃ¨le en cache et rÃ©cent â†’ utiliser
        2. Si modÃ¨le en cache mais ancien â†’ amÃ©liorer avec nouvel audio
        3. Si pas de modÃ¨le et audio trop court â†’ agrÃ©ger historique
        4. CrÃ©er nouveau modÃ¨le

        Args:
            user_id: ID de l'utilisateur
            current_audio_path: Audio actuel pour le clonage
            current_audio_duration_ms: DurÃ©e de l'audio actuel

        Returns:
            VoiceModel prÃªt Ã  l'emploi
        """
        # 1. VÃ©rifier le cache
        cached_model = await self._load_cached_model(user_id)

        if cached_model:
            age_days = (datetime.now() - cached_model.updated_at).days

            # ModÃ¨le rÃ©cent â†’ utiliser directement
            if age_days < self.VOICE_MODEL_MAX_AGE_DAYS:
                logger.info(f"[VOICE] Using cached model for user {user_id} (age: {age_days} days)")
                return cached_model

            # ModÃ¨le ancien â†’ amÃ©liorer avec nouvel audio
            logger.info(f"[VOICE] Model outdated for user {user_id}, improving...")
            return await self._improve_model(cached_model, current_audio_path)

        # 2. Pas de modÃ¨le â†’ crÃ©er
        audio_paths = [current_audio_path]
        total_duration = current_audio_duration_ms

        # Si audio trop court, chercher l'historique
        if total_duration < self.MIN_AUDIO_DURATION_MS:
            logger.info(f"[VOICE] Audio too short ({total_duration}ms), fetching history...")
            historical_audios = await self._get_user_audio_history(user_id)
            audio_paths.extend(historical_audios)
            total_duration = await self._calculate_total_duration(audio_paths)

            logger.info(f"[VOICE] Found {len(historical_audios)} historical audios, total: {total_duration}ms")

        # CrÃ©er le modÃ¨le avec ce qu'on a (mÃªme si insuffisant)
        return await self._create_voice_model(user_id, audio_paths, total_duration)

    async def _create_voice_model(
        self,
        user_id: str,
        audio_paths: List[str],
        total_duration_ms: int
    ) -> VoiceModel:
        """CrÃ©e un nouveau modÃ¨le de voix Ã  partir des audios"""
        from openvoice import se_extractor

        # ConcatÃ©ner les audios si multiples
        if len(audio_paths) > 1:
            combined_audio = await self._concatenate_audios(audio_paths)
        else:
            combined_audio = audio_paths[0]

        # Extraire l'embedding de voix
        embedding = se_extractor.get_se(
            combined_audio,
            self.tone_color_converter,
            target_dir=str(self.voice_cache_dir / user_id)
        )

        # Calculer score de qualitÃ©
        quality_score = self._calculate_quality_score(total_duration_ms, len(audio_paths))

        # CrÃ©er le modÃ¨le
        model = VoiceModel(
            user_id=user_id,
            embedding=embedding,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            audio_count=len(audio_paths),
            total_duration_ms=total_duration_ms,
            quality_score=quality_score
        )

        # Sauvegarder en cache
        await self._save_model_to_cache(model)

        logger.info(f"[VOICE] Created model for user {user_id}: quality={quality_score:.2f}")
        return model

    async def _improve_model(
        self,
        existing_model: VoiceModel,
        new_audio_path: str
    ) -> VoiceModel:
        """AmÃ©liore un modÃ¨le existant avec un nouvel audio"""
        from openvoice import se_extractor

        # Extraire embedding du nouvel audio
        new_embedding = se_extractor.get_se(
            new_audio_path,
            self.tone_color_converter,
            target_dir=str(self.voice_cache_dir / existing_model.user_id / "temp")
        )

        # Moyenne pondÃ©rÃ©e (plus de poids aux anciens pour stabilitÃ©)
        weight_old = 0.7
        weight_new = 0.3
        improved_embedding = (
            weight_old * existing_model.embedding +
            weight_new * new_embedding
        )

        # Mettre Ã  jour le modÃ¨le
        existing_model.embedding = improved_embedding
        existing_model.updated_at = datetime.now()
        existing_model.audio_count += 1
        existing_model.quality_score = min(1.0, existing_model.quality_score + 0.05)

        await self._save_model_to_cache(existing_model)

        logger.info(f"[VOICE] Improved model for user {existing_model.user_id}")
        return existing_model

    async def _get_user_audio_history(self, user_id: str) -> List[str]:
        """
        RÃ©cupÃ¨re l'historique des messages audio d'un utilisateur.
        Utilise la base de donnÃ©es pour trouver les attachements audio.
        """
        # RequÃªte Prisma pour rÃ©cupÃ©rer les audios de l'utilisateur
        from services.database_service import DatabaseService
        db = DatabaseService()

        attachments = await db.prisma.messageattachment.find_many(
            where={
                "message": {
                    "senderId": user_id
                },
                "mimeType": {
                    "startswith": "audio/"
                }
            },
            order_by={"createdAt": "desc"},
            take=20  # Limiter aux 20 derniers audios
        )

        return [att.filePath for att in attachments if os.path.exists(att.filePath)]

    def _calculate_quality_score(self, duration_ms: int, audio_count: int) -> float:
        """
        Calcule un score de qualitÃ© basÃ© sur la durÃ©e et le nombre d'audios.

        - 0-10s: 0.3 (faible)
        - 10-30s: 0.5 (moyen)
        - 30-60s: 0.7 (bon)
        - 60s+: 0.9 (excellent)
        - Bonus: +0.05 par audio supplÃ©mentaire (max +0.1)
        """
        if duration_ms < 10_000:
            base_score = 0.3
        elif duration_ms < 30_000:
            base_score = 0.5
        elif duration_ms < 60_000:
            base_score = 0.7
        else:
            base_score = 0.9

        audio_bonus = min(0.1, (audio_count - 1) * 0.05)
        return min(1.0, base_score + audio_bonus)

    async def schedule_monthly_recalibration(self):
        """
        TÃ¢che planifiÃ©e pour recalibrer les modÃ¨les de voix mensuellement.
        Ã€ exÃ©cuter via un cron job ou un scheduler.
        """
        all_models = await self._list_all_cached_models()

        for model in all_models:
            age_days = (datetime.now() - model.updated_at).days

            if age_days >= self.VOICE_MODEL_MAX_AGE_DAYS:
                logger.info(f"[VOICE] Monthly recalibration for user {model.user_id}")

                # RÃ©cupÃ©rer les audios rÃ©cents (dernier mois)
                recent_audios = await self._get_recent_user_audios(
                    model.user_id,
                    days=30
                )

                if recent_audios:
                    # RecrÃ©er le modÃ¨le avec les audios rÃ©cents
                    await self._create_voice_model(
                        model.user_id,
                        recent_audios,
                        await self._calculate_total_duration(recent_audios)
                    )


@dataclass
class VoiceModel:
    user_id: str
    embedding: np.ndarray
    created_at: datetime
    updated_at: datetime
    audio_count: int
    total_duration_ms: int
    quality_score: float  # 0-1
```

---

## Phase 3 : TTSService avec Clonage

### 3.1 Service TTS

**Fichier**: `services/translator/src/services/tts_service.py`

```python
"""
Service TTS avec support du clonage vocal - Singleton
GÃ©nÃ¨re des audios dans la voix de l'Ã©metteur original
"""

class TTSService:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        self.tts_model = None  # XTTS ou Coqui TTS
        self.output_dir = Path("outputs/audio")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.is_initialized = False

    async def initialize(self) -> bool:
        """Charge le modÃ¨le XTTS"""
        from TTS.api import TTS

        self.tts_model = TTS(
            model_name="tts_models/multilingual/multi-dataset/xtts_v2",
            device=self.device
        )
        self.is_initialized = True
        return True

    async def synthesize_with_voice(
        self,
        text: str,
        voice_model: VoiceModel,
        target_language: str,
        output_format: str = "mp3"
    ) -> TTSResult:
        """
        SynthÃ©tise du texte avec la voix clonÃ©e.

        Args:
            text: Texte Ã  synthÃ©tiser
            voice_model: ModÃ¨le de voix de l'Ã©metteur
            target_language: Langue de sortie
            output_format: Format audio (mp3, wav, ogg)

        Returns:
            TTSResult avec chemin du fichier audio gÃ©nÃ©rÃ©
        """
        start_time = time.time()

        # GÃ©nÃ©rer nom de fichier unique
        output_filename = f"tts_{uuid.uuid4()}.{output_format}"
        output_path = self.output_dir / output_filename

        # Mapper les codes de langue pour XTTS
        xtts_lang = self._map_language_code(target_language)

        # SynthÃ¨se avec voix clonÃ©e
        self.tts_model.tts_to_file(
            text=text,
            speaker_wav=voice_model.embedding,  # Utiliser l'embedding
            language=xtts_lang,
            file_path=str(output_path)
        )

        # Obtenir durÃ©e
        duration_ms = await self._get_audio_duration(output_path)

        processing_time = int((time.time() - start_time) * 1000)

        return TTSResult(
            audio_path=str(output_path),
            audio_url=f"/audio/{output_filename}",
            duration_ms=duration_ms,
            format=output_format,
            language=target_language,
            voice_cloned=True,
            voice_quality=voice_model.quality_score,
            processing_time_ms=processing_time
        )

    def _map_language_code(self, lang: str) -> str:
        """Mappe les codes de langue vers les codes XTTS"""
        mapping = {
            "fr": "fr", "en": "en", "es": "es", "de": "de",
            "pt": "pt", "it": "it", "pl": "pl", "tr": "tr",
            "ru": "ru", "nl": "nl", "cs": "cs", "ar": "ar",
            "zh": "zh-cn", "ja": "ja", "hu": "hu", "ko": "ko"
        }
        return mapping.get(lang, "en")


@dataclass
class TTSResult:
    audio_path: str
    audio_url: str
    duration_ms: int
    format: str
    language: str
    voice_cloned: bool
    voice_quality: float
    processing_time_ms: int
```

---

## Phase 4 : AudioMessagePipeline (Orchestrateur)

### 4.1 Pipeline Principal

**Fichier**: `services/translator/src/services/audio_message_pipeline.py`

```python
"""
Pipeline complet pour le traitement des messages audio.
Orchestre: Transcription â†’ Traduction â†’ Clonage â†’ TTS

Ce pipeline fonctionne de maniÃ¨re AUTONOME (sans Gateway).
"""

class AudioMessagePipeline:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        self.transcription_service = TranscriptionService()
        self.translation_service = get_unified_ml_service()
        self.voice_clone_service = VoiceCloneService()
        self.tts_service = TTSService()
        self.database_service = DatabaseService()
        self.is_initialized = False

    async def initialize(self) -> bool:
        """Initialise tous les services du pipeline"""
        await self.transcription_service.initialize()
        await self.translation_service.initialize()
        await self.voice_clone_service.initialize()
        await self.tts_service.initialize()
        self.is_initialized = True
        return True

    async def process_audio_message(
        self,
        audio_path: str,
        sender_id: str,
        conversation_id: str,
        metadata: Optional[AudioMessageMetadata] = None
    ) -> AudioMessageResult:
        """
        Traite un message audio complet:
        1. Transcription (mobile ou Whisper)
        2. Traduction vers toutes les langues des destinataires
        3. Clonage de la voix de l'Ã©metteur
        4. GÃ©nÃ©ration audio traduit pour chaque langue

        Args:
            audio_path: Chemin vers le fichier audio original
            sender_id: ID de l'utilisateur Ã©metteur
            conversation_id: ID de la conversation
            metadata: MÃ©tadonnÃ©es optionnelles (transcription mobile, langue)

        Returns:
            AudioMessageResult avec original + toutes les traductions audio
        """
        start_time = time.time()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 1: TRANSCRIPTION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info(f"[PIPELINE] Step 1: Transcription for sender {sender_id}")

        transcription = await self.transcription_service.transcribe(
            audio_path=audio_path,
            mobile_transcription=metadata.transcription if metadata else None,
            mobile_language=metadata.language if metadata else None,
            return_timestamps=True
        )

        logger.info(f"[PIPELINE] Transcribed: '{transcription.text[:50]}...' (lang: {transcription.language})")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 2: RÃ‰CUPÃ‰RER LES LANGUES DESTINATAIRES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info(f"[PIPELINE] Step 2: Fetching target languages for conversation {conversation_id}")

        target_languages = await self._get_target_languages(
            conversation_id=conversation_id,
            source_language=transcription.language,
            sender_id=sender_id
        )

        logger.info(f"[PIPELINE] Target languages: {target_languages}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 3: CLONAGE VOCAL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info(f"[PIPELINE] Step 3: Voice cloning for sender {sender_id}")

        voice_model = await self.voice_clone_service.get_or_create_voice_model(
            user_id=sender_id,
            current_audio_path=audio_path,
            current_audio_duration_ms=transcription.duration_ms
        )

        logger.info(f"[PIPELINE] Voice model ready: quality={voice_model.quality_score:.2f}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 4: TRADUCTION + TTS POUR CHAQUE LANGUE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        translations = {}

        for target_lang in target_languages:
            logger.info(f"[PIPELINE] Step 4: Processing language {target_lang}")

            # 4a. Traduire le texte
            translation_result = await self.translation_service.translate_with_structure(
                text=transcription.text,
                source_language=transcription.language,
                target_language=target_lang,
                model_type="medium",  # QualitÃ© moyenne pour messages audio
                source_channel="audio_pipeline"
            )

            translated_text = translation_result.get('translated_text', transcription.text)

            # 4b. GÃ©nÃ©rer audio avec voix clonÃ©e
            tts_result = await self.tts_service.synthesize_with_voice(
                text=translated_text,
                voice_model=voice_model,
                target_language=target_lang,
                output_format="mp3"
            )

            translations[target_lang] = TranslatedAudioVersion(
                language=target_lang,
                text=translated_text,
                audio_path=tts_result.audio_path,
                audio_url=tts_result.audio_url,
                duration_ms=tts_result.duration_ms,
                voice_cloned=True,
                voice_quality=voice_model.quality_score
            )

            logger.info(f"[PIPELINE] Generated {target_lang}: '{translated_text[:30]}...'")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 5: SAUVEGARDER EN BASE DE DONNÃ‰ES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        await self._save_to_database(
            sender_id=sender_id,
            conversation_id=conversation_id,
            transcription=transcription,
            translations=translations
        )

        processing_time = int((time.time() - start_time) * 1000)

        return AudioMessageResult(
            original=OriginalAudio(
                audio_path=audio_path,
                transcription=transcription.text,
                language=transcription.language,
                duration_ms=transcription.duration_ms,
                confidence=transcription.confidence,
                source=transcription.source
            ),
            translations=translations,
            voice_model_quality=voice_model.quality_score,
            processing_time_ms=processing_time
        )

    async def _get_target_languages(
        self,
        conversation_id: str,
        source_language: str,
        sender_id: str
    ) -> List[str]:
        """
        RÃ©cupÃ¨re les langues de destination uniques de tous les membres.
        Exclut la langue source si c'est la mÃªme.
        """
        members = await self.database_service.prisma.conversationmember.find_many(
            where={
                "conversationId": conversation_id,
                "userId": {"not": sender_id},  # Exclure l'Ã©metteur
                "isActive": True
            },
            include={"user": True}
        )

        languages = set()
        for member in members:
            user = member.user
            # PrioritÃ©: customDestinationLanguage > systemLanguage
            if user.useCustomDestination and user.customDestinationLanguage:
                languages.add(user.customDestinationLanguage)
            elif user.translateToSystemLanguage:
                languages.add(user.systemLanguage)
            elif user.translateToRegionalLanguage:
                languages.add(user.regionalLanguage)

        # Exclure la langue source
        languages.discard(source_language)

        return list(languages) if languages else [source_language]


@dataclass
class AudioMessageMetadata:
    """MÃ©tadonnÃ©es fournies par le client mobile"""
    transcription: Optional[str] = None  # Transcription faite sur mobile
    language: Optional[str] = None       # Langue dÃ©tectÃ©e par mobile

@dataclass
class OriginalAudio:
    audio_path: str
    transcription: str
    language: str
    duration_ms: int
    confidence: float
    source: str  # "mobile" ou "whisper"

@dataclass
class TranslatedAudioVersion:
    language: str
    text: str
    audio_path: str
    audio_url: str
    duration_ms: int
    voice_cloned: bool
    voice_quality: float

@dataclass
class AudioMessageResult:
    original: OriginalAudio
    translations: Dict[str, TranslatedAudioVersion]
    voice_model_quality: float
    processing_time_ms: int
```

---

## Phase 5 : API FastAPI (Autonome)

### 5.1 Routes Audio

**Fichier**: `services/translator/src/api/audio_api.py`

```python
"""
API REST pour le traitement audio.
Le Translator fonctionne de maniÃ¨re autonome.
"""

from fastapi import APIRouter, File, UploadFile, Form, HTTPException
from fastapi.responses import FileResponse
import uuid
from pathlib import Path

router = APIRouter(prefix="/audio", tags=["Audio"])

UPLOAD_DIR = Path("uploads/audio")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

@router.post("/process-message")
async def process_audio_message(
    audio: UploadFile = File(...),
    sender_id: str = Form(...),
    conversation_id: str = Form(...),
    mobile_transcription: Optional[str] = Form(None),
    mobile_language: Optional[str] = Form(None)
) -> AudioMessageResponse:
    """
    Traite un message audio complet:
    - Transcription (mobile ou Whisper)
    - Traduction vers les langues des destinataires
    - Clonage vocal + TTS

    Ce endpoint est AUTONOME et ne nÃ©cessite pas le Gateway.
    """
    # Sauvegarder le fichier audio
    audio_filename = f"{uuid.uuid4()}_{audio.filename}"
    audio_path = UPLOAD_DIR / audio_filename

    with open(audio_path, "wb") as f:
        content = await audio.read()
        f.write(content)

    # PrÃ©parer les mÃ©tadonnÃ©es
    metadata = AudioMessageMetadata(
        transcription=mobile_transcription,
        language=mobile_language
    ) if mobile_transcription else None

    # Traiter via le pipeline
    pipeline = AudioMessagePipeline()
    result = await pipeline.process_audio_message(
        audio_path=str(audio_path),
        sender_id=sender_id,
        conversation_id=conversation_id,
        metadata=metadata
    )

    return AudioMessageResponse.from_result(result)


@router.post("/transcribe")
async def transcribe_audio(
    audio: UploadFile = File(...),
    language: Optional[str] = Form(None),
    return_timestamps: bool = Form(False)
) -> TranscriptionResponse:
    """
    Transcrit un fichier audio (endpoint autonome).
    Compatible avec l'API OpenAI Whisper.
    """
    # Sauvegarder le fichier
    audio_path = UPLOAD_DIR / f"transcribe_{uuid.uuid4()}.wav"
    with open(audio_path, "wb") as f:
        f.write(await audio.read())

    # Transcrire
    service = TranscriptionService()
    result = await service.transcribe(
        audio_path=str(audio_path),
        return_timestamps=return_timestamps
    )

    # Nettoyer
    audio_path.unlink()

    return TranscriptionResponse(
        text=result.text,
        language=result.language,
        confidence=result.confidence,
        duration_ms=result.duration_ms,
        segments=result.segments if return_timestamps else None
    )


@router.post("/tts")
async def text_to_speech(
    text: str = Form(...),
    language: str = Form("en"),
    user_id: Optional[str] = Form(None),  # Pour utiliser la voix clonÃ©e
    format: str = Form("mp3")
) -> FileResponse:
    """
    SynthÃ¨se vocale (endpoint autonome).
    Si user_id fourni, utilise la voix clonÃ©e de l'utilisateur.
    """
    tts_service = TTSService()

    if user_id:
        # Avec clonage vocal
        voice_service = VoiceCloneService()
        voice_model = await voice_service.get_or_create_voice_model(
            user_id=user_id,
            current_audio_path=None,  # Utiliser le cache
            current_audio_duration_ms=0
        )
        result = await tts_service.synthesize_with_voice(
            text=text,
            voice_model=voice_model,
            target_language=language,
            output_format=format
        )
    else:
        # Sans clonage (voix par dÃ©faut)
        result = await tts_service.synthesize(
            text=text,
            language=language,
            output_format=format
        )

    return FileResponse(
        result.audio_path,
        media_type=f"audio/{format}",
        filename=f"tts_{language}.{format}"
    )


@router.get("/voice-models/{user_id}")
async def get_voice_model_info(user_id: str) -> VoiceModelInfo:
    """
    Retourne les informations sur le modÃ¨le de voix d'un utilisateur.
    """
    service = VoiceCloneService()
    model = await service._load_cached_model(user_id)

    if not model:
        raise HTTPException(status_code=404, detail="Voice model not found")

    return VoiceModelInfo(
        user_id=model.user_id,
        quality_score=model.quality_score,
        audio_count=model.audio_count,
        total_duration_ms=model.total_duration_ms,
        created_at=model.created_at,
        updated_at=model.updated_at,
        age_days=(datetime.now() - model.updated_at).days
    )


@router.post("/voice-models/{user_id}/recalibrate")
async def recalibrate_voice_model(user_id: str) -> VoiceModelInfo:
    """
    Force la recalibration du modÃ¨le de voix d'un utilisateur.
    """
    service = VoiceCloneService()

    # RÃ©cupÃ©rer les audios rÃ©cents
    recent_audios = await service._get_user_audio_history(user_id)

    if not recent_audios:
        raise HTTPException(status_code=400, detail="No audio history found")

    # RecrÃ©er le modÃ¨le
    model = await service._create_voice_model(
        user_id=user_id,
        audio_paths=recent_audios,
        total_duration_ms=await service._calculate_total_duration(recent_audios)
    )

    return VoiceModelInfo(
        user_id=model.user_id,
        quality_score=model.quality_score,
        audio_count=model.audio_count,
        total_duration_ms=model.total_duration_ms,
        created_at=model.created_at,
        updated_at=model.updated_at,
        age_days=0
    )
```

---

## Phase 6 : ModÃ¨les Base de DonnÃ©es

### 6.1 Nouveaux ModÃ¨les Prisma

**Ã€ ajouter dans `packages/shared/prisma/schema.prisma`**:

```prisma
/// Transcription d'un message audio
model MessageAudioTranscription {
  id                String   @id @default(auto()) @map("_id") @db.ObjectId
  messageId         String   @unique @db.ObjectId

  /// Texte transcrit
  transcribedText   String

  /// Langue dÃ©tectÃ©e
  language          String

  /// Score de confiance (0-1)
  confidence        Float

  /// Source: "mobile" ou "whisper"
  source            String

  /// Segments avec timestamps (JSON)
  segments          Json?

  /// DurÃ©e audio en millisecondes
  audioDurationMs   Int

  /// ModÃ¨le utilisÃ© (si whisper)
  model             String?

  createdAt         DateTime @default(now())

  message           Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)

  @@index([language])
  @@map("message_audio_transcriptions")
}

/// Version audio traduite d'un message (une par langue destinataire)
model MessageTranslatedAudio {
  id                String   @id @default(auto()) @map("_id") @db.ObjectId
  messageId         String   @db.ObjectId

  /// Langue de cette version
  targetLanguage    String

  /// Texte traduit
  translatedText    String

  /// Chemin du fichier audio gÃ©nÃ©rÃ©
  audioPath         String

  /// URL accessible
  audioUrl          String

  /// DurÃ©e en millisecondes
  durationMs        Int

  /// Format audio
  format            String   @default("mp3")

  /// Voix clonÃ©e utilisÃ©e
  voiceCloned       Boolean  @default(true)

  /// QualitÃ© du clonage (0-1)
  voiceQuality      Float

  /// ModÃ¨le TTS utilisÃ©
  ttsModel          String   @default("xtts")

  createdAt         DateTime @default(now())

  message           Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)

  /// Une seule version par message + langue
  @@unique([messageId, targetLanguage])
  @@index([messageId])
  @@index([targetLanguage])
  @@map("message_translated_audios")
}

/// ModÃ¨le de voix clonÃ© d'un utilisateur
model UserVoiceModel {
  id                String   @id @default(auto()) @map("_id") @db.ObjectId
  userId            String   @unique @db.ObjectId

  /// Chemin vers le fichier d'embedding
  embeddingPath     String

  /// Nombre d'audios utilisÃ©s pour l'entraÃ®nement
  audioCount        Int

  /// DurÃ©e totale des audios d'entraÃ®nement (ms)
  totalDurationMs   Int

  /// Score de qualitÃ© (0-1)
  qualityScore      Float

  /// Version du modÃ¨le (incrÃ©mentÃ©e Ã  chaque recalibration)
  version           Int      @default(1)

  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt

  /// Prochaine recalibration prÃ©vue
  nextRecalibrationAt DateTime?

  user              User     @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@index([updatedAt])
  @@map("user_voice_models")
}
```

### 6.2 Mise Ã  jour du Message Model

```prisma
model Message {
  // ... champs existants ...

  // Nouvelles relations pour audio
  audioTranscription    MessageAudioTranscription?
  translatedAudios      MessageTranslatedAudio[]
}

model User {
  // ... champs existants ...

  // Relation vers le modÃ¨le de voix
  voiceModel            UserVoiceModel?
}
```

---

## Phase 7 : Configuration & Environnement

### 7.1 Variables d'Environnement

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRANSCRIPTION (Whisper)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WHISPER_MODEL=large-v3          # tiny, base, small, medium, large, large-v3
WHISPER_DEVICE=cpu              # cpu, cuda
WHISPER_COMPUTE_TYPE=float16    # float16, float32, int8

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLONAGE VOCAL (OpenVoice)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VOICE_CLONE_DEVICE=cpu          # cpu, cuda
VOICE_MODEL_CACHE_DIR=/app/voice_models
VOICE_MODEL_MAX_AGE_DAYS=30     # Recalibration mensuelle
VOICE_MIN_DURATION_MS=10000     # DurÃ©e min pour clonage (10s)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TTS (XTTS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
TTS_DEVICE=cpu                  # cpu, cuda
TTS_OUTPUT_DIR=/app/outputs/audio
TTS_DEFAULT_FORMAT=mp3

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUDIO GÃ‰NÃ‰RAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AUDIO_UPLOAD_DIR=/app/uploads/audio
AUDIO_MAX_SIZE_MB=50
AUDIO_SUPPORTED_FORMATS=mp3,wav,ogg,m4a,webm,flac
```

---

## Checklist d'ImplÃ©mentation

### Phase 1 - TranscriptionService
- [ ] CrÃ©er `transcription_service.py` (Singleton, Whisper)
- [ ] Support des mÃ©tadonnÃ©es mobiles
- [ ] Tests unitaires transcription

### Phase 2 - VoiceCloneService
- [ ] CrÃ©er `voice_clone_service.py` (OpenVoice)
- [ ] ImplÃ©menter cache modÃ¨les de voix
- [ ] Logique d'agrÃ©gation des audios
- [ ] AmÃ©lioration continue du modÃ¨le
- [ ] TÃ¢che de recalibration mensuelle
- [ ] Tests unitaires clonage

### Phase 3 - TTSService
- [ ] CrÃ©er `tts_service.py` (XTTS)
- [ ] SynthÃ¨se avec voix clonÃ©e
- [ ] Tests unitaires TTS

### Phase 4 - AudioMessagePipeline
- [ ] CrÃ©er `audio_message_pipeline.py`
- [ ] Orchestrer les 4 Ã©tapes
- [ ] Gestion des langues destinataires
- [ ] Tests d'intÃ©gration pipeline

### Phase 5 - API FastAPI
- [ ] CrÃ©er `audio_api.py` avec routes
- [ ] IntÃ©grer dans `main.py`
- [ ] Documentation OpenAPI

### Phase 6 - Base de DonnÃ©es
- [ ] Ajouter modÃ¨les Prisma
- [ ] GÃ©nÃ©rer client (`pnpm db:generate`)
- [ ] Tests BDD

### Phase 7 - Docker & DÃ©ploiement
- [ ] Mettre Ã  jour Dockerfile (FFmpeg, dÃ©pendances)
- [ ] Configurer volumes audio
- [ ] Tests environnement Docker

---

## DÃ©pendances Python

**Ã€ ajouter dans `requirements.txt`**:

```
# Transcription
faster-whisper==1.0.0

# Clonage Vocal
openvoice @ git+https://github.com/myshell-ai/OpenVoice.git

# TTS
TTS==0.22.0

# Audio Processing
pydub==0.25.1
ffmpeg-python==0.2.0
scipy==1.11.4
librosa==0.10.0
soundfile==0.12.1
```

---

## Estimation de ComplexitÃ©

| Composant | ComplexitÃ© | PrioritÃ© | Effort |
|-----------|------------|----------|--------|
| TranscriptionService | Moyenne | P1 | 2j |
| VoiceCloneService | Haute | P1 | 4j |
| TTSService | Moyenne | P1 | 2j |
| AudioMessagePipeline | Haute | P1 | 3j |
| API FastAPI | Basse | P2 | 1j |
| ModÃ¨les Prisma | Basse | P1 | 0.5j |
| Tests | Moyenne | P2 | 2j |
| Docker | Basse | P3 | 1j |

**Total estimÃ©: ~15 jours de dÃ©veloppement**
