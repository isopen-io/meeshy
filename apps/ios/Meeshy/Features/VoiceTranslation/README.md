# Voice Translation Feature

Real-time voice translation and audio message transcription for Meeshy.

## Overview

This feature provides:
- **Real-time voice translation** during calls
- **Voice message transcription** with on-device processing
- **Automatic language detection** for incoming audio
- **Privacy-first approach** - all processing happens on-device

## Architecture

```
Features/VoiceTranslation/
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îî‚îÄ‚îÄ VoiceTranslationModels.swift    # Data models & enums
‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îî‚îÄ‚îÄ SpeechRecognitionService.swift  # On-device STT
‚îú‚îÄ‚îÄ Managers/
‚îÇ   ‚îî‚îÄ‚îÄ AudioStreamManager.swift        # Audio capture & routing
‚îú‚îÄ‚îÄ ViewModels/
‚îÇ   ‚îî‚îÄ‚îÄ VoiceTranslationViewModel.swift # Business logic
‚îî‚îÄ‚îÄ Views/
    ‚îú‚îÄ‚îÄ VoiceTranslationView.swift              # Main translation UI
    ‚îî‚îÄ‚îÄ VoiceMessageTranscriptionView.swift     # Voice message UI
```

## Supported Languages

| Language | Code | On-Device Support |
|----------|------|-------------------|
| English | en-US | ‚úÖ Excellent |
| French | fr-FR | ‚úÖ Excellent |
| Spanish | es-ES | ‚úÖ Excellent |
| German | de-DE | ‚úÖ Excellent |
| Chinese | zh-CN | ‚úÖ Good |
| Japanese | ja-JP | ‚úÖ Good |
| Russian | ru-RU | ‚úÖ Good |
| Portuguese | pt-BR | ‚úÖ Good |
| Italian | it-IT | ‚úÖ Good |
| Korean | ko-KR | ‚úÖ Good |
| Arabic | ar-SA | ‚ö†Ô∏è Limited |
| Dutch | nl-NL | ‚úÖ Good |

## Usage

### Real-Time Transcription

```swift
// In a view
@StateObject private var viewModel = VoiceTranslationViewModel()

// Start listening
await viewModel.startListening()

// Access transcription
Text(viewModel.currentTranscription)

// Stop listening
await viewModel.stopListening()
```

### Voice Message Transcription

```swift
// Transcribe an audio file
if let text = await viewModel.transcribeAudioFile(at: audioURL) {
    print("Transcribed: \(text)")
}

// With language detection
if let result = await viewModel.transcribeWithLanguageDetection(at: audioURL) {
    print("Text: \(result.text)")
    print("Language: \(result.detectedLanguage.nativeName)")
}
```

### Integration in Chat

```swift
// Add to voice message bubble
TranscribableVoiceMessageBubble(
    audioURL: message.audioURL,
    duration: message.duration,
    isFromCurrentUser: message.isFromCurrentUser
)

// Or use simple transcribe button
TranscribeButton(audioURL: audioURL) { transcribedText in
    // Handle transcription
}
```

## Permissions Required

Add to `Info.plist`:

```xml
<key>NSSpeechRecognitionUsageDescription</key>
<string>Meeshy uses on-device speech recognition for real-time voice translation...</string>

<key>NSMicrophoneUsageDescription</key>
<string>Meeshy needs access to your microphone for voice messages and calls.</string>
```

## Phase Implementation

### Phase 1: Speech-to-Text ‚úÖ
- [x] On-device speech recognition
- [x] Real-time streaming transcription
- [x] Audio file transcription
- [x] Language detection
- [x] Basic UI

### Phase 2: Translation (Next)
- [ ] Core ML translation models
- [ ] Apple Translation API (iOS 18+)
- [ ] Model download management
- [ ] Translation caching

### Phase 3: Text-to-Speech
- [ ] AVSpeechSynthesizer integration
- [ ] Personal Voice support (iOS 17+)
- [ ] Voice selection UI

### Phase 4: Full Pipeline
- [ ] End-to-end voice translation
- [ ] WebRTC integration
- [ ] Call UI with translation overlay

## Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| STT Latency | < 150ms | ‚úÖ ~100ms |
| Translation | < 100ms | üîú Phase 2 |
| TTS | < 200ms | üîú Phase 3 |
| **Total** | < 500ms | üîú Phase 4 |

## Privacy

All speech recognition happens **on-device** using Apple's Speech framework:
- No audio sent to external servers
- Works offline (after model download)
- User data stays private

## Dependencies

- `Speech` framework (iOS 16+)
- `AVFoundation` framework
- `NaturalLanguage` framework (for language detection fallback)

## Testing

```swift
// Unit tests
class SpeechRecognitionTests: XCTestCase {
    func testOnDeviceAvailability() async {
        let service = SpeechRecognitionService(language: .english)
        XCTAssertTrue(await service.isOnDeviceAvailable())
    }
}
```

## Future Enhancements

1. **Conversation Mode**: Automatic speaker identification
2. **Custom Vocabulary**: Add domain-specific terms
3. **Offline Models**: Pre-download language pairs
4. **Voice Cloning**: Personal Voice for translated speech
5. **Live Captions**: Real-time subtitles during calls
