# Correctifs - PrÃ©servation des segments de transcription via SocketIO

## ğŸ¯ Objectif

PrÃ©server la structure complÃ¨te des segments de transcription depuis la base de donnÃ©es jusqu'au frontend via les Ã©vÃ©nements SocketIO, pour permettre la synchronisation audio/texte en temps rÃ©el.

---

## ğŸ“‹ Modifications apportÃ©es

### 1. âœ… Type TypeScript `AudioTranslationReadyEventData`

**Fichier:** `packages/shared/types/socketio-events.ts` (ligne 243-274)

**AVANT:**
```typescript
export interface AudioTranslationReadyEventData {
  readonly messageId: string;
  readonly attachmentId: string;
  readonly conversationId: string;
  readonly transcription?: {
    readonly text: string;
    readonly language: string;
    readonly confidence?: number;
    // âŒ PAS DE SEGMENTS
  };
  readonly translatedAudios: readonly TranslatedAudioData[];
  readonly processingTimeMs?: number;
}
```

**APRÃˆS:**
```typescript
// Import TranscriptionSegment for real-time audio synchronization
import type { TranscriptionSegment } from './attachment-transcription.js';

/**
 * DonnÃ©es pour l'Ã©vÃ©nement de traduction audio prÃªte
 * Inclut les segments de transcription pour synchronisation audio/texte en temps rÃ©el
 */
export interface AudioTranslationReadyEventData {
  readonly messageId: string;
  readonly attachmentId: string;
  readonly conversationId: string;
  readonly transcription?: {
    readonly text: string;
    readonly language: string;
    readonly confidence?: number;
    readonly durationMs?: number;
    readonly source?: string;
    readonly model?: string;
    /**
     * Segments de transcription avec timestamps pour synchronisation audio/texte
     * DivisÃ©s en morceaux de 1-5 mots pour synchronisation fine
     */
    readonly segments?: readonly TranscriptionSegment[];
  };
  readonly translatedAudios: readonly TranslatedAudioData[];
  readonly processingTimeMs?: number;
}
```

**Changements:**
- âœ… Import de `TranscriptionSegment`
- âœ… Ajout du champ `segments`
- âœ… Ajout des mÃ©tadonnÃ©es: `durationMs`, `source`, `model`
- âœ… Documentation explicite pour la synchronisation

---

### 2. âœ… Type du handler `_handleAudioTranslationReady`

**Fichier:** `services/gateway/src/socketio/MeeshySocketIOManager.ts` (ligne 1515-1530)

**AVANT:**
```typescript
private async _handleAudioTranslationReady(data: {
  taskId: string;
  messageId: string;
  attachmentId: string;
  transcription?: {
    text: string;
    language: string;
    confidence?: number;
    // âŒ PAS DE SEGMENTS
  };
  translatedAudios: TranslatedAudioData[];
  processingTimeMs?: number;
}) {
```

**APRÃˆS:**
```typescript
/**
 * GÃ¨re la rÃ©ception d'une traduction audio prÃªte depuis le Translator
 * Diffuse l'Ã©vÃ©nement AUDIO_TRANSLATION_READY aux clients de la conversation
 * Utilise le type TranslatedAudioData unifiÃ© de @meeshy/shared/types
 * Inclut les segments de transcription pour synchronisation audio/texte
 */
private async _handleAudioTranslationReady(data: {
  taskId: string;
  messageId: string;
  attachmentId: string;
  transcription?: {
    text: string;
    language: string;
    confidence?: number;
    durationMs?: number;
    source?: string;
    model?: string;
    segments?: Array<{ text: string; startMs: number; endMs: number; confidence?: number }>;
  };
  translatedAudios: TranslatedAudioData[];
  processingTimeMs?: number;
}) {
```

**Changements:**
- âœ… Ajout du champ `segments` avec structure complÃ¨te
- âœ… Ajout des mÃ©tadonnÃ©es: `durationMs`, `source`, `model`
- âœ… Documentation mise Ã  jour

---

### 3. âœ… Logs de debugging amÃ©liorÃ©s

**Fichier:** `services/gateway/src/socketio/MeeshySocketIOManager.ts` (ligne 1539-1542)

**AJOUT:**
```typescript
console.log(`   ğŸ“ Transcription Segments: ${data.transcription.segments?.length || 0} segments`);
if (data.transcription.segments && data.transcription.segments.length > 0) {
  console.log(`   ğŸ“ Premier segment: "${data.transcription.segments[0].text}" (${data.transcription.segments[0].startMs}ms - ${data.transcription.segments[0].endMs}ms)`);
}
```

**UtilitÃ©:**
- Affiche le nombre de segments dans les logs
- Affiche le premier segment pour vÃ©rification rapide
- Facilite le debugging de la chaÃ®ne complÃ¨te

---

## ğŸ”„ Flux complet de donnÃ©es

### 1. Backend Python (Translator)

```python
# services/translator/src/services/transcription_service.py (ligne 317)

# Diviser en sous-segments de 1-5 mots pour synchronisation fine
segments = split_segments_into_words(segments, max_words=5)

return TranscriptionResult(
    text=full_text,
    language=info.language,
    confidence=info.language_probability,
    segments=segments,  # âœ… Segments divisÃ©s (1-5 mots)
    duration_ms=int(info.duration * 1000),
    source="whisper",
    model="whisper_boost"
)
```

**Segments produits:**
```python
[
    TranscriptionSegment(text="Bonjour comment allez-vous aujourd'hui", startMs=0, endMs=2142),
    TranscriptionSegment(text="mon ami", startMs=2142, endMs=3000)
]
```

---

### 2. Envoi ZMQ vers Gateway

```python
# services/translator/src/services/zmq_audio_handler.py (ligne 440)

'transcription': {
    'text': result.original.text,
    'language': result.original.language,
    'confidence': result.original.confidence,
    'durationMs': result.original.duration_ms,
    'source': result.original.source,
    'segments': result.original.segments  # âœ… Segments envoyÃ©s
}
```

---

### 3. RÃ©ception Gateway et sauvegarde DB

```typescript
// services/gateway/src/services/message-translation/MessageTranslationService.ts (ligne 727, 737)

// Sauvegarde en base de donnÃ©es
await this.prisma.messageAudioTranscription.upsert({
  where: { attachmentId: data.attachmentId },
  update: {
    transcribedText: data.transcription.text,
    language: data.transcription.language,
    confidence: data.transcription.confidence,
    source: data.transcription.source,
    segments: data.transcription.segments || null,  // âœ… Segments sauvegardÃ©s
    audioDurationMs: attachment.duration || 0
  },
  create: {
    attachmentId: data.attachmentId,
    messageId: data.messageId,
    transcribedText: data.transcription.text,
    language: data.transcription.language,
    confidence: data.transcription.confidence,
    source: data.transcription.source,
    segments: data.transcription.segments || null,  // âœ… Segments sauvegardÃ©s
    audioDurationMs: attachment.duration || 0
  }
});
```

---

### 4. Ã‰mission Ã©vÃ©nement SocketIO

```typescript
// services/gateway/src/services/message-translation/MessageTranslationService.ts (ligne 885-892)

this.emit('audioTranslationReady', {
  taskId: data.taskId,
  messageId: data.messageId,
  attachmentId: data.attachmentId,
  transcription: data.transcription,  // âœ… Segments inclus
  translatedAudios: savedTranslatedAudios,
  processingTimeMs: data.processingTimeMs
});
```

---

### 5. Diffusion SocketIO vers clients

```typescript
// services/gateway/src/socketio/MeeshySocketIOManager.ts (ligne 1564-1575)

const audioTranslationData = {
  messageId: data.messageId,
  attachmentId: data.attachmentId,
  conversationId: normalizedId,
  transcription: data.transcription,  // âœ… Segments inclus
  translatedAudios: data.translatedAudios,
  processingTimeMs: data.processingTimeMs
};

this.io.to(roomName).emit(SERVER_EVENTS.AUDIO_TRANSLATION_READY, audioTranslationData);
```

---

### 6. RÃ©ception frontend

```typescript
// apps/web/components/attachments/AudioAttachment.tsx (ligne 22-56)

const initialTranscription = useMemo(() => {
  if (!attachment.transcription) return undefined;

  const transcription = attachment.transcription as any;

  const result = {
    text: transcription.transcribedText || transcription.text,
    language: transcription.language,
    confidence: transcription.confidence,
    segments: transcription.segments,  // âœ… Segments reÃ§us
  };

  if (process.env.NODE_ENV === 'development') {
    console.log('ğŸµ [AudioAttachment] Transcription extraite:', {
      ...result,
      segmentsCount: result.segments?.length || 0,
    });
  }

  return result;
}, [attachment.transcription]);
```

---

## ğŸ“Š Structure des segments

### Format backend (Python)

```python
@dataclass
class TranscriptionSegment:
    text: str
    start_ms: int
    end_ms: int
    confidence: float = 0.0
```

### Format TypeScript (Frontend/Gateway)

```typescript
interface TranscriptionSegment {
  readonly startMs: number;
  readonly endMs: number;
  readonly text: string;
  readonly speakerId?: string;
  readonly confidence?: number;
}
```

### Exemple de donnÃ©es rÃ©elles

```json
{
  "messageId": "msg_abc123",
  "attachmentId": "att_xyz789",
  "conversationId": "conv_def456",
  "transcription": {
    "text": "Bonjour comment allez-vous aujourd'hui mon ami",
    "language": "fr",
    "confidence": 0.95,
    "durationMs": 3000,
    "source": "whisper",
    "model": "whisper_boost",
    "segments": [
      {
        "text": "Bonjour comment allez-vous aujourd'hui",
        "startMs": 0,
        "endMs": 2142,
        "confidence": 0.96
      },
      {
        "text": "mon ami",
        "startMs": 2142,
        "endMs": 3000,
        "confidence": 0.94
      }
    ]
  },
  "translatedAudios": [
    {
      "id": "ta_123",
      "targetLanguage": "en",
      "translatedText": "Hello how are you today my friend",
      "audioUrl": "https://gate.meeshy.me/uploads/translated/audio_en_123.mp3",
      "durationMs": 2800,
      "voiceCloned": true,
      "voiceQuality": 0.87
    }
  ],
  "processingTimeMs": 4523
}
```

---

## âœ… VÃ©rifications

| Ã‰tape | Statut | DÃ©tails |
|-------|--------|---------|
| **Backend Python** | âœ… | GÃ©nÃ¨re segments 1-5 mots |
| **Envoi ZMQ** | âœ… | Envoie segments dans Ã©vÃ©nement |
| **RÃ©ception Gateway** | âœ… | Type inclut segments |
| **Sauvegarde DB** | âœ… | Segments sauvegardÃ©s dans `MessageAudioTranscription.segments` |
| **Ã‰mission SocketIO** | âœ… | Type `AudioTranslationReadyEventData` inclut segments |
| **Frontend** | âœ… | `AudioAttachment` extrait et passe segments |
| **Synchronisation** | âœ… | `TranscriptionViewer` utilise segments pour highlight |

---

## ğŸ¯ RÃ©sultat final

Les segments de transcription sont maintenant prÃ©servÃ©s sur **toute la chaÃ®ne** :

1. **Python Translator** â†’ GÃ©nÃ¨re segments de 1-5 mots
2. **ZMQ** â†’ Envoie segments au Gateway
3. **Gateway DB** â†’ Sauvegarde segments
4. **SocketIO** â†’ Ã‰met segments vers clients
5. **Frontend** â†’ ReÃ§oit et affiche segments synchronisÃ©s

Le frontend peut dÃ©sormais synchroniser l'affichage du texte avec la lecture audio en temps rÃ©el grÃ¢ce aux timestamps prÃ©cis de chaque segment de 1-5 mots ! ğŸµ

---

## ğŸ”§ Logs de debugging

Lors de la rÃ©ception d'une traduction audio, les logs afficheront :

```
ğŸµ [SocketIOManager] ======== DIFFUSION SOCKET.IO VERS CLIENTS ========
ğŸµ [SocketIOManager] Audio translation ready pour message msg_abc123, attachment att_xyz789
   ğŸ“ Has Transcription: true
   ğŸ“ Transcription Text: "Bonjour comment allez-vous aujourd'hui mon ami"
   ğŸ“ Transcription Language: fr
   ğŸ“ Transcription Confidence: 0.95
   ğŸ“ Transcription Segments: 2 segments
   ğŸ“ Premier segment: "Bonjour comment allez-vous aujourd'hui" (0ms - 2142ms)
   ğŸŒ Translated Audios: 1
   ğŸ”Š Langues: en
ğŸ“¡ [SocketIOManager] Ã‰mission Ã©vÃ©nement 'audio:translation-ready' vers room 'conversation_conv_def456' (3 clients)
âœ… [SocketIOManager] ======== Ã‰VÃ‰NEMENT SOCKET.IO DIFFUSÃ‰ ========
âœ… [SocketIOManager] Traduction audio diffusÃ©e vers 3 client(s)
   ğŸ“ Transcription: OUI
   ğŸŒ Audios traduits: 1
```

Ces logs permettent de vÃ©rifier rapidement que les segments sont bien transmis Ã  chaque Ã©tape.
