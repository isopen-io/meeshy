/**
 * ZMQ Request Sender
 * GÃ¨re l'envoi de toutes les requÃªtes vers le service Translator
 *
 * ResponsabilitÃ©s:
 * - Envoi de requÃªtes de traduction
 * - Envoi de requÃªtes de processing audio (avec multipart)
 * - Envoi de requÃªtes de transcription seule
 * - Envoi de requÃªtes Voice API
 * - Envoi de requÃªtes Voice Profile
 * - Gestion du tracking des requÃªtes en cours
 */

import { randomUUID } from 'crypto';
import type { ZmqConnectionManager } from './ZmqConnectionManager';
import { loadAudioAsBinary, audioFormatToMimeType } from './utils/zmq-helpers';
import type {
  TranslationRequest,
  AudioProcessRequest,
  TranscriptionOnlyRequest,
  VoiceAPIRequest,
  VoiceProfileRequest,
  BinaryFrameInfo
} from './types';
import { enhancedLogger } from '../../utils/logger-enhanced';
// Logger dÃ©diÃ© pour ZmqRequestSender
const logger = enhancedLogger.child({ module: 'ZmqRequestSender' });


export interface RequestSenderStats {
  translationRequests: number;
  audioProcessRequests: number;
  transcriptionRequests: number;
  voiceAPIRequests: number;
  voiceProfileRequests: number;
}

export class ZmqRequestSender {
  private connectionManager: ZmqConnectionManager;

  // Cache des requÃªtes en cours (pour traÃ§abilitÃ©)
  private pendingRequests: Map<string, {
    request: any;
    timestamp: number;
  }> = new Map();

  private stats: RequestSenderStats = {
    translationRequests: 0,
    audioProcessRequests: 0,
    transcriptionRequests: 0,
    voiceAPIRequests: 0,
    voiceProfileRequests: 0
  };

  constructor(connectionManager: ZmqConnectionManager) {
    this.connectionManager = connectionManager;
  }

  /**
   * Envoie une requÃªte de traduction
   */
  async sendTranslationRequest(request: TranslationRequest): Promise<string> {
    const taskId = randomUUID();

    // PrÃ©parer le message de commande
    const requestMessage = {
      type: 'translation',  // Type explicite pour routage
      taskId: taskId,
      messageId: request.messageId,
      text: request.text,
      sourceLanguage: request.sourceLanguage,
      targetLanguages: request.targetLanguages,
      conversationId: request.conversationId,
      modelType: request.modelType || 'basic',
      timestamp: Date.now()
    };

    logger.info('ğŸ” PRÃ‰PARATION ENVOI PUSH:');
    logger.info(`   ğŸ“‹ taskId: ${taskId}`);
    logger.info(`   ğŸ“‹ messageId: ${request.messageId}`);
    logger.info(`   ğŸ“‹ text: "${request.text}"`);
    logger.info(`   ğŸ“‹ sourceLanguage: ${request.sourceLanguage}`);
    logger.info(`   ğŸ“‹ targetLanguages: [${request.targetLanguages.join(', ')}]`);
    logger.info(`   ğŸ“‹ conversationId: ${request.conversationId}`);
    logger.info(`   ğŸ¨ modelType: ${requestMessage.modelType}`);
    logger.info(`   ğŸ“‹ message size: ${JSON.stringify(requestMessage).length} chars`);

    // Envoyer la commande via PUSH (garantit distribution Ã©quitable)
    await this.connectionManager.send(requestMessage);

    // Stocker la requÃªte en cours pour traÃ§abilitÃ©
    this.pendingRequests.set(taskId, {
      request: request,
      timestamp: Date.now()
    });

    this.stats.translationRequests++;

    logger.info(`ğŸ“¤ [ZMQ-Client] Commande PUSH envoyÃ©e: taskId=${taskId}, conversationId=${request.conversationId}, langues=${request.targetLanguages.length}, message=${JSON.stringify(requestMessage)}`);

    return taskId;
  }

  /**
   * Envoie une requÃªte de processing audio au service translator.
   * Le translator va:
   * 1. Transcrire l'audio (ou utiliser la transcription mobile)
   * 2. Traduire vers les langues cibles
   * 3. Cloner la voix de l'Ã©metteur
   * 4. GÃ©nÃ©rer des versions audio traduites
   */
  async sendAudioProcessRequest(request: Omit<AudioProcessRequest, 'type'>): Promise<string> {
    // Valider qu'on a une source audio
    if (!request.audioPath) {
      throw new Error('audioPath must be provided');
    }

    const taskId = randomUUID();

    // Charger l'audio en binaire (OBLIGATOIRE - pas de fallback URL)
    const audioData = await loadAudioAsBinary(request.audioPath);
    if (!audioData) {
      throw new Error(`Impossible de charger le fichier audio: ${request.audioPath}`);
    }

    // PrÃ©parer les frames binaires
    const binaryFrames: Buffer[] = [audioData.buffer];
    const binaryFrameInfo: BinaryFrameInfo = {
      audio: 1,  // L'audio est dans le frame 1 (0-indexed aprÃ¨s le JSON)
      audioMimeType: audioData.mimeType,
      audioSize: audioData.size
    };

    // Extraire et transmettre le voice profile en frame binaire sÃ©parÃ© (si disponible)
    let voiceProfileMetadata: any = undefined;
    if (request.existingVoiceProfile && request.existingVoiceProfile.embedding) {
      try {
        // DÃ©coder l'embedding base64 en Buffer binaire
        const embeddingBuffer = Buffer.from(request.existingVoiceProfile.embedding, 'base64');

        // Ajouter le frame binaire du profil vocal (Frame 2)
        binaryFrames.push(embeddingBuffer);
        binaryFrameInfo.voiceProfile = 2;  // Le profil vocal est dans le frame 2
        binaryFrameInfo.voiceProfileSize = embeddingBuffer.length;

        // CrÃ©er les mÃ©tadonnÃ©es du profil SANS l'embedding (qui est dans le frame binaire)
        voiceProfileMetadata = {
          profileId: request.existingVoiceProfile.profileId,
          userId: request.existingVoiceProfile.userId,
          qualityScore: request.existingVoiceProfile.qualityScore,
          // L'embedding est transmis en frame binaire, pas dans le JSON
        };

        logger.info(`   ğŸ™ï¸ Voice profile transmis en multipart: frame 2 (${embeddingBuffer.length} bytes)`);
      } catch (error) {
        logger.error('âš ï¸ Erreur dÃ©codage voice profile, ignorÃ©', error);
      }
    }

    // PrÃ©parer le message de commande audio (SANS chemin ni URL!)
    const requestMessage: AudioProcessRequest = {
      type: 'audio_process',
      messageId: request.messageId,
      attachmentId: request.attachmentId,
      conversationId: request.conversationId,
      senderId: request.senderId,
      // Pas de audioPath, audioUrl, audioBase64 - uniquement binaryFrames
      audioUrl: '',  // Champ requis par interface mais non utilisÃ©
      audioMimeType: audioData.mimeType,
      binaryFrames: binaryFrameInfo,
      audioDurationMs: request.audioDurationMs,
      mobileTranscription: request.mobileTranscription,
      targetLanguages: request.targetLanguages,
      userLanguage: request.userLanguage,  // Langue de l'utilisateur pour la transcription
      generateVoiceClone: request.generateVoiceClone,
      modelType: request.modelType,
      // Champs voice profile (mÃ©tadonnÃ©es seulement, embedding dans frame binaire)
      originalSenderId: request.originalSenderId,
      existingVoiceProfile: voiceProfileMetadata,  // MÃ©tadonnÃ©es uniquement (sans embedding)
      useOriginalVoice: request.useOriginalVoice,
      voiceCloneParams: request.voiceCloneParams,
      // Champs post audio (prÃ©sents uniquement pour les requÃªtes post media)
      postId: request.postId,
      postMediaId: request.postMediaId,
    };

    const transferMode = `multipart binaire (${(audioData.size / 1024).toFixed(1)}KB, ${audioData.mimeType})`;

    logger.info('ğŸ¤ ENVOI AUDIO PROCESS:');
    logger.info(`   ğŸ“‹ taskId: ${taskId}`);
    logger.info(`   ğŸ“‹ messageId: ${request.messageId}`);
    logger.info(`   ğŸ“‹ attachmentId: ${request.attachmentId}`);
    logger.info(`   ğŸ“‹ senderId: ${request.senderId}`);
    logger.info(`   ğŸ“‹ targetLanguages: [${request.targetLanguages.join(', ')}]`);
    logger.info(`   ğŸ“‹ audioDurationMs: ${request.audioDurationMs}`);
    logger.info(`   ğŸ“‹ mobileTranscription: ${request.mobileTranscription ? 'provided' : 'none'}`);
    logger.info(`   ğŸ“‹ transferMode: ${transferMode}`);

    // Envoyer via PUSH en multipart (TOUJOURS)
    await this.connectionManager.sendMultipart(requestMessage, binaryFrames);

    // Stocker la requÃªte en cours pour traÃ§abilitÃ©
    this.pendingRequests.set(taskId, {
      request: requestMessage,
      timestamp: Date.now()
    });

    this.stats.audioProcessRequests++;

    logger.info(`ğŸ“¤ [ZMQ-Client] Audio process PUSH envoyÃ©e: taskId=${taskId}, messageId=${request.messageId}`);

    return taskId;
  }

  /**
   * Envoie une requÃªte de transcription seule au service translator.
   * Retourne uniquement la transcription sans traduction ni TTS.
   *
   * Envoie les donnÃ©es audio en multipart binaire via ZMQ.
   * Supporte deux modes:
   * - Mode fichier: audioPath fourni â†’ charge le fichier
   * - Mode base64: audioData fourni â†’ dÃ©code en Buffer
   */
  async sendTranscriptionOnlyRequest(
    request: Omit<TranscriptionOnlyRequest, 'type' | 'taskId'>
  ): Promise<string> {
    logger.info(`ğŸ” [ZMQ-TRACE] ======== DÃ‰BUT ENVOI TRANSCRIPTION ========`);
    logger.info(`ğŸ” [ZMQ-TRACE] Request params:`);
    logger.info(`   - messageId: ${request.messageId}`);
    logger.info(`   - attachmentId: ${request.attachmentId}`);
    logger.info(`   - audioPath: ${request.audioPath || 'N/A'}`);
    logger.info(`   - audioData (base64): ${request.audioData ? `${request.audioData.substring(0, 50)}...` : 'N/A'}`);
    logger.info(`   - audioFormat: ${request.audioFormat || 'N/A'}`);
    logger.info(`   - mobileTranscription: ${request.mobileTranscription ? 'OUI' : 'NON'}`);

    // Valider qu'on a une source audio (fichier OU base64)
    if (!request.audioPath && !request.audioData) {
      logger.error(`ğŸ” [ZMQ-TRACE] âŒ Aucune source audio fournie`);
      throw new Error('Either audioPath or audioData (base64) must be provided');
    }

    const taskId = randomUUID();
    logger.info(`ğŸ” [ZMQ-TRACE] Task ID gÃ©nÃ©rÃ©: ${taskId}`);

    let audioBuffer: Buffer;
    let mimeType: string;
    let audioSize: number;

    if (request.audioPath) {
      logger.info(`ğŸ” [ZMQ-TRACE] Mode FICHIER: chargement depuis ${request.audioPath}...`);
      // Mode fichier: charger depuis le disque
      const audioData = await loadAudioAsBinary(request.audioPath);
      if (!audioData) {
        logger.error(`ğŸ” [ZMQ-TRACE] âŒ Impossible de charger le fichier`);
        throw new Error(`Impossible de charger le fichier audio: ${request.audioPath}`);
      }
      audioBuffer = audioData.buffer;
      mimeType = audioData.mimeType;
      audioSize = audioData.size;
      logger.info(`ğŸ” [ZMQ-TRACE] âœ… Fichier chargÃ©: ${(audioSize / 1024).toFixed(2)} KB`);
    } else {
      logger.info(`ğŸ” [ZMQ-TRACE] Mode BASE64: dÃ©codage...`);
      // Mode base64: dÃ©coder en Buffer (pas de fichier temporaire)
      audioBuffer = Buffer.from(request.audioData!, 'base64');
      audioSize = audioBuffer.length;

      // DÃ©terminer le mime type depuis audioFormat
      mimeType = audioFormatToMimeType(request.audioFormat || 'wav');
      logger.info(`ğŸ” [ZMQ-TRACE] âœ… Audio dÃ©codÃ©: ${(audioSize / 1024).toFixed(2)} KB, MIME: ${mimeType}`);
    }

    logger.info(`ğŸ” [ZMQ-TRACE] PrÃ©paration frames multipart...`);

    // PrÃ©parer les frames binaires
    const binaryFrames: Buffer[] = [audioBuffer];
    const binaryFrameInfo: BinaryFrameInfo = {
      audio: 1,
      audioMimeType: mimeType,
      audioSize: audioSize
    };

    // PrÃ©parer le message de commande transcription (sans chemin ni URL)
    const requestMessage: TranscriptionOnlyRequest = {
      type: 'transcription_only',
      taskId,
      messageId: request.messageId,
      attachmentId: request.attachmentId,
      audioFormat: mimeType.replace('audio/', ''),
      mobileTranscription: request.mobileTranscription,
      binaryFrames: binaryFrameInfo
    };

    const sourceMode = request.audioPath ? 'fichier' : 'base64';
    const transferMode = `multipart binaire (${(audioSize / 1024).toFixed(1)}KB, ${mimeType}, source: ${sourceMode})`;

    logger.info('ğŸ” [ZMQ-TRACE] Message Ã  envoyer:');
    logger.info(`   - type: ${requestMessage.type}`);
    logger.info(`   - taskId: ${taskId}`);
    logger.info(`   - messageId: ${request.messageId}`);
    logger.info(`   - attachmentId: ${request.attachmentId || 'N/A'}`);
    logger.info(`   - audioFormat: ${requestMessage.audioFormat}`);
    logger.info(`   - binaryFrames.audio: ${binaryFrameInfo.audio}`);
    logger.info(`   - binaryFrames.audioMimeType: ${binaryFrameInfo.audioMimeType}`);
    logger.info(`   - binaryFrames.audioSize: ${binaryFrameInfo.audioSize} bytes`);
    logger.info(`   - transferMode: ${transferMode}`);
    logger.info(`   - mobileTranscription: ${request.mobileTranscription ? 'provided' : 'none'}`);

    logger.info(`ğŸ” [ZMQ-TRACE] Envoi via PUSH multipart...`);
    // Envoyer via PUSH en multipart
    await this.connectionManager.sendMultipart(requestMessage, binaryFrames);

    logger.info(`ğŸ” [ZMQ-TRACE] âœ… Message envoyÃ© avec succÃ¨s`);

    // Stocker la requÃªte en cours pour traÃ§abilitÃ©
    this.pendingRequests.set(taskId, {
      request: requestMessage,
      timestamp: Date.now()
    });

    this.stats.transcriptionRequests++;

    logger.info(`ğŸ” [ZMQ-TRACE] ======== FIN ENVOI TRANSCRIPTION ========`);
    logger.info(`ğŸ“¤ [ZMQ-Client] Transcription only PUSH envoyÃ©e: taskId=${taskId}, messageId=${request.messageId}`);

    return taskId;
  }

  /**
   * Envoie une requÃªte Voice API au service translator.
   * Supporte toutes les opÃ©rations Voice API:
   * - voice_translate / voice_translate_async
   * - voice_analyze / voice_compare
   * - voice_profile_* (CRUD)
   * - voice_feedback / voice_history / voice_stats
   * - voice_admin_metrics / voice_health / voice_languages
   */
  async sendVoiceAPIRequest(request: VoiceAPIRequest): Promise<string> {
    logger.info('ğŸ¤ ENVOI VOICE API REQUEST:');
    logger.info(`   ğŸ“‹ type: ${request.type}`);
    logger.info(`   ğŸ“‹ taskId: ${request.taskId}`);
    logger.info(`   ğŸ“‹ userId: ${request.userId || 'N/A'}`);

    // Envoyer via PUSH
    await this.connectionManager.send(request);

    // Stocker la requÃªte en cours pour traÃ§abilitÃ©
    this.pendingRequests.set(request.taskId, {
      request: request,
      timestamp: Date.now()
    });

    this.stats.voiceAPIRequests++;

    logger.info(`ğŸ“¤ [ZMQ-Client] Voice API request envoyÃ©e: taskId=${request.taskId}, type=${request.type}`);

    return request.taskId;
  }

  /**
   * Send a voice profile request to Translator for audio processing.
   *
   * Supported types:
   * - voice_profile_analyze: Analyze audio for profile creation/update
   * - voice_profile_verify: Verify audio matches existing profile
   * - voice_profile_compare: Compare two fingerprints
   */
  async sendVoiceProfileRequest(request: VoiceProfileRequest): Promise<string> {
    logger.info('ğŸ¤ ENVOI VOICE PROFILE REQUEST:');
    logger.info(`   ğŸ“‹ type: ${request.type}`);
    logger.info(`   ğŸ“‹ request_id: ${request.request_id}`);

    // Envoyer via PUSH
    await this.connectionManager.send(request);

    // Stocker la requÃªte en cours pour traÃ§abilitÃ©
    this.pendingRequests.set(request.request_id, {
      request: request,
      timestamp: Date.now()
    });

    this.stats.voiceProfileRequests++;

    logger.info(`ğŸ“¤ [ZMQ-Client] Voice Profile request envoyÃ©e: request_id=${request.request_id}, type=${request.type}`);

    return request.request_id;
  }

  /**
   * Retire une requÃªte du cache des requÃªtes en cours
   */
  removePendingRequest(taskId: string): void {
    this.pendingRequests.delete(taskId);
  }

  /**
   * RÃ©cupÃ¨re le nombre de requÃªtes en cours
   */
  getPendingRequestsCount(): number {
    return this.pendingRequests.size;
  }

  /**
   * RÃ©cupÃ¨re les statistiques d'envoi
   */
  getStats(): RequestSenderStats {
    return { ...this.stats };
  }

  /**
   * Nettoie les ressources
   */
  clear(): void {
    this.pendingRequests.clear();
  }
}
