/**
 * ZMQ Request Sender
 * G√®re l'envoi de toutes les requ√™tes vers le service Translator
 *
 * Responsabilit√©s:
 * - Envoi de requ√™tes de traduction
 * - Envoi de requ√™tes de processing audio (avec multipart)
 * - Envoi de requ√™tes de transcription seule
 * - Envoi de requ√™tes Voice API
 * - Envoi de requ√™tes Voice Profile
 * - Gestion du tracking des requ√™tes en cours
 */

import { randomUUID } from 'crypto';
import type { ZmqConnectionManager } from './ZmqConnectionManager';
import { loadAudioAsBinary, audioFormatToMimeType } from './utils/zmq-helpers';
import type {
  TranslationRequest,
  AudioProcessRequest,
  TranscriptionOnlyRequest,
  VoiceAPIRequest,
  VoiceProfileRequest,
  BinaryFrameInfo
} from './types';
import { enhancedLogger } from '../../utils/logger-enhanced';
// Logger d√©di√© pour ZmqRequestSender
const logger = enhancedLogger.child({ module: 'ZmqRequestSender' });


export interface RequestSenderStats {
  translationRequests: number;
  audioProcessRequests: number;
  transcriptionRequests: number;
  voiceAPIRequests: number;
  voiceProfileRequests: number;
}

export class ZmqRequestSender {
  private connectionManager: ZmqConnectionManager;

  // Cache des requ√™tes en cours (pour tra√ßabilit√©)
  private pendingRequests: Map<string, {
    request: any;
    timestamp: number;
  }> = new Map();

  private stats: RequestSenderStats = {
    translationRequests: 0,
    audioProcessRequests: 0,
    transcriptionRequests: 0,
    voiceAPIRequests: 0,
    voiceProfileRequests: 0
  };

  constructor(connectionManager: ZmqConnectionManager) {
    this.connectionManager = connectionManager;
  }

  /**
   * Envoie une requ√™te de traduction
   */
  async sendTranslationRequest(request: TranslationRequest): Promise<string> {
    const taskId = randomUUID();

    // Pr√©parer le message de commande
    const requestMessage = {
      type: 'translation',  // Type explicite pour routage
      taskId: taskId,
      messageId: request.messageId,
      text: request.text,
      sourceLanguage: request.sourceLanguage,
      targetLanguages: request.targetLanguages,
      conversationId: request.conversationId,
      modelType: request.modelType || 'basic',
      timestamp: Date.now()
    };

    logger.info('[GATEWAY] üîç PR√âPARATION ENVOI PUSH:');
    logger.info(`[GATEWAY]    üìã taskId: ${taskId}`);
    logger.info(`[GATEWAY]    üìã messageId: ${request.messageId}`);
    logger.info(`[GATEWAY]    üìã text: "${request.text}"`);
    logger.info(`[GATEWAY]    üìã sourceLanguage: ${request.sourceLanguage}`);
    logger.info(`[GATEWAY]    üìã targetLanguages: [${request.targetLanguages.join(', ')}]`);
    logger.info(`[GATEWAY]    üìã conversationId: ${request.conversationId}`);
    logger.info(`[GATEWAY]    üé® modelType: ${requestMessage.modelType}`);
    logger.info(`[GATEWAY]    üìã message size: ${JSON.stringify(requestMessage).length} chars`);

    // Envoyer la commande via PUSH (garantit distribution √©quitable)
    await this.connectionManager.send(requestMessage);

    // Stocker la requ√™te en cours pour tra√ßabilit√©
    this.pendingRequests.set(taskId, {
      request: request,
      timestamp: Date.now()
    });

    this.stats.translationRequests++;

    logger.info(`[GATEWAY] üì§ [ZMQ-Client] Commande PUSH envoy√©e: taskId=${taskId}, conversationId=${request.conversationId}, langues=${request.targetLanguages.length}, message=${JSON.stringify(requestMessage)}`);

    return taskId;
  }

  /**
   * Envoie une requ√™te de processing audio au service translator.
   * Le translator va:
   * 1. Transcrire l'audio (ou utiliser la transcription mobile)
   * 2. Traduire vers les langues cibles
   * 3. Cloner la voix de l'√©metteur
   * 4. G√©n√©rer des versions audio traduites
   */
  async sendAudioProcessRequest(request: Omit<AudioProcessRequest, 'type'>): Promise<string> {
    // Valider qu'on a une source audio
    if (!request.audioPath) {
      throw new Error('audioPath must be provided');
    }

    const taskId = randomUUID();

    // Charger l'audio en binaire (OBLIGATOIRE - pas de fallback URL)
    const audioData = await loadAudioAsBinary(request.audioPath);
    if (!audioData) {
      throw new Error(`Impossible de charger le fichier audio: ${request.audioPath}`);
    }

    // Pr√©parer les frames binaires
    const binaryFrames: Buffer[] = [audioData.buffer];
    const binaryFrameInfo: BinaryFrameInfo = {
      audio: 1,  // L'audio est dans le frame 1 (0-indexed apr√®s le JSON)
      audioMimeType: audioData.mimeType,
      audioSize: audioData.size
    };

    // Extraire et transmettre le voice profile en frame binaire s√©par√© (si disponible)
    let voiceProfileMetadata: any = undefined;
    if (request.existingVoiceProfile && request.existingVoiceProfile.embedding) {
      try {
        // D√©coder l'embedding base64 en Buffer binaire
        const embeddingBuffer = Buffer.from(request.existingVoiceProfile.embedding, 'base64');

        // Ajouter le frame binaire du profil vocal (Frame 2)
        binaryFrames.push(embeddingBuffer);
        binaryFrameInfo.voiceProfile = 2;  // Le profil vocal est dans le frame 2
        binaryFrameInfo.voiceProfileSize = embeddingBuffer.length;

        // Cr√©er les m√©tadonn√©es du profil SANS l'embedding (qui est dans le frame binaire)
        voiceProfileMetadata = {
          profileId: request.existingVoiceProfile.profileId,
          userId: request.existingVoiceProfile.userId,
          qualityScore: request.existingVoiceProfile.qualityScore,
          // L'embedding est transmis en frame binaire, pas dans le JSON
        };

        logger.info(`[GATEWAY]    üéôÔ∏è Voice profile transmis en multipart: frame 2 (${embeddingBuffer.length} bytes)`);
      } catch (error) {
        logger.error('[GATEWAY] ‚ö†Ô∏è Erreur d√©codage voice profile, ignor√©', error);
      }
    }

    // Pr√©parer le message de commande audio (SANS chemin ni URL!)
    const requestMessage: AudioProcessRequest = {
      type: 'audio_process',
      messageId: request.messageId,
      attachmentId: request.attachmentId,
      conversationId: request.conversationId,
      senderId: request.senderId,
      // Pas de audioPath, audioUrl, audioBase64 - uniquement binaryFrames
      audioUrl: '',  // Champ requis par interface mais non utilis√©
      audioMimeType: audioData.mimeType,
      binaryFrames: binaryFrameInfo,
      audioDurationMs: request.audioDurationMs,
      mobileTranscription: request.mobileTranscription,
      targetLanguages: request.targetLanguages,
      generateVoiceClone: request.generateVoiceClone,
      modelType: request.modelType,
      // Champs voice profile (m√©tadonn√©es seulement, embedding dans frame binaire)
      originalSenderId: request.originalSenderId,
      existingVoiceProfile: voiceProfileMetadata,  // M√©tadonn√©es uniquement (sans embedding)
      useOriginalVoice: request.useOriginalVoice,
      voiceCloneParams: request.voiceCloneParams
    };

    const transferMode = `multipart binaire (${(audioData.size / 1024).toFixed(1)}KB, ${audioData.mimeType})`;

    logger.info('[GATEWAY] üé§ ENVOI AUDIO PROCESS:');
    logger.info(`[GATEWAY]    üìã taskId: ${taskId}`);
    logger.info(`[GATEWAY]    üìã messageId: ${request.messageId}`);
    logger.info(`[GATEWAY]    üìã attachmentId: ${request.attachmentId}`);
    logger.info(`[GATEWAY]    üìã senderId: ${request.senderId}`);
    logger.info(`[GATEWAY]    üìã targetLanguages: [${request.targetLanguages.join(', ')}]`);
    logger.info(`[GATEWAY]    üìã audioDurationMs: ${request.audioDurationMs}`);
    logger.info(`[GATEWAY]    üìã mobileTranscription: ${request.mobileTranscription ? 'provided' : 'none'}`);
    logger.info(`[GATEWAY]    üìã transferMode: ${transferMode}`);

    // Envoyer via PUSH en multipart (TOUJOURS)
    await this.connectionManager.sendMultipart(requestMessage, binaryFrames);

    // Stocker la requ√™te en cours pour tra√ßabilit√©
    this.pendingRequests.set(taskId, {
      request: requestMessage,
      timestamp: Date.now()
    });

    this.stats.audioProcessRequests++;

    logger.info(`[GATEWAY] üì§ [ZMQ-Client] Audio process PUSH envoy√©e: taskId=${taskId}, messageId=${request.messageId}`);

    return taskId;
  }

  /**
   * Envoie une requ√™te de transcription seule au service translator.
   * Retourne uniquement la transcription sans traduction ni TTS.
   *
   * Envoie les donn√©es audio en multipart binaire via ZMQ.
   * Supporte deux modes:
   * - Mode fichier: audioPath fourni ‚Üí charge le fichier
   * - Mode base64: audioData fourni ‚Üí d√©code en Buffer
   */
  async sendTranscriptionOnlyRequest(
    request: Omit<TranscriptionOnlyRequest, 'type' | 'taskId'>
  ): Promise<string> {
    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] ======== D√âBUT ENVOI TRANSCRIPTION ========`);
    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] Request params:`);
    logger.info(`[GATEWAY]    - messageId: ${request.messageId}`);
    logger.info(`[GATEWAY]    - attachmentId: ${request.attachmentId}`);
    logger.info(`[GATEWAY]    - audioPath: ${request.audioPath || 'N/A'}`);
    logger.info(`[GATEWAY]    - audioData (base64): ${request.audioData ? `${request.audioData.substring(0, 50)}...` : 'N/A'}`);
    logger.info(`[GATEWAY]    - audioFormat: ${request.audioFormat || 'N/A'}`);
    logger.info(`[GATEWAY]    - mobileTranscription: ${request.mobileTranscription ? 'OUI' : 'NON'}`);

    // Valider qu'on a une source audio (fichier OU base64)
    if (!request.audioPath && !request.audioData) {
      logger.error(`[GATEWAY] üîç [ZMQ-TRACE] ‚ùå Aucune source audio fournie`);
      throw new Error('Either audioPath or audioData (base64) must be provided');
    }

    const taskId = randomUUID();
    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] Task ID g√©n√©r√©: ${taskId}`);

    let audioBuffer: Buffer;
    let mimeType: string;
    let audioSize: number;

    if (request.audioPath) {
      logger.info(`[GATEWAY] üîç [ZMQ-TRACE] Mode FICHIER: chargement depuis ${request.audioPath}...`);
      // Mode fichier: charger depuis le disque
      const audioData = await loadAudioAsBinary(request.audioPath);
      if (!audioData) {
        logger.error(`[GATEWAY] üîç [ZMQ-TRACE] ‚ùå Impossible de charger le fichier`);
        throw new Error(`Impossible de charger le fichier audio: ${request.audioPath}`);
      }
      audioBuffer = audioData.buffer;
      mimeType = audioData.mimeType;
      audioSize = audioData.size;
      logger.info(`[GATEWAY] üîç [ZMQ-TRACE] ‚úÖ Fichier charg√©: ${(audioSize / 1024).toFixed(2)} KB`);
    } else {
      logger.info(`[GATEWAY] üîç [ZMQ-TRACE] Mode BASE64: d√©codage...`);
      // Mode base64: d√©coder en Buffer (pas de fichier temporaire)
      audioBuffer = Buffer.from(request.audioData!, 'base64');
      audioSize = audioBuffer.length;

      // D√©terminer le mime type depuis audioFormat
      mimeType = audioFormatToMimeType(request.audioFormat || 'wav');
      logger.info(`[GATEWAY] üîç [ZMQ-TRACE] ‚úÖ Audio d√©cod√©: ${(audioSize / 1024).toFixed(2)} KB, MIME: ${mimeType}`);
    }

    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] Pr√©paration frames multipart...`);

    // Pr√©parer les frames binaires
    const binaryFrames: Buffer[] = [audioBuffer];
    const binaryFrameInfo: BinaryFrameInfo = {
      audio: 1,
      audioMimeType: mimeType,
      audioSize: audioSize
    };

    // Pr√©parer le message de commande transcription (sans chemin ni URL)
    const requestMessage: TranscriptionOnlyRequest = {
      type: 'transcription_only',
      taskId,
      messageId: request.messageId,
      attachmentId: request.attachmentId,
      audioFormat: mimeType.replace('audio/', ''),
      mobileTranscription: request.mobileTranscription,
      binaryFrames: binaryFrameInfo
    };

    const sourceMode = request.audioPath ? 'fichier' : 'base64';
    const transferMode = `multipart binaire (${(audioSize / 1024).toFixed(1)}KB, ${mimeType}, source: ${sourceMode})`;

    logger.info('[GATEWAY] üîç [ZMQ-TRACE] Message √† envoyer:');
    logger.info(`[GATEWAY]    - type: ${requestMessage.type}`);
    logger.info(`[GATEWAY]    - taskId: ${taskId}`);
    logger.info(`[GATEWAY]    - messageId: ${request.messageId}`);
    logger.info(`[GATEWAY]    - attachmentId: ${request.attachmentId || 'N/A'}`);
    logger.info(`[GATEWAY]    - audioFormat: ${requestMessage.audioFormat}`);
    logger.info(`[GATEWAY]    - binaryFrames.audio: ${binaryFrameInfo.audio}`);
    logger.info(`[GATEWAY]    - binaryFrames.audioMimeType: ${binaryFrameInfo.audioMimeType}`);
    logger.info(`[GATEWAY]    - binaryFrames.audioSize: ${binaryFrameInfo.audioSize} bytes`);
    logger.info(`[GATEWAY]    - transferMode: ${transferMode}`);
    logger.info(`[GATEWAY]    - mobileTranscription: ${request.mobileTranscription ? 'provided' : 'none'}`);

    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] Envoi via PUSH multipart...`);
    // Envoyer via PUSH en multipart
    await this.connectionManager.sendMultipart(requestMessage, binaryFrames);

    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] ‚úÖ Message envoy√© avec succ√®s`);

    // Stocker la requ√™te en cours pour tra√ßabilit√©
    this.pendingRequests.set(taskId, {
      request: requestMessage,
      timestamp: Date.now()
    });

    this.stats.transcriptionRequests++;

    logger.info(`[GATEWAY] üîç [ZMQ-TRACE] ======== FIN ENVOI TRANSCRIPTION ========`);
    logger.info(`[GATEWAY] üì§ [ZMQ-Client] Transcription only PUSH envoy√©e: taskId=${taskId}, messageId=${request.messageId}`);

    return taskId;
  }

  /**
   * Envoie une requ√™te Voice API au service translator.
   * Supporte toutes les op√©rations Voice API:
   * - voice_translate / voice_translate_async
   * - voice_analyze / voice_compare
   * - voice_profile_* (CRUD)
   * - voice_feedback / voice_history / voice_stats
   * - voice_admin_metrics / voice_health / voice_languages
   */
  async sendVoiceAPIRequest(request: VoiceAPIRequest): Promise<string> {
    logger.info('[GATEWAY] üé§ ENVOI VOICE API REQUEST:');
    logger.info(`[GATEWAY]    üìã type: ${request.type}`);
    logger.info(`[GATEWAY]    üìã taskId: ${request.taskId}`);
    logger.info(`[GATEWAY]    üìã userId: ${request.userId || 'N/A'}`);

    // Envoyer via PUSH
    await this.connectionManager.send(request);

    // Stocker la requ√™te en cours pour tra√ßabilit√©
    this.pendingRequests.set(request.taskId, {
      request: request,
      timestamp: Date.now()
    });

    this.stats.voiceAPIRequests++;

    logger.info(`[GATEWAY] üì§ [ZMQ-Client] Voice API request envoy√©e: taskId=${request.taskId}, type=${request.type}`);

    return request.taskId;
  }

  /**
   * Send a voice profile request to Translator for audio processing.
   *
   * Supported types:
   * - voice_profile_analyze: Analyze audio for profile creation/update
   * - voice_profile_verify: Verify audio matches existing profile
   * - voice_profile_compare: Compare two fingerprints
   */
  async sendVoiceProfileRequest(request: VoiceProfileRequest): Promise<string> {
    logger.info('[GATEWAY] üé§ ENVOI VOICE PROFILE REQUEST:');
    logger.info(`[GATEWAY]    üìã type: ${request.type}`);
    logger.info(`[GATEWAY]    üìã request_id: ${request.request_id}`);

    // Envoyer via PUSH
    await this.connectionManager.send(request);

    // Stocker la requ√™te en cours pour tra√ßabilit√©
    this.pendingRequests.set(request.request_id, {
      request: request,
      timestamp: Date.now()
    });

    this.stats.voiceProfileRequests++;

    logger.info(`[GATEWAY] üì§ [ZMQ-Client] Voice Profile request envoy√©e: request_id=${request.request_id}, type=${request.type}`);

    return request.request_id;
  }

  /**
   * Retire une requ√™te du cache des requ√™tes en cours
   */
  removePendingRequest(taskId: string): void {
    this.pendingRequests.delete(taskId);
  }

  /**
   * R√©cup√®re le nombre de requ√™tes en cours
   */
  getPendingRequestsCount(): number {
    return this.pendingRequests.size;
  }

  /**
   * R√©cup√®re les statistiques d'envoi
   */
  getStats(): RequestSenderStats {
    return { ...this.stats };
  }

  /**
   * Nettoie les ressources
   */
  clear(): void {
    this.pendingRequests.clear();
  }
}
