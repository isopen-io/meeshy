"""
Service de Re-transcription LÃ©gÃ¨re
====================================

Re-transcrit les audios traduits et mappe les speakers par timestamps.

Architecture:
1. Re-transcrire l'audio traduit (Whisper sans diarisation)
2. Mapper les speakers en utilisant les timestamps des tours de parole
3. Pas de diarisation nÃ©cessaire (speakers dÃ©jÃ  connus)

Avantages:
- Segments fins avec timestamps exacts
- 30% plus rapide que re-transcription + diarisation
- Speakers garantis cohÃ©rents (pas de dÃ©rive)
- Fallback robuste si Ã©chec
"""

import os
import logging
from typing import List, Dict, Any, Optional, Tuple

logger = logging.getLogger(__name__)


async def retranscribe_translated_audio(
    audio_path: str,
    target_language: str,
    turns_metadata: List[Dict[str, Any]],
    transcription_service=None
) -> List[Dict[str, Any]]:
    """
    Re-transcrit l'audio traduit et mappe les speakers par timestamps.

    OPTIMISATION: Pas de diarisation (inutile, speakers dÃ©jÃ  connus).

    Args:
        audio_path: Chemin audio traduit
        target_language: Langue cible (pour Whisper)
        turns_metadata: MÃ©tadonnÃ©es des tours [
            {
                'start_ms': int,
                'end_ms': int,
                'speaker_id': str,
                'voice_similarity_score': Optional[float]
            },
            ...
        ]
        transcription_service: Service de transcription (injectÃ©)

    Returns:
        Segments fins avec speaker_id et voiceSimilarityScore mappÃ©s
    """
    logger.info(
        f"[RETRANSCRIBE] ğŸ¤ Re-transcription lÃ©gÃ¨re: {target_language}, "
        f"{len(turns_metadata)} tours de parole"
    )

    try:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 1: TRANSCRIPTION PURE (sans diarisation)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if transcription_service is None:
            from ..transcription_service import get_transcription_service
            transcription_service = get_transcription_service()

        # DÃ©sactiver temporairement la diarisation
        original_diarization_setting = os.getenv('ENABLE_DIARIZATION', 'true')
        os.environ['ENABLE_DIARIZATION'] = 'false'

        try:
            result = await transcription_service.transcribe(
                audio_path=audio_path,
                return_timestamps=True
            )
        finally:
            # Restaurer le setting
            os.environ['ENABLE_DIARIZATION'] = original_diarization_setting

        logger.info(
            f"[RETRANSCRIBE] âœ… Transcrit: {len(result.segments)} segments, "
            f"{result.duration_ms}ms"
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 2: MAPPER LES SPEAKERS PAR TIMESTAMPS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        segments_with_speakers = []

        for seg in result.segments:
            # Trouver dans quel tour de parole se trouve ce segment
            segment_mid_ms = (seg.start_ms + seg.end_ms) // 2

            speaker_id = None
            voice_similarity_score = None

            for turn_meta in turns_metadata:
                turn_start = turn_meta['start_ms']
                turn_end = turn_meta['end_ms']

                if turn_start <= segment_mid_ms <= turn_end:
                    speaker_id = turn_meta['speaker_id']
                    voice_similarity_score = turn_meta.get('voice_similarity_score')
                    break

            # Si pas trouvÃ©, utiliser le speaker du tour le plus proche
            if not speaker_id:
                closest_turn = _find_closest_turn(segment_mid_ms, turns_metadata)
                speaker_id = closest_turn['speaker_id']
                voice_similarity_score = closest_turn.get('voice_similarity_score')

            segments_with_speakers.append({
                'text': seg.text,
                'startMs': seg.start_ms,
                'endMs': seg.end_ms,
                'speakerId': speaker_id,
                'voiceSimilarityScore': voice_similarity_score,
                'confidence': seg.confidence
            })

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 3: VALIDATION & STATISTIQUES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        _validate_speaker_mapping(segments_with_speakers, turns_metadata)

        logger.info(
            f"[RETRANSCRIBE] âœ… MappÃ© {len(segments_with_speakers)} segments "
            f"sur {len(turns_metadata)} tours"
        )

        return segments_with_speakers

    except Exception as e:
        logger.error(f"[RETRANSCRIBE] âŒ Erreur re-transcription: {e}")
        import traceback
        traceback.print_exc()

        # Fallback: crÃ©er segments grossiers depuis les tours
        return _create_coarse_segments_from_turns(turns_metadata)


def _find_closest_turn(
    segment_mid_ms: int,
    turns_metadata: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    Trouve le tour le plus proche temporellement.
    Utile pour segments en bordure de tours.
    """
    min_distance = float('inf')
    closest_turn = turns_metadata[0] if turns_metadata else {
        'speaker_id': 's0',
        'voice_similarity_score': None
    }

    for turn_meta in turns_metadata:
        # Distance au centre du tour
        turn_mid = (turn_meta['start_ms'] + turn_meta['end_ms']) // 2
        distance = abs(segment_mid_ms - turn_mid)

        if distance < min_distance:
            min_distance = distance
            closest_turn = turn_meta

    return closest_turn


def _validate_speaker_mapping(
    segments: List[Dict[str, Any]],
    turns_metadata: List[Dict[str, Any]]
) -> None:
    """
    Valide que le mapping des speakers est cohÃ©rent.
    """
    # Compter segments par speaker
    speaker_counts = {}
    for seg in segments:
        speaker_id = seg.get('speakerId', 'unknown')
        speaker_counts[speaker_id] = speaker_counts.get(speaker_id, 0) + 1

    # Compter tours par speaker
    turn_speakers = set(turn['speaker_id'] for turn in turns_metadata)

    logger.info("[RETRANSCRIBE] ğŸ“Š Validation mapping:")
    logger.info(f"  â€¢ Speakers dans tours: {sorted(turn_speakers)}")
    logger.info(f"  â€¢ Speakers dans segments: {sorted(speaker_counts.keys())}")

    for speaker_id, count in speaker_counts.items():
        logger.info(f"  â€¢ {speaker_id}: {count} segments")

    # Warnings si incohÃ©rences
    unmapped_segments = sum(
        1 for seg in segments
        if not seg.get('speakerId') or seg['speakerId'] not in turn_speakers
    )

    if unmapped_segments > 0:
        logger.warning(
            f"[RETRANSCRIBE] âš ï¸  {unmapped_segments}/{len(segments)} segments "
            f"non mappÃ©s ou avec speaker inconnu"
        )


def _create_coarse_segments_from_turns(
    turns_metadata: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    Fallback: crÃ©er segments grossiers (1 par tour) si re-transcription Ã©choue.
    """
    logger.warning("[RETRANSCRIBE] âš ï¸  Fallback: segments grossiers")

    return [
        {
            'text': f"[Tour de parole {i+1}]",
            'startMs': turn_meta['start_ms'],
            'endMs': turn_meta['end_ms'],
            'speakerId': turn_meta['speaker_id'],
            'voiceSimilarityScore': turn_meta.get('voice_similarity_score'),
            'confidence': 0.5,
            'fallback': True
        }
        for i, turn_meta in enumerate(turns_metadata)
    ]
