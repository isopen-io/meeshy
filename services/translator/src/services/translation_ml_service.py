"""
Service de traduction ML unifi√© - REFACTORIS√â
Fa√ßade de compatibilit√© pour l'ancienne API

Architecture modulaire:
- translation_ml/model_loader.py: Gestion des mod√®les ML
- translation_ml/translator_engine.py: Moteur de traduction
- translation_ml/translation_cache.py: Cache Redis
- translation_ml/translation_service.py: Orchestrateur principal

Total: ~290 lignes (vs 1191 lignes God Object original)
"""

import os
import logging
import threading
from typing import Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

# CRITIQUE: Charger les variables d'environnement AVANT tout import
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent.parent.parent / '.env'
    env_local_path = Path(__file__).parent.parent.parent / '.env.local'

    if env_path.exists():
        load_dotenv(env_path)

    if env_local_path.exists():
        load_dotenv(env_local_path, override=True)
        print(f"üîß [ML-SERVICE] .env.local charg√© depuis: {env_local_path}")
except ImportError:
    print("‚ö†Ô∏è [ML-SERVICE] python-dotenv non disponible")

# Import des settings
from config.settings import get_settings

# CRITIQUE: D√©finir les variables d'environnement AVANT d'importer transformers
_settings = get_settings()
os.environ['HF_HOME'] = str(_settings.models_path)
os.environ['TRANSFORMERS_CACHE'] = str(_settings.models_path)
os.environ['HUGGINGFACE_HUB_CACHE'] = str(_settings.models_path)

# Import du module ML refactoris√©
from services.translation_ml import (
    ModelLoader,
    TranslatorEngine,
    TranslationCache,
    TranslationService,
    TranslationResult
)

# Import des d√©pendances ML avec warnings
try:
    import torch
    torch._C._disable_meta = True
    ML_AVAILABLE = True

    import warnings
    warnings.filterwarnings("ignore", message=".*Retry attempt.*")
    warnings.filterwarnings("ignore", message=".*reqwest.*")
    warnings.filterwarnings("ignore", message=".*xethub.*")
except ImportError:
    ML_AVAILABLE = False
    print("‚ö†Ô∏è Dependencies ML non disponibles")

logger = logging.getLogger(__name__)


class TranslationMLService:
    """
    Service de traduction ML unifi√© - Singleton

    REFACTORIS√â: Fa√ßade de compatibilit√© qui d√©l√®gue aux modules sp√©cialis√©s
    Pr√©serve l'API publique existante pour compatibilit√© avec le code existant
    """

    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        """Singleton pattern"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(
        self,
        settings,
        model_type: str = "all",
        max_workers: int = 4,
        quantization_level: str = "float16"
    ):
        """
        Initialise le service ML avec injection de d√©pendances

        Args:
            settings: Configuration du service
            model_type: Type de mod√®le ('all', 'basic', 'premium')
            max_workers: Nombre de workers pour ThreadPoolExecutor
            quantization_level: Niveau de quantification
        """
        if self._initialized:
            return

        self.settings = settings
        self.model_type = model_type

        # Configuration workers CPU multicore
        cpu_workers = min(max_workers, int(os.getenv('ML_MAX_WORKERS', '16')))
        self.max_workers = cpu_workers
        self.quantization_level = quantization_level

        # ThreadPoolExecutor partag√©
        self.executor = ThreadPoolExecutor(max_workers=cpu_workers)

        # REFACTORIS√â: Injection de d√©pendances des modules sp√©cialis√©s
        self.model_loader = ModelLoader(settings, self.executor, quantization_level)
        self.translator_engine = TranslatorEngine(self.model_loader, self.executor)
        self.translation_cache = TranslationCache()
        self.translation_service = TranslationService(
            self.model_loader,
            self.translator_engine,
            self.translation_cache,
            max_workers=cpu_workers
        )

        # Compatibilit√©: Exposer les attributs attendus par l'ancienne API
        self.models = self.model_loader.models
        self.tokenizers = self.model_loader.tokenizers
        self.pipelines = {}  # G√©r√© par TranslatorEngine maintenant
        self.model_configs = self.model_loader.model_configs
        self.lang_codes = self.translator_engine.lang_codes
        self.text_segmenter = self.translation_service.text_segmenter
        self.stats = self.translation_service.stats
        self.request_times = self.translation_service.request_times
        self.is_initialized = False
        self.is_loading = False

        self._initialized = True
        logger.info(f"ü§ñ Service ML Unifi√© cr√©√© (Refactoris√©) avec {cpu_workers} workers")

    async def initialize(self) -> bool:
        """
        Initialise les mod√®les ML
        D√âL√âGATION vers TranslationService.initialize()
        """
        result = await self.translation_service.initialize()

        # Synchroniser l'√©tat
        self.is_initialized = self.translation_service.is_initialized
        self.is_loading = self.translation_service.is_loading

        return result

    async def translate(
        self,
        text: str,
        source_language: str = "auto",
        target_language: str = "en",
        model_type: str = "basic",
        source_channel: str = "unknown"
    ) -> Dict[str, Any]:
        """
        Interface unique de traduction pour tous les canaux
        D√âL√âGATION vers TranslationService.translate()
        """
        return await self.translation_service.translate(
            text, source_language, target_language, model_type, source_channel
        )

    async def translate_with_structure(
        self,
        text: str,
        source_language: str = "auto",
        target_language: str = "en",
        model_type: str = "basic",
        source_channel: str = "unknown"
    ) -> Dict[str, Any]:
        """
        Traduction avec pr√©servation de structure
        D√âL√âGATION vers TranslationService.translate_with_structure()
        """
        return await self.translation_service.translate_with_structure(
            text, source_language, target_language, model_type, source_channel
        )

    async def get_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques globales
        D√âL√âGATION vers TranslationService.get_stats()
        """
        return await self.translation_service.get_stats()

    async def get_health(self) -> Dict[str, Any]:
        """
        Health check du service
        D√âL√âGATION vers TranslationService.get_health()
        """
        return await self.translation_service.get_health()

    async def close(self):
        """
        Ferme proprement le service et lib√®re les ressources
        D√âL√âGATION vers TranslationService.close()
        """
        logger.info("üõë Arr√™t du service ML unifi√© (Refactoris√©)...")

        try:
            # Arr√™ter le ThreadPoolExecutor
            if hasattr(self, 'executor') and self.executor:
                self.executor.shutdown(wait=False)
                logger.info("‚úÖ ThreadPoolExecutor arr√™t√©")

            # D√©l√©guer au service principal
            await self.translation_service.close()

            # Synchroniser l'√©tat
            self.is_initialized = False
            self.is_loading = False

            # R√©initialiser singleton
            self._initialized = False
            TranslationMLService._instance = None

            logger.info("‚úÖ Service ML unifi√© (Refactoris√©) arr√™t√© proprement")

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du service ML: {e}")

    # COMPATIBILIT√â: Propri√©t√©s pour acc√®s direct (utilis√©es par l'ancienne API)
    @property
    def device(self) -> str:
        """Device configur√© (cpu, cuda, mps)"""
        return self.model_loader.device

    @property
    def models_path(self):
        """Chemin vers les mod√®les"""
        return self.model_loader.models_path

    # M√âTHODES PRIV√âES INTERNES (pour compatibilit√© stricte si n√©cessaire)
    # Note: Ces m√©thodes sont maintenant g√©r√©es par les modules, mais on garde
    # les signatures pour compatibilit√© totale

    def _detect_language(self, text: str) -> str:
        """D√©tection de langue - D√âL√âGATION vers TranslatorEngine"""
        return self.translator_engine.detect_language(text)

    async def _ml_translate(
        self,
        text: str,
        source_lang: str,
        target_lang: str,
        model_type: str
    ) -> str:
        """Traduction ML - D√âL√âGATION vers TranslatorEngine"""
        return await self.translator_engine.translate_text(
            text, source_lang, target_lang, model_type
        )

    async def _ml_translate_batch(
        self,
        texts: list,
        source_lang: str,
        target_lang: str,
        model_type: str
    ) -> list:
        """Traduction batch - D√âL√âGATION vers TranslatorEngine"""
        return await self.translator_engine.translate_batch(
            texts, source_lang, target_lang, model_type
        )


# Instance globale du service (Singleton)
def get_unified_ml_service(max_workers: int = 4) -> TranslationMLService:
    """Retourne l'instance unique du service ML refactoris√©"""
    return TranslationMLService(get_settings(), max_workers=max_workers)
