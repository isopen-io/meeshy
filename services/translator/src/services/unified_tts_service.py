"""
Service TTS Unifi√© avec support multi-mod√®les - Singleton
Supporte: Chatterbox (recommand√©), Higgs Audio V2, XTTS (legacy)

Architecture:
- Interface unifi√©e pour tous les mod√®les TTS
- Chargement √† chaud des mod√®les (hot-loading)
- V√©rification de disponibilit√© locale des mod√®les
- T√©l√©chargement en arri√®re-plan si espace disponible
- Fallback automatique sur Chatterbox (mod√®le par d√©faut)
- Alertes automatiques pour les licences commerciales
"""

import os
import logging
import time
import asyncio
import threading
import uuid
import shutil
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field
from pathlib import Path
from enum import Enum
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor

# Configuration du logging
logger = logging.getLogger(__name__)

# Executor pour les op√©rations de t√©l√©chargement en arri√®re-plan
_background_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="tts_download")


class TTSModel(str, Enum):
    """Mod√®les TTS disponibles"""
    CHATTERBOX = "chatterbox"           # Recommand√© - Apache 2.0 (FALLBACK par d√©faut)
    CHATTERBOX_TURBO = "chatterbox-turbo"  # Plus rapide, 350M params
    HIGGS_AUDIO_V2 = "higgs-audio-v2"   # √âtat de l'art - Licence limit√©e
    XTTS_V2 = "xtts-v2"                 # Legacy - Non-commercial

    @classmethod
    def get_default(cls) -> 'TTSModel':
        """Retourne le mod√®le par d√©faut (et fallback)"""
        return cls.CHATTERBOX

    @classmethod
    def get_fallback(cls) -> 'TTSModel':
        """Retourne le mod√®le de fallback"""
        return cls.CHATTERBOX


@dataclass
class TTSModelInfo:
    """Informations sur un mod√®le TTS"""
    name: str
    display_name: str
    license: str
    commercial_use: bool
    license_warning: Optional[str]
    languages: list
    min_audio_seconds: float
    quality_score: int  # 1-100
    speed_score: int    # 1-100
    vram_gb: float
    # Identifiants HuggingFace pour v√©rification locale
    hf_model_id: Optional[str] = None
    model_size_gb: float = 0.0  # Taille approximative du mod√®le


@dataclass
class ModelStatus:
    """Statut d'un mod√®le"""
    model: 'TTSModel'
    is_available: bool          # Package Python install√©
    is_downloaded: bool         # Mod√®le t√©l√©charg√© localement
    is_loaded: bool             # Mod√®le charg√© en m√©moire
    is_downloading: bool        # T√©l√©chargement en cours
    download_progress: float    # Progression du t√©l√©chargement (0-100)
    error: Optional[str] = None


# Informations sur les mod√®les
TTS_MODEL_INFO: Dict[TTSModel, TTSModelInfo] = {
    TTSModel.CHATTERBOX: TTSModelInfo(
        name="chatterbox",
        display_name="Chatterbox (Resemble AI)",
        license="Apache 2.0",
        commercial_use=True,
        license_warning=None,
        languages=["en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "ar", "zh", "ja", "hu", "ko", "hi"],
        min_audio_seconds=3.0,
        quality_score=95,
        speed_score=85,
        vram_gb=4.0,
        hf_model_id="ResembleAI/chatterbox",
        model_size_gb=3.5
    ),
    TTSModel.CHATTERBOX_TURBO: TTSModelInfo(
        name="chatterbox-turbo",
        display_name="Chatterbox Turbo (Resemble AI)",
        license="Apache 2.0",
        commercial_use=True,
        license_warning=None,
        languages=["en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "ar", "zh", "ja", "hu", "ko", "hi"],
        min_audio_seconds=3.0,
        quality_score=90,
        speed_score=95,
        vram_gb=2.0,
        hf_model_id="ResembleAI/chatterbox-turbo",
        model_size_gb=1.5
    ),
    TTSModel.HIGGS_AUDIO_V2: TTSModelInfo(
        name="higgs-audio-v2",
        display_name="Higgs Audio V2 (Boson AI)",
        license="Boson Higgs Audio 2 Community License",
        commercial_use=False,
        license_warning=(
            "‚ö†Ô∏è ALERTE LICENCE HIGGS AUDIO V2 ‚ö†Ô∏è\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "La licence 'Boson Higgs Audio 2 Community License' autorise:\n"
            "  ‚úÖ Usage commercial si < 100,000 utilisateurs actifs annuels\n"
            "  ‚ùå Au-del√† de 100k users ‚Üí licence commerciale OBLIGATOIRE\n"
            "\n"
            "Si vous pr√©voyez de d√©passer ce seuil, contactez Boson AI:\n"
            "  üìß https://www.boson.ai/contact\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        ),
        languages=[
            "en", "es", "fr", "de", "it", "pt", "ru", "zh", "ja", "ko", "ar",
            "hi", "bn", "pa", "ta", "te", "mr", "gu", "kn", "ml", "or",
            "pl", "nl", "sv", "da", "no", "fi", "cs", "sk", "hu", "ro",
            "bg", "uk", "el", "tr", "he", "th", "vi", "id", "ms", "tl",
            "sw", "am", "yo", "ig", "ha", "zu", "af", "fa", "ur"
        ],
        min_audio_seconds=3.0,
        quality_score=98,
        speed_score=75,
        vram_gb=8.0,
        hf_model_id="bosonai/higgs-audio-v2-generation-3B-base",
        model_size_gb=6.0
    ),
    TTSModel.XTTS_V2: TTSModelInfo(
        name="xtts-v2",
        display_name="XTTS v2 (Coqui - Legacy)",
        license="Coqui Public Model License",
        commercial_use=False,
        license_warning=(
            "‚ö†Ô∏è ALERTE LICENCE XTTS V2 ‚ö†Ô∏è\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            "XTTS v2 utilise la 'Coqui Public Model License' qui:\n"
            "  ‚ùå INTERDIT tout usage commercial\n"
            "  ‚úÖ Autorise uniquement usage personnel/recherche\n"
            "\n"
            "Pour un usage commercial, utilisez Chatterbox (Apache 2.0).\n"
            "Note: Coqui a ferm√© en 2024, ce mod√®le n'est plus maintenu.\n"
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        ),
        languages=["en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl", "cs", "ar", "zh", "ja", "hu", "ko"],
        min_audio_seconds=6.0,
        quality_score=75,
        speed_score=70,
        vram_gb=4.0,
        hf_model_id=None,  # XTTS utilise son propre syst√®me de t√©l√©chargement
        model_size_gb=3.0
    ),
}


@dataclass
class UnifiedTTSResult:
    """R√©sultat unifi√© d'une synth√®se TTS"""
    audio_path: str
    audio_url: str
    duration_ms: int
    format: str
    language: str
    voice_cloned: bool
    voice_quality: float
    processing_time_ms: int
    text_length: int
    model_used: TTSModel
    model_info: TTSModelInfo


class BaseTTSBackend(ABC):
    """Interface abstraite pour les backends TTS"""

    def __init__(self):
        self._initialized = False
        self._downloading = False
        self._download_progress = 0.0

    @abstractmethod
    async def initialize(self) -> bool:
        """Initialise le backend (charge le mod√®le)"""
        pass

    @abstractmethod
    async def synthesize(
        self,
        text: str,
        language: str,
        speaker_audio_path: Optional[str] = None,
        output_path: str = None,
        **kwargs
    ) -> str:
        """Synth√©tise le texte et retourne le chemin du fichier audio"""
        pass

    @abstractmethod
    async def close(self):
        """Lib√®re les ressources"""
        pass

    @property
    @abstractmethod
    def is_available(self) -> bool:
        """V√©rifie si le package Python est install√©"""
        pass

    @abstractmethod
    def is_model_downloaded(self) -> bool:
        """V√©rifie si le mod√®le est t√©l√©charg√© localement"""
        pass

    @abstractmethod
    async def download_model(self) -> bool:
        """T√©l√©charge le mod√®le"""
        pass

    @property
    def is_initialized(self) -> bool:
        return self._initialized

    @property
    def is_downloading(self) -> bool:
        return self._downloading

    @property
    def download_progress(self) -> float:
        return self._download_progress


class ChatterboxBackend(BaseTTSBackend):
    """Backend Chatterbox (Resemble AI) - MOD√àLE PAR D√âFAUT ET FALLBACK"""

    def __init__(self, device: str = "auto", turbo: bool = False):
        super().__init__()
        self.device = device
        self.turbo = turbo
        self.model = None
        self._available = False
        self._models_path = Path(os.getenv("MODELS_PATH", "/workspace/models"))

        try:
            from chatterbox.tts import ChatterboxTTS
            self._available = True
            logger.info(f"‚úÖ [TTS] Chatterbox {'Turbo' if turbo else ''} package disponible")
        except ImportError:
            logger.warning(f"‚ö†Ô∏è [TTS] Chatterbox {'Turbo' if turbo else ''} package non disponible")

    @property
    def is_available(self) -> bool:
        return self._available

    def is_model_downloaded(self) -> bool:
        """V√©rifie si le mod√®le Chatterbox est t√©l√©charg√©"""
        if not self._available:
            return False

        try:
            from huggingface_hub import try_to_load_from_cache
            model_id = "ResembleAI/chatterbox-turbo" if self.turbo else "ResembleAI/chatterbox"

            # V√©rifier si les fichiers du mod√®le sont en cache
            config_path = try_to_load_from_cache(model_id, "config.json")
            return config_path is not None

        except Exception as e:
            logger.debug(f"[TTS] V√©rification cache Chatterbox: {e}")
            return False

    async def download_model(self) -> bool:
        """T√©l√©charge le mod√®le Chatterbox"""
        if not self._available:
            return False

        self._downloading = True
        self._download_progress = 0.0

        try:
            from huggingface_hub import snapshot_download

            model_id = "ResembleAI/chatterbox-turbo" if self.turbo else "ResembleAI/chatterbox"
            logger.info(f"[TTS] üì• T√©l√©chargement de {model_id}...")

            loop = asyncio.get_event_loop()

            def download():
                return snapshot_download(
                    repo_id=model_id,
                    cache_dir=str(self._models_path / "huggingface"),
                    resume_download=True
                )

            await loop.run_in_executor(_background_executor, download)

            self._download_progress = 100.0
            logger.info(f"[TTS] ‚úÖ {model_id} t√©l√©charg√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[TTS] ‚ùå Erreur t√©l√©chargement Chatterbox: {e}")
            return False

        finally:
            self._downloading = False

    async def initialize(self) -> bool:
        if self._initialized:
            return True

        if not self._available:
            return False

        try:
            from chatterbox.tts import ChatterboxTTS
            import torch

            # D√©terminer le device
            if self.device == "auto":
                device = "cuda" if torch.cuda.is_available() else "cpu"
            else:
                device = self.device

            model_name = "Turbo" if self.turbo else ""
            logger.info(f"[TTS] üîÑ Chargement Chatterbox {model_name}...")

            loop = asyncio.get_event_loop()

            if self.turbo:
                self.model = await loop.run_in_executor(
                    None,
                    lambda: ChatterboxTTS.from_pretrained("ResembleAI/chatterbox-turbo", device=device)
                )
            else:
                self.model = await loop.run_in_executor(
                    None,
                    lambda: ChatterboxTTS.from_pretrained(device=device)
                )

            self._initialized = True
            logger.info(f"‚úÖ [TTS] Chatterbox {model_name} initialis√© sur {device}")
            return True

        except Exception as e:
            logger.error(f"‚ùå [TTS] Erreur initialisation Chatterbox: {e}")
            return False

    async def synthesize(
        self,
        text: str,
        language: str,
        speaker_audio_path: Optional[str] = None,
        output_path: str = None,
        exaggeration: float = 0.5,
        cfg_weight: float = 0.5,
        **kwargs
    ) -> str:
        if not self._initialized:
            await self.initialize()

        if not self.model:
            raise RuntimeError("Chatterbox non initialis√©")

        import torchaudio

        loop = asyncio.get_event_loop()

        # G√©n√©rer l'audio
        if speaker_audio_path and os.path.exists(speaker_audio_path):
            wav = await loop.run_in_executor(
                None,
                lambda: self.model.generate(
                    text,
                    audio_prompt_path=speaker_audio_path,
                    exaggeration=exaggeration,
                    cfg_weight=cfg_weight
                )
            )
        else:
            wav = await loop.run_in_executor(
                None,
                lambda: self.model.generate(text, exaggeration=exaggeration, cfg_weight=cfg_weight)
            )

        # Sauvegarder le fichier
        await loop.run_in_executor(
            None,
            lambda: torchaudio.save(output_path, wav, self.model.sr)
        )

        return output_path

    async def close(self):
        self.model = None
        self._initialized = False


class HiggsAudioBackend(BaseTTSBackend):
    """Backend Higgs Audio V2 (Boson AI)"""

    def __init__(self, device: str = "auto"):
        super().__init__()
        self.device = device
        self.model = None
        self.tokenizer = None
        self._available = False
        self._models_path = Path(os.getenv("MODELS_PATH", "/workspace/models"))

        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            import torchaudio
            self._available = True
            logger.info("‚úÖ [TTS] Higgs Audio V2 package disponible")
        except ImportError:
            logger.warning("‚ö†Ô∏è [TTS] Higgs Audio V2 non disponible (transformers requis)")

    @property
    def is_available(self) -> bool:
        return self._available

    def is_model_downloaded(self) -> bool:
        """V√©rifie si le mod√®le Higgs Audio V2 est t√©l√©charg√©"""
        if not self._available:
            return False

        try:
            from huggingface_hub import try_to_load_from_cache
            model_id = "bosonai/higgs-audio-v2-generation-3B-base"

            config_path = try_to_load_from_cache(model_id, "config.json")
            return config_path is not None

        except Exception as e:
            logger.debug(f"[TTS] V√©rification cache Higgs Audio: {e}")
            return False

    async def download_model(self) -> bool:
        """T√©l√©charge le mod√®le Higgs Audio V2"""
        if not self._available:
            return False

        self._downloading = True
        self._download_progress = 0.0

        try:
            from huggingface_hub import snapshot_download

            model_id = "bosonai/higgs-audio-v2-generation-3B-base"
            logger.info(f"[TTS] üì• T√©l√©chargement de {model_id}...")

            loop = asyncio.get_event_loop()

            def download():
                return snapshot_download(
                    repo_id=model_id,
                    cache_dir=str(self._models_path / "huggingface"),
                    resume_download=True
                )

            await loop.run_in_executor(_background_executor, download)

            self._download_progress = 100.0
            logger.info(f"[TTS] ‚úÖ {model_id} t√©l√©charg√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[TTS] ‚ùå Erreur t√©l√©chargement Higgs Audio: {e}")
            return False

        finally:
            self._downloading = False

    async def initialize(self) -> bool:
        if self._initialized:
            return True

        if not self._available:
            return False

        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            import torch

            # Afficher l'alerte de licence
            model_info = TTS_MODEL_INFO[TTSModel.HIGGS_AUDIO_V2]
            if model_info.license_warning:
                logger.warning(model_info.license_warning)
                print(f"\n{model_info.license_warning}\n")

            # D√©terminer le device
            if self.device == "auto":
                device = "cuda" if torch.cuda.is_available() else "cpu"
            else:
                device = self.device

            logger.info("[TTS] üîÑ Chargement Higgs Audio V2...")

            loop = asyncio.get_event_loop()
            model_name = "bosonai/higgs-audio-v2-generation-3B-base"

            self.tokenizer = await loop.run_in_executor(
                None,
                lambda: AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
            )

            self.model = await loop.run_in_executor(
                None,
                lambda: AutoModelForCausalLM.from_pretrained(
                    model_name,
                    trust_remote_code=True,
                    torch_dtype=torch.float16 if device == "cuda" else torch.float32
                ).to(device)
            )

            self._initialized = True
            logger.info(f"‚úÖ [TTS] Higgs Audio V2 initialis√© sur {device}")
            return True

        except Exception as e:
            logger.error(f"‚ùå [TTS] Erreur initialisation Higgs Audio V2: {e}")
            return False

    async def synthesize(
        self,
        text: str,
        language: str,
        speaker_audio_path: Optional[str] = None,
        output_path: str = None,
        **kwargs
    ) -> str:
        if not self._initialized:
            await self.initialize()

        if not self.model:
            raise RuntimeError("Higgs Audio V2 non initialis√©")

        import torch
        import torchaudio

        loop = asyncio.get_event_loop()

        prompt = text
        if speaker_audio_path and os.path.exists(speaker_audio_path):
            prompt = f"[voice_clone]{text}"

        def generate():
            inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)

            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=2048,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9
                )

            audio_tokens = outputs[0][inputs["input_ids"].shape[1]:]
            audio = self.model.decode_audio(audio_tokens)
            return audio

        audio = await loop.run_in_executor(None, generate)

        await loop.run_in_executor(
            None,
            lambda: torchaudio.save(output_path, audio.unsqueeze(0), 24000)
        )

        return output_path

    async def close(self):
        self.model = None
        self.tokenizer = None
        self._initialized = False


class XTTSBackend(BaseTTSBackend):
    """Backend XTTS v2 (Coqui) - Legacy"""

    def __init__(self, device: str = "auto"):
        super().__init__()
        self.device = device
        self.model = None
        self._available = False

        try:
            from TTS.api import TTS
            self._available = True
            logger.info("‚úÖ [TTS] XTTS v2 package disponible")
        except ImportError:
            logger.warning("‚ö†Ô∏è [TTS] XTTS v2 non disponible")

    @property
    def is_available(self) -> bool:
        return self._available

    def is_model_downloaded(self) -> bool:
        """V√©rifie si XTTS v2 est t√©l√©charg√©"""
        if not self._available:
            return False

        try:
            # XTTS stocke les mod√®les dans un dossier sp√©cifique
            tts_models_path = Path.home() / ".local" / "share" / "tts"
            xtts_path = tts_models_path / "tts_models--multilingual--multi-dataset--xtts_v2"
            return xtts_path.exists()
        except Exception:
            return False

    async def download_model(self) -> bool:
        """T√©l√©charge XTTS v2 (via TTS.api)"""
        if not self._available:
            return False

        self._downloading = True
        self._download_progress = 0.0

        try:
            from TTS.api import TTS

            logger.info("[TTS] üì• T√©l√©chargement de XTTS v2...")

            loop = asyncio.get_event_loop()

            # Le t√©l√©chargement se fait automatiquement lors de l'instanciation
            await loop.run_in_executor(
                None,
                lambda: TTS("tts_models/multilingual/multi-dataset/xtts_v2", progress_bar=True)
            )

            self._download_progress = 100.0
            logger.info("[TTS] ‚úÖ XTTS v2 t√©l√©charg√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[TTS] ‚ùå Erreur t√©l√©chargement XTTS v2: {e}")
            return False

        finally:
            self._downloading = False

    async def initialize(self) -> bool:
        if self._initialized:
            return True

        if not self._available:
            return False

        try:
            from TTS.api import TTS

            # Afficher l'alerte de licence
            model_info = TTS_MODEL_INFO[TTSModel.XTTS_V2]
            if model_info.license_warning:
                logger.warning(model_info.license_warning)
                print(f"\n{model_info.license_warning}\n")

            logger.info("[TTS] üîÑ Chargement XTTS v2 (legacy)...")

            loop = asyncio.get_event_loop()

            self.model = await loop.run_in_executor(
                None,
                lambda: TTS("tts_models/multilingual/multi-dataset/xtts_v2", progress_bar=False).to(self.device)
            )

            self._initialized = True
            logger.info(f"‚úÖ [TTS] XTTS v2 initialis√© sur {self.device}")
            return True

        except Exception as e:
            logger.error(f"‚ùå [TTS] Erreur initialisation XTTS v2: {e}")
            return False

    async def synthesize(
        self,
        text: str,
        language: str,
        speaker_audio_path: Optional[str] = None,
        output_path: str = None,
        **kwargs
    ) -> str:
        if not self._initialized:
            await self.initialize()

        if not self.model:
            raise RuntimeError("XTTS v2 non initialis√©")

        loop = asyncio.get_event_loop()

        lang_map = {
            "fr": "fr", "en": "en", "es": "es", "de": "de",
            "pt": "pt", "it": "it", "pl": "pl", "tr": "tr",
            "ru": "ru", "nl": "nl", "cs": "cs", "ar": "ar",
            "zh": "zh-cn", "ja": "ja", "hu": "hu", "ko": "ko"
        }
        xtts_lang = lang_map.get(language.lower(), "en")

        if speaker_audio_path and os.path.exists(speaker_audio_path):
            await loop.run_in_executor(
                None,
                lambda: self.model.tts_to_file(
                    text=text,
                    speaker_wav=speaker_audio_path,
                    language=xtts_lang,
                    file_path=output_path
                )
            )
        else:
            await loop.run_in_executor(
                None,
                lambda: self.model.tts_to_file(
                    text=text,
                    language=xtts_lang,
                    file_path=output_path
                )
            )

        return output_path

    async def close(self):
        self.model = None
        self._initialized = False


class UnifiedTTSService:
    """
    Service TTS Unifi√© - Singleton

    Fonctionnalit√©s:
    - Support multi-mod√®les (Chatterbox, Higgs Audio V2, XTTS)
    - Chargement √† chaud des mod√®les
    - V√©rification de disponibilit√© locale
    - T√©l√©chargement en arri√®re-plan
    - Fallback automatique sur Chatterbox
    """

    _instance = None
    _lock = threading.Lock()

    # Espace disque minimum requis pour t√©l√©charger un mod√®le (en GB)
    MIN_DISK_SPACE_GB = 2.0

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._singleton_initialized = False
        return cls._instance

    def __init__(
        self,
        model: TTSModel = None,
        output_dir: Optional[str] = None,
        device: str = "auto"
    ):
        if self._singleton_initialized:
            return

        # Configuration
        model_env = os.getenv("TTS_MODEL", "chatterbox")
        try:
            self.requested_model = model or TTSModel(model_env)
        except ValueError:
            logger.warning(f"[TTS] Mod√®le inconnu: {model_env}, utilisation de chatterbox")
            self.requested_model = TTSModel.CHATTERBOX

        self.current_model = self.requested_model
        self.output_dir = Path(output_dir or os.getenv("TTS_OUTPUT_DIR", "/app/outputs/audio"))
        self.device = os.getenv("TTS_DEVICE", device)
        self.default_format = os.getenv("TTS_DEFAULT_FORMAT", "wav")
        self.models_path = Path(os.getenv("MODELS_PATH", "/workspace/models"))

        # Backends
        self.backends: Dict[TTSModel, BaseTTSBackend] = {}
        self.active_backend: Optional[BaseTTSBackend] = None

        # √âtat
        self.is_initialized = False
        self._init_lock = asyncio.Lock()
        self._background_downloads: Dict[TTSModel, asyncio.Task] = {}

        # Cr√©er les r√©pertoires
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "translated").mkdir(parents=True, exist_ok=True)

        logger.info(f"[TTS] Service configur√©: model={self.requested_model.value}, device={self.device}")

        self._singleton_initialized = True

    def _create_backend(self, model: TTSModel) -> BaseTTSBackend:
        """Cr√©e le backend appropri√© pour le mod√®le"""
        if model == TTSModel.CHATTERBOX:
            return ChatterboxBackend(device=self.device, turbo=False)
        elif model == TTSModel.CHATTERBOX_TURBO:
            return ChatterboxBackend(device=self.device, turbo=True)
        elif model == TTSModel.HIGGS_AUDIO_V2:
            return HiggsAudioBackend(device=self.device)
        elif model == TTSModel.XTTS_V2:
            return XTTSBackend(device=self.device)
        else:
            raise ValueError(f"Mod√®le inconnu: {model}")

    def _get_available_disk_space_gb(self) -> float:
        """Retourne l'espace disque disponible en GB"""
        try:
            total, used, free = shutil.disk_usage(self.models_path)
            return free / (1024 ** 3)
        except Exception:
            return 0.0

    def _can_download_model(self, model: TTSModel) -> bool:
        """V√©rifie si on peut t√©l√©charger un mod√®le (espace disque suffisant)"""
        model_info = TTS_MODEL_INFO[model]
        available_space = self._get_available_disk_space_gb()
        required_space = model_info.model_size_gb + self.MIN_DISK_SPACE_GB
        return available_space >= required_space

    async def get_model_status(self, model: TTSModel) -> ModelStatus:
        """Retourne le statut d'un mod√®le"""
        if model not in self.backends:
            backend = self._create_backend(model)
            self.backends[model] = backend
        else:
            backend = self.backends[model]

        return ModelStatus(
            model=model,
            is_available=backend.is_available,
            is_downloaded=backend.is_model_downloaded(),
            is_loaded=backend.is_initialized,
            is_downloading=backend.is_downloading,
            download_progress=backend.download_progress
        )

    async def get_all_models_status(self) -> Dict[str, ModelStatus]:
        """Retourne le statut de tous les mod√®les"""
        statuses = {}
        for model in TTSModel:
            statuses[model.value] = await self.get_model_status(model)
        return statuses

    async def initialize(self, model: TTSModel = None) -> bool:
        """
        Initialise le service avec le mod√®le sp√©cifi√©.

        Logique NON-BLOQUANTE:
        1. Cherche un mod√®le disponible localement (priorit√©: demand√© > chatterbox > autres)
        2. Si trouv√© ‚Üí le charger imm√©diatement
        3. T√©l√©charge les mod√®les manquants en ARRI√àRE-PLAN
        4. Si aucun mod√®le local ‚Üí mode "pending" jusqu'√† fin du premier t√©l√©chargement
        """
        model = model or self.requested_model

        async with self._init_lock:
            # Si d√©j√† initialis√© avec ce mod√®le, retourner True
            if model in self.backends and self.backends[model].is_initialized:
                self.active_backend = self.backends[model]
                self.current_model = model
                self.is_initialized = True
                return True

            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # √âTAPE 1: Trouver un mod√®le disponible localement
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            local_model = await self._find_local_model(model)

            if local_model:
                # Charger le mod√®le local imm√©diatement
                success = await self._load_model(local_model)

                if success:
                    # T√©l√©charger les autres mod√®les en arri√®re-plan
                    asyncio.create_task(self._download_models_background(model))
                    return True

            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # √âTAPE 2: Aucun mod√®le local - t√©l√©chargement en arri√®re-plan
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.warning("[TTS] ‚ö†Ô∏è Aucun mod√®le TTS disponible localement")
            logger.info("[TTS] üì• D√©marrage des t√©l√©chargements en arri√®re-plan...")

            # Lancer les t√©l√©chargements en arri√®re-plan (priorit√©: demand√©, puis chatterbox)
            asyncio.create_task(self._download_and_load_first_available(model))

            # Service d√©marre en mode "pending" - sera pr√™t apr√®s le premier t√©l√©chargement
            self.is_initialized = True  # Le service est "initialis√©" mais sans mod√®le actif
            logger.info("[TTS] ‚è≥ Service TTS d√©marr√© en mode pending (t√©l√©chargement en cours)")

            return True

    async def _find_local_model(self, preferred: TTSModel) -> Optional[TTSModel]:
        """
        Cherche un mod√®le disponible localement.

        Priorit√©:
        1. Le mod√®le demand√©
        2. Chatterbox (fallback par d√©faut)
        3. Chatterbox Turbo
        4. Tout autre mod√®le disponible
        """
        # Ordre de priorit√©
        priority_order = [
            preferred,
            TTSModel.CHATTERBOX,
            TTSModel.CHATTERBOX_TURBO,
            TTSModel.HIGGS_AUDIO_V2,
            TTSModel.XTTS_V2
        ]
        # Supprimer les doublons tout en gardant l'ordre
        seen = set()
        priority_order = [m for m in priority_order if not (m in seen or seen.add(m))]

        for model in priority_order:
            if model not in self.backends:
                self.backends[model] = self._create_backend(model)

            backend = self.backends[model]

            if backend.is_available and backend.is_model_downloaded():
                logger.info(f"[TTS] ‚úÖ Mod√®le local trouv√©: {model.value}")
                return model

        return None

    async def _load_model(self, model: TTSModel) -> bool:
        """Charge un mod√®le en m√©moire"""
        if model not in self.backends:
            self.backends[model] = self._create_backend(model)

        backend = self.backends[model]

        # Afficher l'alerte de licence si n√©cessaire
        model_info = TTS_MODEL_INFO[model]
        if model_info.license_warning:
            logger.warning(model_info.license_warning)
            print(f"\n{model_info.license_warning}\n")

        logger.info(f"[TTS] üîÑ Chargement du mod√®le {model.value}...")
        success = await backend.initialize()

        if success:
            self.active_backend = backend
            self.current_model = model
            self.is_initialized = True
            logger.info(f"‚úÖ [TTS] Mod√®le {model.value} charg√© avec succ√®s")
            return True
        else:
            logger.error(f"[TTS] ‚ùå √âchec du chargement de {model.value}")
            return False

    async def _download_and_load_first_available(self, preferred: TTSModel):
        """
        T√©l√©charge et charge le premier mod√®le disponible.
        Appel√© quand aucun mod√®le n'est disponible localement.
        """
        # Priorit√©: mod√®le demand√©, puis Chatterbox
        models_to_try = [preferred]
        if preferred != TTSModel.CHATTERBOX:
            models_to_try.append(TTSModel.CHATTERBOX)

        for model in models_to_try:
            if model not in self.backends:
                self.backends[model] = self._create_backend(model)

            backend = self.backends[model]

            if not backend.is_available:
                logger.warning(f"[TTS] Package {model.value} non disponible, skip")
                continue

            if not self._can_download_model(model):
                logger.warning(f"[TTS] Espace disque insuffisant pour {model.value}, skip")
                continue

            logger.info(f"[TTS] üì• T√©l√©chargement prioritaire de {model.value}...")

            try:
                success = await backend.download_model()

                if success:
                    # Charger le mod√®le apr√®s t√©l√©chargement
                    load_success = await self._load_model(model)

                    if load_success:
                        logger.info(f"[TTS] ‚úÖ Premier mod√®le pr√™t: {model.value}")
                        # Continuer avec les t√©l√©chargements en arri√®re-plan
                        asyncio.create_task(self._download_models_background(preferred))
                        return

            except Exception as e:
                logger.error(f"[TTS] ‚ùå Erreur t√©l√©chargement {model.value}: {e}")
                continue

        logger.error("[TTS] ‚ùå Impossible de t√©l√©charger/charger un mod√®le TTS!")

    async def _download_models_background(self, preferred: TTSModel):
        """
        T√©l√©charge les mod√®les en arri√®re-plan si espace disponible.

        Priorit√© de t√©l√©chargement:
        1. Le mod√®le demand√© (s'il n'est pas celui charg√©)
        2. Chatterbox (fallback)
        3. Autres mod√®les
        """
        await asyncio.sleep(5)  # Attendre que le service soit stable

        # Ordre de priorit√© pour les t√©l√©chargements
        priority_order = [preferred, TTSModel.CHATTERBOX, TTSModel.CHATTERBOX_TURBO]
        # Ajouter les autres mod√®les
        for m in TTSModel:
            if m not in priority_order:
                priority_order.append(m)

        for model in priority_order:
            # Skip le mod√®le actuellement charg√©
            if model == self.current_model:
                continue

            # V√©rifier si d√©j√† en t√©l√©chargement
            if model in self._background_downloads:
                continue

            if model not in self.backends:
                self.backends[model] = self._create_backend(model)

            backend = self.backends[model]

            # V√©rifier si le mod√®le est d√©j√† t√©l√©charg√©
            if backend.is_model_downloaded():
                logger.debug(f"[TTS] {model.value} d√©j√† t√©l√©charg√©, skip")
                continue

            # V√©rifier si le package est disponible
            if not backend.is_available:
                logger.debug(f"[TTS] Package {model.value} non disponible, skip")
                continue

            # V√©rifier l'espace disque
            if not self._can_download_model(model):
                logger.info(f"[TTS] Espace insuffisant pour t√©l√©charger {model.value} en arri√®re-plan")
                continue

            # Lancer le t√©l√©chargement en arri√®re-plan
            logger.info(f"[TTS] üì• T√©l√©chargement de {model.value} en arri√®re-plan...")

            async def download_task(m: TTSModel, b: BaseTTSBackend):
                try:
                    await b.download_model()
                    logger.info(f"[TTS] ‚úÖ {m.value} t√©l√©charg√© avec succ√®s (arri√®re-plan)")
                except Exception as e:
                    logger.warning(f"[TTS] Erreur t√©l√©chargement arri√®re-plan {m.value}: {e}")
                finally:
                    if m in self._background_downloads:
                        del self._background_downloads[m]

            task = asyncio.create_task(download_task(model, backend))
            self._background_downloads[model] = task

            # Attendre un peu entre chaque t√©l√©chargement pour √©viter surcharge
            await asyncio.sleep(30)

    async def switch_model(self, model: TTSModel, force: bool = False) -> bool:
        """
        Change de mod√®le TTS (chargement √† chaud).

        Args:
            model: Mod√®le cible
            force: Si True, force le rechargement m√™me si d√©j√† actif

        Returns:
            True si le changement a r√©ussi
        """
        if model == self.current_model and self.active_backend and self.active_backend.is_initialized and not force:
            logger.info(f"[TTS] Mod√®le {model.value} d√©j√† actif")
            return True

        logger.info(f"[TTS] üîÑ Changement de mod√®le: {self.current_model.value} ‚Üí {model.value}")

        # V√©rifier le statut du mod√®le
        status = await self.get_model_status(model)

        if not status.is_available:
            logger.warning(f"[TTS] Package {model.value} non disponible")
            return False

        if not status.is_downloaded:
            # V√©rifier si on peut t√©l√©charger
            if not self._can_download_model(model):
                logger.warning(f"[TTS] Espace disque insuffisant pour {model.value}")
                return False

            logger.info(f"[TTS] T√©l√©chargement de {model.value}...")
            backend = self.backends[model]
            success = await backend.download_model()

            if not success:
                logger.warning(f"[TTS] √âchec t√©l√©chargement {model.value}")
                return False

        # Charger le nouveau mod√®le
        success = await self.initialize(model)

        if success:
            logger.info(f"‚úÖ [TTS] Changement vers {model.value} r√©ussi")
        else:
            logger.warning(f"[TTS] ‚ö†Ô∏è √âchec changement vers {model.value}")

        return success

    async def synthesize_with_voice(
        self,
        text: str,
        speaker_audio_path: str,
        target_language: str,
        output_format: str = None,
        message_id: Optional[str] = None,
        model: TTSModel = None,
        max_wait_seconds: int = 120,
        **kwargs
    ) -> UnifiedTTSResult:
        """Synth√©tise du texte avec clonage vocal."""
        start_time = time.time()

        # Changer de mod√®le si n√©cessaire
        if model and model != self.current_model and self.active_backend:
            success = await self.switch_model(model)
            if not success:
                # Fallback sur le mod√®le actuel
                logger.warning(f"[TTS] Impossible de changer vers {model.value}, utilisation de {self.current_model.value}")

        # Attendre qu'un mod√®le soit disponible (mode pending)
        if not self.active_backend:
            logger.info("[TTS] ‚è≥ Attente d'un mod√®le TTS (t√©l√©chargement en cours)...")
            waited = 0
            while not self.active_backend and waited < max_wait_seconds:
                await asyncio.sleep(2)
                waited += 2
                if waited % 10 == 0:
                    logger.info(f"[TTS] ‚è≥ Attente mod√®le TTS... ({waited}s)")

        if not self.active_backend:
            raise RuntimeError(
                f"Aucun backend TTS disponible apr√®s {max_wait_seconds}s. "
                "V√©rifiez la connexion internet et l'espace disque."
            )

        # Pr√©parer le fichier de sortie
        output_format = output_format or self.default_format
        file_id = message_id or str(uuid.uuid4())
        output_filename = f"{file_id}_{target_language}.{output_format}"
        output_path = str(self.output_dir / "translated" / output_filename)

        logger.info(f"[TTS] üé§ Synth√®se avec {self.current_model.value}: '{text[:50]}...' ‚Üí {target_language}")

        try:
            await self.active_backend.synthesize(
                text=text,
                language=target_language,
                speaker_audio_path=speaker_audio_path,
                output_path=output_path,
                **kwargs
            )

            # Convertir le format si n√©cessaire
            if output_format != "wav":
                output_path = await self._convert_format(output_path, output_format)

            duration_ms = await self._get_duration_ms(output_path)
            processing_time = int((time.time() - start_time) * 1000)

            model_info = TTS_MODEL_INFO[self.current_model]

            logger.info(
                f"[TTS] ‚úÖ Synth√®se termin√©e: {output_filename} "
                f"(dur={duration_ms}ms, time={processing_time}ms, model={self.current_model.value})"
            )

            return UnifiedTTSResult(
                audio_path=output_path,
                audio_url=f"/outputs/audio/translated/{output_filename}",
                duration_ms=duration_ms,
                format=output_format,
                language=target_language,
                voice_cloned=bool(speaker_audio_path and os.path.exists(speaker_audio_path)),
                voice_quality=model_info.quality_score / 100.0,
                processing_time_ms=processing_time,
                text_length=len(text),
                model_used=self.current_model,
                model_info=model_info
            )

        except Exception as e:
            logger.error(f"[TTS] ‚ùå Erreur synth√®se: {e}")
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"√âchec de la synth√®se TTS: {e}")

    async def synthesize(
        self,
        text: str,
        language: str,
        output_format: str = None,
        model: TTSModel = None,
        **kwargs
    ) -> UnifiedTTSResult:
        """Synth√®se vocale simple (sans clonage)."""
        return await self.synthesize_with_voice(
            text=text,
            speaker_audio_path=None,
            target_language=language,
            output_format=output_format,
            model=model,
            **kwargs
        )

    async def _convert_format(self, input_path: str, target_format: str) -> str:
        """Convertit un fichier audio vers un autre format"""
        try:
            from pydub import AudioSegment

            output_path = input_path.rsplit(".", 1)[0] + f".{target_format}"

            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                None,
                lambda: AudioSegment.from_wav(input_path).export(output_path, format=target_format)
            )

            if input_path != output_path and os.path.exists(input_path):
                os.unlink(input_path)

            return output_path

        except Exception as e:
            logger.warning(f"[TTS] Erreur conversion format: {e}")
            return input_path

    async def _get_duration_ms(self, audio_path: str) -> int:
        """R√©cup√®re la dur√©e d'un fichier audio en ms"""
        try:
            import librosa
            loop = asyncio.get_event_loop()
            duration = await loop.run_in_executor(
                None,
                lambda: librosa.get_duration(path=audio_path)
            )
            return int(duration * 1000)
        except Exception:
            return 0

    def get_model_info(self, model: TTSModel = None) -> TTSModelInfo:
        """Retourne les informations sur un mod√®le"""
        return TTS_MODEL_INFO[model or self.current_model]

    def get_available_models(self) -> Dict[str, TTSModelInfo]:
        """Retourne tous les mod√®les disponibles avec leurs infos"""
        return {model.value: info for model, info in TTS_MODEL_INFO.items()}

    def get_supported_languages(self, model: TTSModel = None) -> list:
        """Retourne les langues support√©es par le mod√®le"""
        info = TTS_MODEL_INFO[model or self.current_model]
        return info.languages

    @property
    def is_ready(self) -> bool:
        """Retourne True si un mod√®le est charg√© et pr√™t √† synth√©tiser"""
        return self.active_backend is not None and self.active_backend.is_initialized

    async def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du service"""
        models_status = await self.get_all_models_status()

        # Infos sur le mod√®le actuel (si charg√©)
        current_model_info = None
        if self.active_backend:
            current_model_info = {
                "name": TTS_MODEL_INFO[self.current_model].display_name,
                "license": TTS_MODEL_INFO[self.current_model].license,
                "commercial_use": TTS_MODEL_INFO[self.current_model].commercial_use,
                "quality_score": TTS_MODEL_INFO[self.current_model].quality_score,
                "languages_count": len(TTS_MODEL_INFO[self.current_model].languages)
            }

        return {
            "service": "UnifiedTTSService",
            "initialized": self.is_initialized,
            "is_ready": self.is_ready,
            "status": "ready" if self.is_ready else "pending",
            "current_model": self.current_model.value if self.active_backend else None,
            "requested_model": self.requested_model.value,
            "fallback_model": TTSModel.get_fallback().value,
            "current_model_info": current_model_info,
            "background_downloads_count": len(self._background_downloads),
            "models_status": {
                model: {
                    "is_available": status.is_available,
                    "is_downloaded": status.is_downloaded,
                    "is_loaded": status.is_loaded,
                    "is_downloading": status.is_downloading,
                    "download_progress": status.download_progress
                }
                for model, status in models_status.items()
            },
            "disk_space_available_gb": self._get_available_disk_space_gb(),
            "device": self.device,
            "output_dir": str(self.output_dir),
            "default_format": self.default_format
        }

    async def close(self):
        """Lib√®re les ressources de tous les backends"""
        logger.info("[TTS] üõë Fermeture du service unifi√©")

        # Annuler les t√©l√©chargements en cours
        for task in self._background_downloads.values():
            task.cancel()
        self._background_downloads.clear()

        # Fermer tous les backends
        for backend in self.backends.values():
            await backend.close()
        self.backends.clear()
        self.active_backend = None
        self.is_initialized = False


# Fonction helper pour obtenir l'instance singleton
def get_unified_tts_service() -> UnifiedTTSService:
    """Retourne l'instance singleton du service TTS unifi√©"""
    return UnifiedTTSService()


# V√©rification des licences au d√©marrage
def check_license_compliance(model: TTSModel) -> Tuple[bool, Optional[str]]:
    """
    V√©rifie la conformit√© de la licence pour un usage commercial.

    Returns:
        (is_commercial_ok, warning_message)
    """
    info = TTS_MODEL_INFO[model]
    return info.commercial_use, info.license_warning
