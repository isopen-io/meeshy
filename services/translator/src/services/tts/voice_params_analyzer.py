"""
Voice Parameters Analyzer
=========================

Analyse un √©chantillon vocal pour calculer automatiquement
les param√®tres optimaux de clonage (exaggeration, cfg_weight).

M√©triques analys√©es:
- Pitch variance: Variation de la hauteur de voix
- Energy dynamics: Variation de l'intensit√©
- Speaking rate: D√©bit de parole
- Voice stability: Stabilit√©/r√©gularit√© vocale
"""

import numpy as np
import logging
from dataclasses import dataclass
from typing import Optional, Tuple
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass
class VoiceAnalysisResult:
    """R√©sultat de l'analyse vocale"""
    # M√©triques brutes
    pitch_mean: float
    pitch_std: float
    pitch_range: float
    energy_mean: float
    energy_std: float
    energy_dynamics: float
    speaking_rate: float  # syllabes/seconde estim√©
    voice_stability: float  # 0-1, 1 = tr√®s stable
    duration_seconds: float

    # Scores normalis√©s (0-1)
    expressiveness_score: float  # Bas√© sur pitch + energy variance
    clarity_score: float  # Bas√© sur stabilit√© + √©nergie

    # Param√®tres recommand√©s
    recommended_exaggeration: float
    recommended_cfg_weight: float

    # Confiance de la recommandation
    confidence: float

    def __str__(self):
        return f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ANALYSE VOCALE - PARAM√àTRES RECOMMAND√âS                     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  Dur√©e audio: {self.duration_seconds:.1f}s
‚ïë
‚ïë  üìä M√âTRIQUES VOCALES:
‚ïë  ‚îú‚îÄ Pitch moyen: {self.pitch_mean:.1f} Hz (¬±{self.pitch_std:.1f})
‚ïë  ‚îú‚îÄ Plage pitch: {self.pitch_range:.1f} Hz
‚ïë  ‚îú‚îÄ Dynamique √©nergie: {self.energy_dynamics:.2f}
‚ïë  ‚îú‚îÄ Stabilit√© vocale: {self.voice_stability:.2f}
‚ïë  ‚îî‚îÄ D√©bit estim√©: {self.speaking_rate:.1f} syll/s
‚ïë
‚ïë  üìà SCORES:
‚ïë  ‚îú‚îÄ Expressivit√©: {self.expressiveness_score:.2f}
‚ïë  ‚îî‚îÄ Clart√©: {self.clarity_score:.2f}
‚ïë
‚ïë  üéØ PARAM√àTRES RECOMMAND√âS:
‚ïë  ‚îú‚îÄ exaggeration: {self.recommended_exaggeration:.2f}
‚ïë  ‚îú‚îÄ cfg_weight: {self.recommended_cfg_weight:.2f}
‚ïë  ‚îî‚îÄ Confiance: {self.confidence:.0%}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""


class VoiceParamsAnalyzer:
    """
    Analyseur de param√®tres vocaux pour optimiser le clonage.

    Calcule les param√®tres optimaux bas√©s sur les caract√©ristiques
    de la voix source.
    """

    def __init__(self):
        self._librosa = None
        self._scipy = None

    def _load_dependencies(self):
        """Charge les d√©pendances √† la demande"""
        if self._librosa is None:
            try:
                import librosa
                import scipy.signal
                self._librosa = librosa
                self._scipy = scipy
            except ImportError as e:
                raise ImportError(f"librosa et scipy requis: {e}")

    def analyze(self, audio_path: str) -> VoiceAnalysisResult:
        """
        Analyse un fichier audio et retourne les param√®tres recommand√©s.

        Args:
            audio_path: Chemin vers le fichier audio (WAV, MP3, etc.)

        Returns:
            VoiceAnalysisResult avec m√©triques et param√®tres recommand√©s
        """
        self._load_dependencies()
        librosa = self._librosa

        logger.info(f"üîç Analyse vocale: {Path(audio_path).name}")

        # Charger l'audio
        y, sr = librosa.load(audio_path, sr=None)
        duration = len(y) / sr

        # 1. Analyse du pitch (F0)
        pitch_mean, pitch_std, pitch_range = self._analyze_pitch(y, sr)

        # 2. Analyse de l'√©nergie
        energy_mean, energy_std, energy_dynamics = self._analyze_energy(y, sr)

        # 3. Estimation du d√©bit de parole
        speaking_rate = self._estimate_speaking_rate(y, sr)

        # 4. Analyse de la stabilit√© vocale
        voice_stability = self._analyze_stability(y, sr)

        # 5. Calculer les scores normalis√©s
        expressiveness_score = self._calculate_expressiveness(
            pitch_std, pitch_range, energy_dynamics
        )
        clarity_score = self._calculate_clarity(
            voice_stability, energy_mean, speaking_rate
        )

        # 6. Calculer les param√®tres recommand√©s
        exaggeration, cfg_weight, confidence = self._calculate_optimal_params(
            expressiveness_score, clarity_score, voice_stability, duration
        )

        result = VoiceAnalysisResult(
            pitch_mean=pitch_mean,
            pitch_std=pitch_std,
            pitch_range=pitch_range,
            energy_mean=energy_mean,
            energy_std=energy_std,
            energy_dynamics=energy_dynamics,
            speaking_rate=speaking_rate,
            voice_stability=voice_stability,
            duration_seconds=duration,
            expressiveness_score=expressiveness_score,
            clarity_score=clarity_score,
            recommended_exaggeration=exaggeration,
            recommended_cfg_weight=cfg_weight,
            confidence=confidence
        )

        logger.info(f"‚úÖ Analyse termin√©e: exp={exaggeration:.2f}, cfg={cfg_weight:.2f}")
        return result

    def _analyze_pitch(self, y: np.ndarray, sr: int) -> Tuple[float, float, float]:
        """Analyse le pitch (F0) de l'audio"""
        librosa = self._librosa

        # Extraire F0 avec pyin (plus pr√©cis que yin)
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y,
            fmin=librosa.note_to_hz('C2'),  # ~65 Hz
            fmax=librosa.note_to_hz('C7'),  # ~2093 Hz
            sr=sr
        )

        # Filtrer les valeurs non-vois√©es (NaN)
        f0_voiced = f0[~np.isnan(f0)]

        if len(f0_voiced) < 10:
            # Pas assez de donn√©es vocales
            return 150.0, 30.0, 100.0

        pitch_mean = np.mean(f0_voiced)
        pitch_std = np.std(f0_voiced)
        pitch_range = np.percentile(f0_voiced, 95) - np.percentile(f0_voiced, 5)

        return pitch_mean, pitch_std, pitch_range

    def _analyze_energy(self, y: np.ndarray, sr: int) -> Tuple[float, float, float]:
        """Analyse l'√©nergie/intensit√© de l'audio"""
        librosa = self._librosa

        # RMS energy par frame
        rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]

        # Convertir en dB
        rms_db = librosa.amplitude_to_db(rms, ref=np.max)

        # Filtrer les silences (< -40 dB)
        rms_voiced = rms_db[rms_db > -40]

        if len(rms_voiced) < 10:
            return -20.0, 5.0, 0.5

        energy_mean = np.mean(rms_voiced)
        energy_std = np.std(rms_voiced)

        # Dynamique normalis√©e (0-1)
        # Plus la variance est grande, plus la voix est dynamique
        energy_dynamics = min(1.0, energy_std / 15.0)

        return energy_mean, energy_std, energy_dynamics

    def _estimate_speaking_rate(self, y: np.ndarray, sr: int) -> float:
        """Estime le d√©bit de parole en syllabes/seconde"""
        librosa = self._librosa

        # Onset detection pour estimer les syllabes
        onset_env = librosa.onset.onset_strength(y=y, sr=sr)
        onsets = librosa.onset.onset_detect(
            onset_envelope=onset_env,
            sr=sr,
            units='time'
        )

        duration = len(y) / sr

        if duration < 1:
            return 4.0  # Valeur par d√©faut

        # Nombre d'onsets / dur√©e ‚âà syllabes/seconde
        # Facteur de correction car tous les onsets ne sont pas des syllabes
        speaking_rate = len(onsets) / duration * 0.7

        # Borner entre 2 et 8 syllabes/seconde (plage normale)
        return np.clip(speaking_rate, 2.0, 8.0)

    def _analyze_stability(self, y: np.ndarray, sr: int) -> float:
        """
        Analyse la stabilit√© vocale (r√©gularit√© du pitch et de l'√©nergie).

        Retourne un score 0-1 o√π 1 = tr√®s stable.
        """
        librosa = self._librosa

        # 1. Stabilit√© du pitch
        f0, _, _ = librosa.pyin(
            y,
            fmin=librosa.note_to_hz('C2'),
            fmax=librosa.note_to_hz('C7'),
            sr=sr
        )
        f0_voiced = f0[~np.isnan(f0)]

        if len(f0_voiced) < 10:
            return 0.5

        # Coefficient de variation du pitch (plus bas = plus stable)
        pitch_cv = np.std(f0_voiced) / np.mean(f0_voiced) if np.mean(f0_voiced) > 0 else 0.5
        pitch_stability = 1.0 - min(1.0, pitch_cv * 2)

        # 2. Stabilit√© de l'√©nergie
        rms = librosa.feature.rms(y=y)[0]
        rms_nonzero = rms[rms > 0.01]

        if len(rms_nonzero) < 10:
            return pitch_stability

        energy_cv = np.std(rms_nonzero) / np.mean(rms_nonzero)
        energy_stability = 1.0 - min(1.0, energy_cv)

        # Score combin√©
        stability = (pitch_stability * 0.6 + energy_stability * 0.4)

        return np.clip(stability, 0.0, 1.0)

    def _calculate_expressiveness(
        self,
        pitch_std: float,
        pitch_range: float,
        energy_dynamics: float
    ) -> float:
        """
        Calcule un score d'expressivit√© (0-1).

        Voix expressive = grande variation de pitch + √©nergie dynamique
        """
        # Normaliser pitch_std (typiquement 20-80 Hz pour voix expressive)
        pitch_score = min(1.0, pitch_std / 60.0)

        # Normaliser pitch_range (typiquement 50-200 Hz)
        range_score = min(1.0, pitch_range / 150.0)

        # Combiner les scores
        expressiveness = (
            pitch_score * 0.35 +
            range_score * 0.35 +
            energy_dynamics * 0.30
        )

        return np.clip(expressiveness, 0.0, 1.0)

    def _calculate_clarity(
        self,
        stability: float,
        energy_mean: float,
        speaking_rate: float
    ) -> float:
        """
        Calcule un score de clart√© (0-1).

        Voix claire = stable + bonne √©nergie + d√©bit mod√©r√©
        """
        # Normaliser l'√©nergie (-30 √† -5 dB typique)
        energy_score = min(1.0, max(0.0, (energy_mean + 30) / 25))

        # D√©bit optimal autour de 4-5 syllabes/seconde
        rate_score = 1.0 - abs(speaking_rate - 4.5) / 4.0
        rate_score = max(0.0, rate_score)

        clarity = (
            stability * 0.50 +
            energy_score * 0.30 +
            rate_score * 0.20
        )

        return np.clip(clarity, 0.0, 1.0)

    def _calculate_optimal_params(
        self,
        expressiveness: float,
        clarity: float,
        stability: float,
        duration: float
    ) -> Tuple[float, float, float]:
        """
        Calcule les param√®tres optimaux bas√©s sur l'analyse.

        Returns:
            (exaggeration, cfg_weight, confidence)
        """
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # EXAGGERATION: Bas√© sur l'expressivit√© de la voix source
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        #
        # - Voix expressive (score √©lev√©) ‚Üí exaggeration plus bas
        #   (la voix est d√©j√† expressive, pas besoin d'amplifier)
        # - Voix monotone (score bas) ‚Üí exaggeration plus haut
        #   (ajouter de l'expressivit√©)
        #
        # Plage cible: 0.3 - 0.7

        if expressiveness > 0.7:
            # Voix tr√®s expressive ‚Üí garder exaggeration bas
            exaggeration = 0.3 + (1.0 - expressiveness) * 0.2
        elif expressiveness < 0.3:
            # Voix monotone ‚Üí augmenter exaggeration
            exaggeration = 0.5 + (0.3 - expressiveness) * 0.5
        else:
            # Voix normale ‚Üí valeur m√©diane
            exaggeration = 0.4 + expressiveness * 0.2

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CFG_WEIGHT: Bas√© sur la clart√© et stabilit√©
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        #
        # - Voix claire et stable ‚Üí cfg plus bas (plus de libert√©)
        # - Voix instable ou peu claire ‚Üí cfg plus haut (plus de guidance)
        #
        # Plage cible: 0.3 - 0.7

        combined_quality = (clarity * 0.5 + stability * 0.5)

        if combined_quality > 0.7:
            # Bonne qualit√© ‚Üí cfg plus bas
            cfg_weight = 0.35 + (1.0 - combined_quality) * 0.3
        elif combined_quality < 0.4:
            # Qualit√© faible ‚Üí cfg plus haut
            cfg_weight = 0.55 + (0.4 - combined_quality) * 0.4
        else:
            # Qualit√© moyenne
            cfg_weight = 0.45 + (0.5 - combined_quality) * 0.2

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CONFIANCE: Bas√©e sur la dur√©e et la qualit√© de l'analyse
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        # Plus l'audio est long, plus l'analyse est fiable
        duration_confidence = min(1.0, duration / 30.0)

        # Plus la voix est stable, plus l'analyse est fiable
        stability_confidence = stability

        confidence = (duration_confidence * 0.6 + stability_confidence * 0.4)

        # Borner les valeurs
        exaggeration = np.clip(exaggeration, 0.25, 0.75)
        cfg_weight = np.clip(cfg_weight, 0.25, 0.75)
        confidence = np.clip(confidence, 0.3, 0.95)

        return exaggeration, cfg_weight, confidence


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# QUALITY VERIFICATION (optionnel - pour √©valuer le r√©sultat)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class VoiceCloneQualityChecker:
    """
    V√©rifie la qualit√© d'un clone vocal en comparant avec l'original.

    M√©triques:
    - Speaker embedding similarity (similarit√© cosinus)
    - F0 correlation (corr√©lation de pitch)
    - Energy profile similarity
    """

    def __init__(self):
        self._librosa = None

    def _load_dependencies(self):
        if self._librosa is None:
            import librosa
            self._librosa = librosa

    def compare(
        self,
        original_path: str,
        cloned_path: str
    ) -> dict:
        """
        Compare un audio clon√© avec l'original.

        Returns:
            dict avec scores de similarit√©
        """
        self._load_dependencies()
        librosa = self._librosa

        # Charger les audios
        y_orig, sr_orig = librosa.load(original_path, sr=22050)
        y_clone, sr_clone = librosa.load(cloned_path, sr=22050)

        # 1. Similarit√© MFCC (timbre)
        mfcc_orig = librosa.feature.mfcc(y=y_orig, sr=sr_orig, n_mfcc=13)
        mfcc_clone = librosa.feature.mfcc(y=y_clone, sr=sr_clone, n_mfcc=13)

        # Moyenne des MFCCs
        mfcc_orig_mean = np.mean(mfcc_orig, axis=1)
        mfcc_clone_mean = np.mean(mfcc_clone, axis=1)

        # Similarit√© cosinus
        mfcc_similarity = np.dot(mfcc_orig_mean, mfcc_clone_mean) / (
            np.linalg.norm(mfcc_orig_mean) * np.linalg.norm(mfcc_clone_mean)
        )

        # 2. Corr√©lation F0
        f0_orig, _, _ = librosa.pyin(y_orig, fmin=65, fmax=2000, sr=sr_orig)
        f0_clone, _, _ = librosa.pyin(y_clone, fmin=65, fmax=2000, sr=sr_clone)

        # Aligner les longueurs
        min_len = min(len(f0_orig), len(f0_clone))
        f0_orig = f0_orig[:min_len]
        f0_clone = f0_clone[:min_len]

        # Masquer les NaN
        valid_mask = ~(np.isnan(f0_orig) | np.isnan(f0_clone))
        if np.sum(valid_mask) > 10:
            f0_correlation = np.corrcoef(
                f0_orig[valid_mask],
                f0_clone[valid_mask]
            )[0, 1]
        else:
            f0_correlation = 0.0

        # 3. Similarit√© de l'enveloppe d'√©nergie
        rms_orig = librosa.feature.rms(y=y_orig)[0]
        rms_clone = librosa.feature.rms(y=y_clone)[0]

        # Normaliser et comparer
        rms_orig_norm = rms_orig / (np.max(rms_orig) + 1e-8)
        rms_clone_norm = rms_clone / (np.max(rms_clone) + 1e-8)

        min_len = min(len(rms_orig_norm), len(rms_clone_norm))
        energy_correlation = np.corrcoef(
            rms_orig_norm[:min_len],
            rms_clone_norm[:min_len]
        )[0, 1]

        # Score global
        overall_score = (
            mfcc_similarity * 0.5 +
            max(0, f0_correlation) * 0.3 +
            max(0, energy_correlation) * 0.2
        )

        return {
            "mfcc_similarity": float(mfcc_similarity),
            "f0_correlation": float(f0_correlation) if not np.isnan(f0_correlation) else 0.0,
            "energy_correlation": float(energy_correlation) if not np.isnan(energy_correlation) else 0.0,
            "overall_score": float(overall_score),
            "quality_rating": self._get_rating(overall_score)
        }

    def _get_rating(self, score: float) -> str:
        """Convertit le score en rating lisible"""
        if score >= 0.85:
            return "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent"
        elif score >= 0.75:
            return "‚≠ê‚≠ê‚≠ê‚≠ê Tr√®s bon"
        elif score >= 0.65:
            return "‚≠ê‚≠ê‚≠ê Bon"
        elif score >= 0.50:
            return "‚≠ê‚≠ê Acceptable"
        else:
            return "‚≠ê √Ä am√©liorer"


# Fonctions utilitaires
def get_voice_params_analyzer() -> VoiceParamsAnalyzer:
    """Factory pour obtenir l'analyseur"""
    return VoiceParamsAnalyzer()


def get_voice_quality_checker() -> VoiceCloneQualityChecker:
    """Factory pour obtenir le v√©rificateur de qualit√©"""
    return VoiceCloneQualityChecker()


# Test CLI
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python voice_params_analyzer.py <audio_file>")
        print("       python voice_params_analyzer.py <original> <cloned>  # Compare")
        sys.exit(1)

    if len(sys.argv) == 2:
        # Analyse seule
        analyzer = VoiceParamsAnalyzer()
        result = analyzer.analyze(sys.argv[1])
        print(result)
    else:
        # Comparaison
        checker = VoiceCloneQualityChecker()
        comparison = checker.compare(sys.argv[1], sys.argv[2])
        print("\nüìä COMPARAISON QUALIT√â CLONE:")
        print(f"   MFCC Similarity: {comparison['mfcc_similarity']:.3f}")
        print(f"   F0 Correlation: {comparison['f0_correlation']:.3f}")
        print(f"   Energy Correlation: {comparison['energy_correlation']:.3f}")
        print(f"   Overall Score: {comparison['overall_score']:.3f}")
        print(f"   Rating: {comparison['quality_rating']}")
