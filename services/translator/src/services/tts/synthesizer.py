"""
Synthesizer - Synth√®se TTS et conversion audio
===============================================

Responsabilit√©s:
- Synth√®se TTS avec clonage vocal
- Conversion de formats audio
- Calcul de dur√©e audio
- Encodage base64 pour transmission
- Gestion des param√®tres de synth√®se
- Segmentation intelligente pour textes longs
"""

import os
import re
import shutil
import logging
import time
import uuid
import asyncio
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass
from pathlib import Path

logger = logging.getLogger(__name__)

# Configuration segmentation texte long (configurable via .env)
# Chatterbox max_new_tokens=2048 ‚âà 140s audio max (2min20s)
MAX_SEGMENT_CHARS = int(os.getenv("TTS_MAX_SEGMENT_CHARS", "1000"))  # Caract√®res max par segment (~70-80s audio)
MIN_SEGMENT_CHARS = int(os.getenv("TTS_MIN_SEGMENT_CHARS", "50"))     # Caract√®res min (√©viter segments trop courts)

# Configuration vitesse audio (D√âSACTIV√â - contr√¥l√© via param√®tres Chatterbox)
# La vitesse est maintenant g√©r√©e via exaggeration et cfg_weight dans chatterbox_backend.py
# Facteur de vitesse: 1.0 = normal, 0.9 = 10% plus lent, 1.1 = 10% plus rapide
AUDIO_SPEED_FACTOR = 1.0  # D√©sactiv√© - pas de post-traitement


@dataclass
class UnifiedTTSResult:
    """R√©sultat unifi√© d'une synth√®se TTS"""
    audio_path: str
    audio_url: str
    duration_ms: int
    format: str
    language: str
    voice_cloned: bool
    voice_quality: float
    processing_time_ms: int
    text_length: int
    model_used: 'TTSModel'
    model_info: 'TTSModelInfo'
    # Audio en base64 pour transmission directe au Gateway (pas de fichier partag√©)
    audio_data_base64: Optional[str] = None
    audio_mime_type: Optional[str] = None


class Synthesizer:
    """
    Gestionnaire de synth√®se TTS.

    Responsabilit√©s:
    - Synth√®se vocale avec ou sans clonage
    - Conversion de formats audio
    - G√©n√©ration des r√©sultats unifi√©s
    - Segmentation intelligente pour textes longs (>150 chars)
    """

    def __init__(self, output_dir: Path, default_format: str = "mp3"):
        """
        Initialise le synth√©tiseur.

        Args:
            output_dir: R√©pertoire de sortie pour les fichiers audio
            default_format: Format de sortie par d√©faut
        """
        self.output_dir = output_dir
        self.default_format = default_format

        # Cr√©er les r√©pertoires de sortie
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "translated").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "segments").mkdir(parents=True, exist_ok=True)

        logger.info(f"[Synthesizer] Initialis√©: output={output_dir}, format={default_format}")

    def _segment_text(self, text: str, max_chars: int = MAX_SEGMENT_CHARS) -> List[str]:
        """
        Segmente un texte long en morceaux synth√©tisables.

        Strat√©gie:
        1. D√©couper par phrases (., !, ?)
        2. Si phrase trop longue, d√©couper par virgules
        3. Si toujours trop long, d√©couper par mots

        Args:
            text: Texte √† segmenter
            max_chars: Longueur maximale par segment

        Returns:
            Liste de segments de texte
        """
        if len(text) <= max_chars:
            return [text]

        segments = []
        current_segment = ""

        # D√©couper par phrases
        # Pattern: fin de phrase + espace ou fin de texte
        sentence_pattern = r'([^.!?]*[.!?]+\s*)'
        sentences = re.findall(sentence_pattern, text)

        # Ajouter le reste s'il y en a (sans ponctuation finale)
        remaining = re.sub(sentence_pattern, '', text).strip()
        if remaining:
            sentences.append(remaining)

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            # Si la phrase tient dans le segment actuel
            if len(current_segment) + len(sentence) + 1 <= max_chars:
                current_segment = (current_segment + " " + sentence).strip()
            else:
                # Sauvegarder le segment actuel s'il n'est pas vide
                if current_segment and len(current_segment) >= MIN_SEGMENT_CHARS:
                    segments.append(current_segment)
                    current_segment = ""

                # Si la phrase elle-m√™me est trop longue
                if len(sentence) > max_chars:
                    # D√©couper par virgules
                    sub_parts = sentence.split(',')
                    for part in sub_parts:
                        part = part.strip()
                        if not part:
                            continue

                        if len(current_segment) + len(part) + 2 <= max_chars:
                            current_segment = (current_segment + ", " + part).strip()
                            if current_segment.startswith(", "):
                                current_segment = current_segment[2:]
                        else:
                            if current_segment and len(current_segment) >= MIN_SEGMENT_CHARS:
                                segments.append(current_segment)
                            current_segment = part

                            # Si le part est encore trop long, d√©couper par mots
                            if len(current_segment) > max_chars:
                                words = current_segment.split()
                                current_segment = ""
                                for word in words:
                                    if len(current_segment) + len(word) + 1 <= max_chars:
                                        current_segment = (current_segment + " " + word).strip()
                                    else:
                                        if current_segment:
                                            segments.append(current_segment)
                                        current_segment = word
                else:
                    current_segment = sentence

        # Ajouter le dernier segment
        if current_segment:
            # Si le dernier segment est trop court, le fusionner avec le pr√©c√©dent
            if len(current_segment) < MIN_SEGMENT_CHARS and segments:
                last = segments.pop()
                if len(last) + len(current_segment) + 1 <= max_chars * 1.2:  # Tol√©rance 20%
                    segments.append(last + " " + current_segment)
                else:
                    segments.append(last)
                    segments.append(current_segment)
            else:
                segments.append(current_segment)

        logger.info(
            f"[Synthesizer] Texte segment√©: {len(text)} chars ‚Üí {len(segments)} segments "
            f"(moy: {len(text)//max(1,len(segments))} chars/seg)"
        )

        return segments if segments else [text]

    async def _concatenate_audios(
        self,
        audio_paths: List[str],
        output_path: str,
        silence_ms: int = 150
    ) -> str:
        """
        Concat√®ne plusieurs fichiers audio avec des silences entre eux.

        Args:
            audio_paths: Liste des chemins audio √† concat√©ner
            output_path: Chemin de sortie
            silence_ms: Dur√©e du silence entre segments (ms)

        Returns:
            Chemin du fichier concat√©n√©
        """
        if len(audio_paths) == 1:
            # Un seul fichier, le renommer simplement
            if audio_paths[0] != output_path:
                import shutil
                shutil.move(audio_paths[0], output_path)
            return output_path

        try:
            from pydub import AudioSegment

            loop = asyncio.get_event_loop()

            def concat():
                combined = AudioSegment.empty()
                silence = AudioSegment.silent(duration=silence_ms)

                for i, path in enumerate(audio_paths):
                    if not os.path.exists(path):
                        logger.warning(f"[Synthesizer] Fichier segment manquant: {path}")
                        continue

                    # D√©tecter le format
                    ext = path.rsplit(".", 1)[-1].lower() if "." in path else "wav"
                    segment = AudioSegment.from_file(path, format=ext)
                    combined += segment

                    # Ajouter silence entre segments (pas apr√®s le dernier)
                    if i < len(audio_paths) - 1:
                        combined += silence

                # Exporter
                output_format = output_path.rsplit(".", 1)[-1].lower() if "." in output_path else "mp3"
                combined.export(output_path, format=output_format)

                # Nettoyer les fichiers temporaires
                for path in audio_paths:
                    if os.path.exists(path) and path != output_path:
                        try:
                            os.unlink(path)
                        except Exception:
                            pass

                return output_path

            result = await loop.run_in_executor(None, concat)
            logger.info(
                f"[Synthesizer] ‚úÖ {len(audio_paths)} segments concat√©n√©s ‚Üí {output_path}"
            )
            return result

        except Exception as e:
            logger.error(f"[Synthesizer] ‚ùå Erreur concat√©nation: {e}")
            # En cas d'erreur, retourner le premier segment
            if audio_paths and os.path.exists(audio_paths[0]):
                return audio_paths[0]
            raise

    async def synthesize_with_voice(
        self,
        text: str,
        target_language: str,
        backend: 'BaseTTSBackend',
        model: 'TTSModel',
        model_info: 'TTSModelInfo',
        speaker_audio_path: Optional[str] = None,
        output_format: Optional[str] = None,
        message_id: Optional[str] = None,
        # Param√®tres de clonage vocal configurables
        exaggeration: Optional[float] = None,
        cfg_weight: Optional[float] = None,
        temperature: Optional[float] = None,
        repetition_penalty: Optional[float] = None,
        min_p: Optional[float] = None,
        top_p: Optional[float] = None,
        cloning_params: Optional[Dict[str, Any]] = None,
        auto_optimize: bool = True,
        # NOUVEAU: Conditionals Chatterbox pr√©-calcul√©s
        conditionals: Optional[Any] = None,
        **kwargs
    ) -> UnifiedTTSResult:
        """
        Synth√©tise du texte avec clonage vocal optionnel.

        Args:
            text: Texte √† synth√©tiser
            target_language: Langue cible (code ISO 639-1)
            backend: Backend TTS √† utiliser
            model: Mod√®le TTS utilis√©
            model_info: Informations sur le mod√®le
            speaker_audio_path: Chemin audio de r√©f√©rence (optionnel)
            output_format: Format de sortie (mp3, wav, etc.)
            message_id: ID du message pour le nommage du fichier

            PARAM√àTRES DE CLONAGE VOCAL (6 param√®tres Chatterbox):
            exaggeration: Expressivit√© (0.0-1.0, d√©faut 0.5)
            cfg_weight: Guidance (0.0-1.0, d√©faut 0.0 pour non-anglais)
            temperature: Cr√©ativit√© (0.0-2.0, d√©faut 0.8)
            repetition_penalty: P√©nalit√© r√©p√©tition (1.0-3.0)
            min_p: Probabilit√© minimum (0.0-1.0, d√©faut 0.05)
            top_p: Nucleus sampling (0.0-1.0, d√©faut 1.0)
            cloning_params: Dict avec tous les param√®tres (alternative)
            auto_optimize: Calculer automatiquement les param√®tres non sp√©cifi√©s

        Returns:
            UnifiedTTSResult avec les informations de l'audio g√©n√©r√©
        """
        start_time = time.time()

        # R√©cup√©rer les param√®tres de clonage depuis cloning_params ou valeurs individuelles
        if cloning_params:
            exaggeration = cloning_params.get("exaggeration", exaggeration)
            cfg_weight = cloning_params.get("cfg_weight", cfg_weight)
            temperature = cloning_params.get("temperature", temperature)
            repetition_penalty = cloning_params.get("repetition_penalty", repetition_penalty)
            min_p = cloning_params.get("min_p", min_p)
            top_p = cloning_params.get("top_p", top_p)
            auto_optimize = cloning_params.get("auto_optimize", auto_optimize)

        # Ajouter les param√®tres aux kwargs pour le backend
        if exaggeration is not None:
            kwargs['exaggeration'] = exaggeration
        if cfg_weight is not None:
            kwargs['cfg_weight'] = cfg_weight
        if temperature is not None:
            kwargs['temperature'] = temperature
        if repetition_penalty is not None:
            kwargs['repetition_penalty'] = repetition_penalty
        if min_p is not None:
            kwargs['min_p'] = min_p
        if top_p is not None:
            kwargs['top_p'] = top_p

        # Activer/d√©sactiver l'auto-optimisation
        kwargs['auto_optimize_params'] = auto_optimize

        logger.debug(
            f"[Synthesizer] Param√®tres clonage: exag={exaggeration}, cfg={cfg_weight}, "
            f"temp={temperature}, rep_pen={repetition_penalty}, "
            f"min_p={min_p}, top_p={top_p}, auto_opt={auto_optimize}"
        )

        # Pr√©parer le fichier de sortie
        output_format = output_format or self.default_format
        file_id = message_id or str(uuid.uuid4())
        output_filename = f"{file_id}_{target_language}.{output_format}"
        output_path = str(self.output_dir / "translated" / output_filename)

        # Convertir text en string si n√©cessaire
        text_str = str(text) if not isinstance(text, str) else text

        logger.info(
            f"[Synthesizer] üé§ Synth√®se: '{text_str[:50]}...' ‚Üí {target_language} "
            f"(model={model.value}, len={len(text_str)} chars)"
        )

        try:
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # SEGMENTATION POUR TEXTES LONGS
            # Chatterbox limite √† ~140s audio (max_new_tokens=2048)
            # On segmente les textes > 1000 chars pour √©viter la troncature
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            segments = self._segment_text(text)

            if len(segments) > 1:
                logger.info(
                    f"[Synthesizer] üìù Texte long d√©tect√© ({len(text)} chars) ‚Üí "
                    f"{len(segments)} segments √† synth√©tiser S√âQUENTIELLEMENT"
                )

                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                # SYNTH√àSE S√âQUENTIELLE des segments
                # Note: La synth√®se parall√®le cause des erreurs de tenseurs avec
                # Chatterbox car le mod√®le n'est pas thread-safe. Les appels
                # concurrents interf√®rent au niveau des tenseurs internes.
                # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

                segment_paths = []
                for i, segment_text in enumerate(segments):
                    segment_filename = f"{file_id}_{target_language}_seg{i:03d}.wav"
                    segment_path = str(self.output_dir / "segments" / segment_filename)

                    logger.debug(
                        f"[Synthesizer] üîÑ Segment {i+1}/{len(segments)}: "
                        f"'{segment_text[:40]}...' ({len(segment_text)} chars)"
                    )

                    try:
                        await backend.synthesize(
                            text=segment_text,
                            language=target_language,
                            speaker_audio_path=speaker_audio_path,
                            output_path=segment_path,
                            conditionals=conditionals,
                            **kwargs
                        )

                        if os.path.exists(segment_path):
                            logger.debug(f"[Synthesizer] ‚úÖ Segment {i+1} synth√©tis√©")
                            segment_paths.append(segment_path)
                        else:
                            logger.warning(f"[Synthesizer] ‚ö†Ô∏è Segment {i+1} non g√©n√©r√©")
                    except Exception as e:
                        logger.error(f"[Synthesizer] ‚ùå Erreur segment {i+1}: {e}")

                logger.info(
                    f"[Synthesizer] ‚úÖ Synth√®se s√©quentielle termin√©e: "
                    f"{len(segment_paths)}/{len(segments)} segments r√©ussis"
                )

                # Concat√©ner tous les segments
                if segment_paths:
                    temp_concat_path = str(self.output_dir / "segments" / f"{file_id}_{target_language}_full.wav")
                    await self._concatenate_audios(segment_paths, temp_concat_path)
                    # D√©placer vers la destination finale
                    output_path_wav = output_path.rsplit(".", 1)[0] + ".wav"
                    shutil.move(temp_concat_path, output_path_wav)
                    output_path = output_path_wav
                else:
                    raise RuntimeError("Aucun segment audio g√©n√©r√©")
            else:
                # Texte court: synth√®se directe
                await backend.synthesize(
                    text=text,
                    language=target_language,
                    speaker_audio_path=speaker_audio_path,
                    output_path=output_path,
                    conditionals=conditionals,
                    **kwargs
                )

            # Ajuster la vitesse de l'audio (ralentir de 10% par d√©faut)
            if AUDIO_SPEED_FACTOR != 1.0:
                output_path = await self._adjust_speed(output_path, AUDIO_SPEED_FACTOR)

            # Convertir le format si n√©cessaire
            if output_format != "wav":
                output_path = await self._convert_format(output_path, output_format)

            # Calculer la dur√©e et le temps de traitement
            duration_ms = await self._get_duration_ms(output_path)
            processing_time = int((time.time() - start_time) * 1000)

            # Encoder l'audio en base64 pour transmission au Gateway
            audio_data_base64, audio_mime_type = await self._encode_audio_base64(
                output_path,
                output_format
            )

            logger.info(
                f"[Synthesizer] ‚úÖ Synth√®se termin√©e: {output_filename} "
                f"(dur={duration_ms}ms, time={processing_time}ms, model={model.value})"
            )

            return UnifiedTTSResult(
                audio_path=output_path,
                audio_url=f"/outputs/audio/translated/{output_filename}",
                duration_ms=duration_ms,
                format=output_format,
                language=target_language,
                voice_cloned=bool(speaker_audio_path and os.path.exists(speaker_audio_path)),
                voice_quality=model_info.quality_score / 100.0,
                processing_time_ms=processing_time,
                text_length=len(text),
                model_used=model,
                model_info=model_info,
                audio_data_base64=audio_data_base64,
                audio_mime_type=audio_mime_type
            )

        except Exception as e:
            logger.error(f"[Synthesizer] ‚ùå Erreur synth√®se: {e}")
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"√âchec de la synth√®se TTS: {e}")

    async def _convert_format(self, input_path: str, target_format: str) -> str:
        """
        Convertit un fichier audio vers un autre format.

        Args:
            input_path: Chemin du fichier source
            target_format: Format de sortie (mp3, wav, etc.)

        Returns:
            Chemin du fichier converti
        """
        try:
            from pydub import AudioSegment

            output_path = input_path.rsplit(".", 1)[0] + f".{target_format}"

            # D√©tecter le format source automatiquement
            source_ext = input_path.rsplit(".", 1)[-1].lower() if "." in input_path else "wav"

            logger.debug(f"[Synthesizer] Conversion {source_ext} ‚Üí {target_format}")

            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                None,
                lambda: AudioSegment.from_file(input_path, format=source_ext).export(
                    output_path,
                    format=target_format
                )
            )

            # Supprimer le fichier source si diff√©rent
            if input_path != output_path and os.path.exists(input_path):
                os.unlink(input_path)

            logger.debug(f"[Synthesizer] Conversion termin√©e: {output_path}")
            return output_path

        except Exception as e:
            logger.warning(f"[Synthesizer] Erreur conversion format: {e}")
            return input_path

    async def _get_duration_ms(self, audio_path: str) -> int:
        """
        R√©cup√®re la dur√©e d'un fichier audio en millisecondes.

        Args:
            audio_path: Chemin du fichier audio

        Returns:
            Dur√©e en millisecondes
        """
        try:
            import librosa
            loop = asyncio.get_event_loop()
            duration = await loop.run_in_executor(
                None,
                lambda: librosa.get_duration(path=audio_path)
            )
            return int(duration * 1000)
        except Exception as e:
            logger.warning(f"[Synthesizer] Erreur calcul dur√©e: {e}")
            return 0

    async def _adjust_speed(self, audio_path: str, speed_factor: float = AUDIO_SPEED_FACTOR) -> str:
        """
        Ajuste la vitesse de l'audio sans modifier le pitch.

        Utilise librosa time_stretch pour un time-stretching de qualit√©.

        Args:
            audio_path: Chemin du fichier audio
            speed_factor: Facteur de vitesse (0.9 = 10% plus lent, 1.1 = 10% plus rapide)

        Returns:
            Chemin du fichier modifi√© (m√™me fichier, √©cras√©)
        """
        if speed_factor == 1.0:
            return audio_path

        try:
            import librosa
            import soundfile as sf

            loop = asyncio.get_event_loop()

            def stretch_audio():
                # Charger l'audio
                y, sr = librosa.load(audio_path, sr=None)

                # Time-stretch: rate > 1 = plus rapide, rate < 1 = plus lent
                # Pour ralentir de 10%, on utilise rate=0.9
                y_stretched = librosa.effects.time_stretch(y, rate=speed_factor)

                # Sauvegarder (√©craser le fichier original)
                sf.write(audio_path, y_stretched, sr)

                return audio_path

            result = await loop.run_in_executor(None, stretch_audio)

            logger.info(
                f"[Synthesizer] üéöÔ∏è Vitesse ajust√©e: {speed_factor:.2f}x "
                f"({'ralenti' if speed_factor < 1 else 'acc√©l√©r√©'} de {abs(1-speed_factor)*100:.0f}%)"
            )

            return result

        except Exception as e:
            logger.warning(f"[Synthesizer] Erreur ajustement vitesse: {e}")
            return audio_path

    async def _encode_audio_base64(
        self,
        audio_path: str,
        audio_format: str
    ) -> tuple[Optional[str], Optional[str]]:
        """
        Encode un fichier audio en base64 pour transmission.

        Args:
            audio_path: Chemin du fichier audio
            audio_format: Format audio (mp3, wav, etc.)

        Returns:
            Tuple (audio_base64, mime_type)
        """
        try:
            import base64

            loop = asyncio.get_event_loop()

            def read_and_encode():
                with open(audio_path, 'rb') as f:
                    audio_bytes = f.read()
                return base64.b64encode(audio_bytes).decode('utf-8')

            audio_data_base64 = await loop.run_in_executor(None, read_and_encode)
            audio_mime_type = f"audio/{audio_format}"

            logger.debug(
                f"[Synthesizer] Audio encod√© en base64: "
                f"{len(audio_data_base64)} chars"
            )

            return audio_data_base64, audio_mime_type

        except Exception as e:
            logger.warning(f"[Synthesizer] Erreur encodage base64: {e}")
            return None, None


# Alias pour compatibilit√©
TTSResult = UnifiedTTSResult
