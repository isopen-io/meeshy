"""
Chatterbox TTS Backend
======================

Backend Chatterbox (Resemble AI) - MOD√àLE PAR D√âFAUT
Supporte le clonage vocal pour 23 langues.

INT√âGRATION: Ce backend utilise le ModelManager centralis√© pour:
- Gestion m√©moire unifi√©e avec √©viction LRU
- Statistiques globales sur les mod√®les Chatterbox charg√©s
- Pas de duplication de mod√®les entre sessions
"""

import os
import asyncio
import logging
import io
from pathlib import Path
from typing import Optional, Any, Tuple
from concurrent.futures import ThreadPoolExecutor

from ..base import BaseTTSBackend
from config.settings import get_settings
from services.voice_analyzer_service import VoiceAnalyzerService, VoiceCharacteristics
from ...model_manager import TTSBackend as TTSBackendEnum

logger = logging.getLogger(__name__)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# INITIALISATION EINOPS POUR COMPATIBILIT√â AVEC ThreadPoolExecutor
# einops doit "d√©couvrir" le backend torch dans le thread principal
# AVANT d'√™tre utilis√© dans un executor, sinon: "Tensor type unknown to einops"
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
try:
    import torch
    from einops import rearrange
    # Forcer einops √† enregistrer le backend torch avec une op√©ration factice
    _dummy_tensor = torch.randn(2, 3)
    _dummy_result = rearrange(_dummy_tensor, "a b -> b a")
    del _dummy_tensor, _dummy_result
    logger.debug("[CHATTERBOX] ‚úÖ einops backend torch initialis√©")
except ImportError:
    pass
except Exception as e:
    logger.warning(f"[CHATTERBOX] ‚ö†Ô∏è Initialisation einops: {e}")

_background_executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="tts_download")


class ChatterboxBackend(BaseTTSBackend):
    """Backend Chatterbox (Resemble AI) - MOD√àLE PAR D√âFAUT ET FALLBACK

    Supporte 2 modes:
    - Monolingual (ChatterboxTTS): Anglais uniquement, plus l√©ger
    - Multilingual (ChatterboxMultilingualTTS): 23 langues support√©es
    """

    # Langues support√©es par le mod√®le multilingue
    MULTILINGUAL_LANGUAGES = {
        'ar', 'da', 'de', 'el', 'en', 'es', 'fi', 'fr', 'he', 'hi',
        'it', 'ja', 'ko', 'ms', 'nl', 'no', 'pl', 'pt', 'ru', 'sv',
        'sw', 'tr', 'zh'
    }

    def __init__(self, device: str = "auto", turbo: bool = False):
        super().__init__()
        self.device = device
        self.turbo = turbo
        # NOTE: Les mod√®les sont maintenant g√©r√©s par le ModelManager centralis√©
        # au lieu d'attributs locaux. On garde les IDs pour les r√©cup√©rer.
        backend_name = TTSBackendEnum.CHATTERBOX_TURBO.value if turbo else TTSBackendEnum.CHATTERBOX.value
        self._model_id = f"tts_{backend_name}_mono"
        self._model_id_multi = f"tts_{backend_name}_multilingual"
        self._available = False
        self._available_multilingual = False
        self._initialized_multilingual = False
        self._settings = get_settings()
        self._models_path = Path(self._settings.huggingface_cache_path)

        # Verrou pour s√©rialiser les appels de synth√®se (ChatterBox n'est pas thread-safe)
        self._synthesis_lock = asyncio.Lock()

        try:
            from chatterbox.tts import ChatterboxTTS
            self._available = True
            logger.info(f"‚úÖ [TTS] Chatterbox {'Turbo' if turbo else ''} package disponible")
        except ImportError:
            logger.warning(f"‚ö†Ô∏è [TTS] Chatterbox {'Turbo' if turbo else ''} package non disponible")

        try:
            from chatterbox.mtl_tts import ChatterboxMultilingualTTS
            self._available_multilingual = True
            logger.info("‚úÖ [TTS] Chatterbox Multilingual (23 langues) disponible")
        except ImportError:
            logger.warning("‚ö†Ô∏è [TTS] Chatterbox Multilingual non disponible")

    @property
    def is_available(self) -> bool:
        return self._available or self._available_multilingual

    def is_model_downloaded(self) -> bool:
        """
        V√©rifie si le mod√®le Chatterbox est t√©l√©charg√©.

        PRIORIT√â MULTILINGUE: V√©rifie d'abord le mod√®le multilingual,
        puis fallback sur le monolingual.

        V√©rifie dans l'ordre:
        1. Le cache personnalis√© (models/huggingface/)
        2. Le cache global HuggingFace (~/.cache/huggingface/hub/)

        Note: Chatterbox utilise tokenizer.json au lieu de config.json
        """
        if not self._available and not self._available_multilingual:
            return False

        try:
            from huggingface_hub import try_to_load_from_cache

            # PRIORIT√â 1: V√©rifier le mod√®le CHATTERBOX (contient mono + multi)
            # NOTE: Le mod√®le multilingual et monolingual partagent le M√äME repo HuggingFace
            # ResembleAI/chatterbox contient les deux variantes (classes Python diff√©rentes)
            if self._available_multilingual or self._available:
                model_id = "ResembleAI/chatterbox-turbo" if self.turbo else "ResembleAI/chatterbox"
                check_file = "tokenizer.json"

                # 1a. Cache personnalis√©
                file_path = try_to_load_from_cache(
                    model_id,
                    check_file,
                    cache_dir=str(self._models_path)
                )
                if file_path is not None:
                    logger.debug(f"[TTS] Chatterbox trouv√© dans cache personnalis√©: {model_id}")
                    return True

                # 1b. Cache global
                file_path = try_to_load_from_cache(model_id, check_file)
                if file_path is not None:
                    logger.debug(f"[TTS] Chatterbox trouv√© dans cache global: {model_id}")
                    return True

            return False
        except Exception as e:
            logger.debug(f"[TTS] V√©rification cache Chatterbox: {e}")
            return False

    async def download_model(self) -> bool:
        """
        T√©l√©charge le mod√®le Chatterbox.

        PRIORIT√â MULTILINGUE: T√©l√©charge le mod√®le multilingual (23 langues) en priorit√©
        pour supporter une plateforme multilingue comme Meeshy.
        """
        if not self._available and not self._available_multilingual:
            return False

        self._downloading = True
        self._download_progress = 0.0

        try:
            from huggingface_hub import snapshot_download

            # T√©l√©charger ResembleAI/chatterbox qui contient MONO + MULTI
            # NOTE: Le m√™me repo contient les 2 variantes (classes Python diff√©rentes)
            model_id = "ResembleAI/chatterbox-turbo" if self.turbo else "ResembleAI/chatterbox"

            if self._available_multilingual:
                logger.info(f"[TTS] üåç T√©l√©chargement Chatterbox (avec support Multilingual 23 langues) vers {self._models_path}...")
                logger.info("[TTS] Langues support√©es via ChatterboxMultilingualTTS: ar, da, de, el, en, es, fi, fr, he, hi, it, ja, ko, ms, nl, no, pl, pt, ru, sv, sw, tr, zh")
            else:
                logger.info(f"[TTS] üì• T√©l√©chargement Chatterbox (ChatterboxTTS - anglais) vers {self._models_path}...")
                logger.warning("[TTS] ‚ö†Ô∏è Chatterbox Multilingual non disponible - support anglais uniquement")

            loop = asyncio.get_event_loop()

            def download():
                return snapshot_download(
                    repo_id=model_id,
                    cache_dir=str(self._models_path),
                    resume_download=True
                )

            await loop.run_in_executor(_background_executor, download)

            self._download_progress = 100.0
            logger.info(f"[TTS] ‚úÖ {model_id} t√©l√©charg√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[TTS] ‚ùå Erreur t√©l√©chargement Chatterbox: {e}")
            return False

        finally:
            self._downloading = False

    def _get_device(self):
        """D√©termine le device √† utiliser."""
        import torch
        if self.device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif torch.backends.mps.is_available():
                return "mps"
            else:
                return "cpu"
        return self.device

    async def initialize(self) -> bool:
        """
        Initialise le mod√®le Chatterbox.

        PRIORIT√â MULTILINGUE: Pour une plateforme multilingue comme Meeshy,
        charge le mod√®le multilingual (23 langues) par d√©faut si disponible.
        Fallback sur le monolingual (anglais uniquement) si √©chec.
        """
        # Si d√©j√† initialis√© (mono ou multi), retourner True
        if self._initialized or self._initialized_multilingual:
            return True

        # √âTAPE 1: Essayer de charger le mod√®le MULTILINGUAL en priorit√©
        if self._available_multilingual:
            logger.info("[TTS] üåç Tentative de chargement Chatterbox Multilingual (23 langues)...")
            success = await self.initialize_multilingual()
            if success:
                logger.info("[TTS] ‚úÖ Chatterbox Multilingual charg√© - support de 23 langues activ√©")
                self._initialized = True  # Marquer comme initialis√© aussi
                return True
            else:
                logger.warning("[TTS] ‚ö†Ô∏è √âchec chargement multilingual, fallback sur monolingual...")

        # √âTAPE 2: Fallback sur le mod√®le MONOLINGUAL (anglais uniquement)
        if self._initialized:
            return True

        # V√©rifier si d√©j√† dans le ModelManager
        if self._has_model(self._model_id):
            logger.debug(f"[TTS] Chatterbox mono r√©cup√©r√© depuis ModelManager")
            self._initialized = True
            return True

        if not self._available:
            return False

        try:
            from chatterbox.tts import ChatterboxTTS

            device = self._get_device()
            model_name = "Turbo" if self.turbo else ""
            logger.info(f"[TTS] üîÑ Chargement Chatterbox {model_name} (monolingual - anglais uniquement)...")

            loop = asyncio.get_event_loop()

            if self.turbo:
                model = await loop.run_in_executor(
                    None,
                    lambda: ChatterboxTTS.from_pretrained("ResembleAI/chatterbox-turbo", device=device)
                )
            else:
                model = await loop.run_in_executor(
                    None,
                    lambda: ChatterboxTTS.from_pretrained(device=device)
                )

            # Enregistrer dans le ModelManager centralis√©
            backend_name = TTSBackendEnum.CHATTERBOX_TURBO.value if self.turbo else TTSBackendEnum.CHATTERBOX.value
            self._register_model(
                model_id=self._model_id,
                model_object=model,
                backend=backend_name,
                priority=1  # Haute priorit√© - mod√®le principal
            )

            self._initialized = True
            logger.info(f"‚úÖ [TTS] Chatterbox {model_name} monolingual initialis√© sur {device}")
            logger.warning("[TTS] ‚ö†Ô∏è Support multilingue limit√© - seulement anglais disponible")
            return True

        except Exception as e:
            logger.error(f"‚ùå [TTS] Erreur initialisation Chatterbox: {e}")
            return False

    async def initialize_multilingual(self) -> bool:
        """Initialise le mod√®le multilingue (23 langues)."""
        if self._initialized_multilingual:
            return True

        # V√©rifier si d√©j√† dans le ModelManager
        if self._has_model(self._model_id_multi):
            logger.debug(f"[TTS] Chatterbox multilingue r√©cup√©r√© depuis ModelManager")
            self._initialized_multilingual = True
            return True

        if not self._available_multilingual:
            logger.warning("[TTS] Chatterbox Multilingual non disponible")
            return False

        try:
            from chatterbox.mtl_tts import ChatterboxMultilingualTTS
            import torch

            device = self._get_device()
            logger.info(f"[TTS] üîÑ Chargement Chatterbox Multilingual (23 langues)...")

            # Monkey patch torch.load pour g√©rer le mapping CUDA -> CPU/MPS
            original_torch_load = torch.load

            def patched_torch_load(*args, **kwargs):
                if 'map_location' not in kwargs:
                    kwargs['map_location'] = device
                if 'weights_only' not in kwargs:
                    kwargs['weights_only'] = False
                return original_torch_load(*args, **kwargs)

            torch.load = patched_torch_load

            try:
                loop = asyncio.get_event_loop()
                model_multilingual = await loop.run_in_executor(
                    None,
                    lambda: ChatterboxMultilingualTTS.from_pretrained(device=device)
                )
            finally:
                torch.load = original_torch_load

            # Enregistrer dans le ModelManager centralis√©
            backend_name = TTSBackendEnum.CHATTERBOX_TURBO.value if self.turbo else TTSBackendEnum.CHATTERBOX.value
            self._register_model(
                model_id=self._model_id_multi,
                model_object=model_multilingual,
                backend=backend_name,
                priority=1  # Haute priorit√© - mod√®le multilingue tr√®s utilis√©
            )

            self._initialized_multilingual = True
            logger.info(f"‚úÖ [TTS] Chatterbox Multilingual initialis√© sur {device} (via ModelManager)")
            return True

        except Exception as e:
            logger.error(f"‚ùå [TTS] Erreur initialisation Chatterbox Multilingual: {e}")
            import traceback
            traceback.print_exc()
            return False

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # PARAM√àTRES CHATTERBOX - VALEURS PAR D√âFAUT OFFICIELLES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # Bas√© sur chatterbox_voice_translation_test.py qui fonctionne correctement.
    # IMPORTANT: Ne pas surcharger avec des param√®tres non-standards (temperature,
    # repetition_penalty, min_p, top_p) car ils causent des troncatures audio.
    #
    # Pour les langues non-anglaises: cfg_weight=0.0 r√©duit le transfert d'accent
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    DEFAULT_PARAMS = {
        "exaggeration": 0.5,      # 0.0-1.0: Expressivit√© vocale (d√©faut officiel)
        "cfg_weight": 0.5,        # 0.0-1.0: Guidance du mod√®le (d√©faut officiel)
        # NOTE: Pour non-anglais, cfg_weight sera mis √† 0.0 automatiquement
    }

    # Mode TURBO pour synth√®se plus neutre/stable
    FAST_PARAMS = {
        "exaggeration": 0.3,      # Expressivit√© r√©duite pour stabilit√©
        "cfg_weight": 0.5,        # Guidance standard
    }

    async def synthesize(
        self,
        text: str,
        language: str,
        speaker_audio_path: Optional[str] = None,
        output_path: str = None,
        # Param√®tres de clonage vocal (seuls param√®tres officiels Chatterbox)
        exaggeration: Optional[float] = None,
        cfg_weight: Optional[float] = None,
        # Options
        auto_optimize_params: bool = True,
        voice_characteristics: Optional[VoiceCharacteristics] = None,
        # Conditionals Chatterbox pr√©-calcul√©s
        conditionals: Optional[Any] = None,
        # MODE RAPIDE
        fast_mode: bool = False,
        **kwargs  # Ignorer les param√®tres non-standards
    ) -> str:
        """
        Synth√®se vocale avec Chatterbox.

        IMPORTANT: Utilise UNIQUEMENT les param√®tres officiels Chatterbox:
        - exaggeration: Expressivit√© vocale (0.0-1.0, d√©faut 0.5)
        - cfg_weight: Guidance du mod√®le (0.0-1.0, d√©faut 0.5, 0.0 pour non-anglais)

        Les param√®tres non-standards (temperature, repetition_penalty, min_p, top_p)
        sont IGNOR√âS car ils causent des troncatures audio.
        """
        import torchaudio

        # Normaliser le code langue (ex: fr-FR -> fr)
        lang_code = language.split('-')[0].lower() if language else 'en'

        # D√©terminer si on utilise le mod√®le multilingue
        use_multilingual = (
            lang_code in self.MULTILINGUAL_LANGUAGES and
            self._available_multilingual
        )

        # S√©lectionner les param√®tres par d√©faut
        params_source = self.FAST_PARAMS if fast_mode else self.DEFAULT_PARAMS
        if fast_mode:
            logger.info("[TTS] ‚ö° MODE RAPIDE activ√©")

        # Appliquer les valeurs par d√©faut
        if exaggeration is None:
            exaggeration = params_source["exaggeration"]
        if cfg_weight is None:
            cfg_weight = params_source["cfg_weight"]

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # R√àGLE CRUCIALE: cfg_weight=0.0 pour les langues non-anglaises
        # Bas√© sur chatterbox_voice_translation_test.py qui fonctionne
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if lang_code != 'en':
            effective_cfg = 0.0  # R√©duit le transfert d'accent pour cross-langue
            logger.info(f"[TTS] Cross-language: cfg_weight=0.0 pour {lang_code} (r√©duit transfert accent)")
        else:
            effective_cfg = cfg_weight

        logger.info(
            f"[TTS] Params: lang={lang_code}, exaggeration={exaggeration:.2f}, cfg_weight={effective_cfg:.2f}"
        )

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # INITIALISATION DU MOD√àLE
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        model_mono = None
        model_multi = None

        if use_multilingual:
            if not self._initialized_multilingual:
                await self.initialize_multilingual()

            model_multi = self._get_model(self._model_id_multi)
            if not model_multi:
                logger.warning(f"[TTS] Multilingual non disponible, fallback sur monolingual pour {lang_code}")
                use_multilingual = False

        if not use_multilingual:
            if not self._initialized:
                await self.initialize()

            model_mono = self._get_model(self._model_id)
            if not model_mono:
                raise RuntimeError("Chatterbox non initialis√©")

        loop = asyncio.get_event_loop()

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # G√âN√âRATION AUDIO - PARAM√àTRES SIMPLES UNIQUEMENT
        # Comme dans chatterbox_voice_translation_test.py
        # VERROU: ChatterBox n'est pas thread-safe, s√©rialisation des appels
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        async with self._synthesis_lock:
            if use_multilingual:
                _model = model_multi
                _text = text
                _lang_code = lang_code
                _speaker = speaker_audio_path
                _exp = exaggeration
                _cfg = effective_cfg
                _conditionals = conditionals

                # Si des conditionals pr√©-calcul√©s sont fournis
                if _conditionals is not None:
                    logger.info("[CHATTERBOX] üé§ Utilisation des conditionals pr√©-calcul√©s")
                    _model.conds = _conditionals
                    wav = await loop.run_in_executor(
                        None,
                        lambda: _model.generate(
                            text=_text,
                            language_id=_lang_code,
                            exaggeration=_exp,
                            cfg_weight=_cfg
                        )
                    )
                elif speaker_audio_path and os.path.exists(speaker_audio_path):
                    wav = await loop.run_in_executor(
                        None,
                        lambda: _model.generate(
                            text=_text,
                            audio_prompt_path=_speaker,
                            language_id=_lang_code,
                            exaggeration=_exp,
                            cfg_weight=_cfg
                        )
                    )
                else:
                    wav = await loop.run_in_executor(
                        None,
                        lambda: _model.generate(
                            text=_text,
                            language_id=_lang_code,
                            exaggeration=_exp,
                            cfg_weight=_cfg
                        )
                    )

                sample_rate = model_multi.sr
                logger.debug(f"[TTS] Synth√®se multilingue: {lang_code}")
            else:
                _model = model_mono
                _text = text
                _speaker = speaker_audio_path
                _exp = exaggeration
                _cfg = effective_cfg
                _conditionals = conditionals

                if _conditionals is not None:
                    logger.info("[CHATTERBOX] üé§ Utilisation des conditionals pr√©-calcul√©s")
                    _model.conds = _conditionals
                    wav = await loop.run_in_executor(
                        None,
                        lambda: _model.generate(
                            _text,
                            exaggeration=_exp,
                            cfg_weight=_cfg
                        )
                    )
                elif speaker_audio_path and os.path.exists(speaker_audio_path):
                    wav = await loop.run_in_executor(
                        None,
                        lambda: _model.generate(
                            _text,
                            audio_prompt_path=_speaker,
                            exaggeration=_exp,
                            cfg_weight=_cfg
                        )
                    )
                else:
                    wav = await loop.run_in_executor(
                        None,
                        lambda: _model.generate(
                            _text,
                            exaggeration=_exp,
                            cfg_weight=_cfg
                        )
                    )

                sample_rate = model_mono.sr
                logger.debug(f"[TTS] Synth√®se monolingual: en")

            await loop.run_in_executor(
                None,
                lambda: torchaudio.save(output_path, wav, sample_rate)
            )

            return output_path

    async def _get_optimal_params(
        self,
        speaker_audio_path: str,
        target_language: str,
        voice_characteristics: Optional[VoiceCharacteristics] = None
    ) -> dict:
        """
        Calcule les param√®tres optimaux bas√©s sur l'analyse vocale.

        NOTE: Simplifi√© pour n'utiliser que exaggeration et cfg_weight (params officiels).
        """
        try:
            analyzer = VoiceAnalyzerService()
            await analyzer.initialize()

            if voice_characteristics is None:
                characteristics = await analyzer.analyze(speaker_audio_path)
            else:
                characteristics = voice_characteristics

            optimal = analyzer.get_optimal_clone_params(characteristics, target_language)

            logger.debug(
                f"[TTS] Analyse vocale: type={characteristics.voice_type}, "
                f"pitch={characteristics.pitch_mean:.1f}Hz"
            )

            # Retourner uniquement les param√®tres officiels
            return {
                "exaggeration": optimal.get("exaggeration", self.DEFAULT_PARAMS["exaggeration"]),
                "cfg_weight": optimal.get("cfg_weight", self.DEFAULT_PARAMS["cfg_weight"]),
            }

        except Exception as e:
            logger.warning(f"[TTS] Erreur auto-optimisation, utilisation valeurs par d√©faut: {e}")
            return {
                "exaggeration": self.DEFAULT_PARAMS["exaggeration"],
                "cfg_weight": self.DEFAULT_PARAMS["cfg_weight"],
            }

    async def prepare_voice_conditionals(
        self,
        audio_path: str,
        exaggeration: float = 0.5,
        serialize: bool = False
    ) -> Tuple[Optional[Any], Optional[bytes]]:
        """
        Pr√©pare les conditionals Chatterbox √† partir d'un fichier audio.

        Ces conditionals peuvent √™tre stock√©s et r√©utilis√©s pour √©viter
        de recalculer √† chaque synth√®se.

        Args:
            audio_path: Chemin vers l'audio de r√©f√©rence
            exaggeration: Niveau d'expressivit√© (0.0-1.0)
            serialize: Si True, retourne aussi les bytes s√©rialis√©s

        Returns:
            Tuple (Conditionals, bytes_s√©rialis√©s) ou (Conditionals, None)
        """
        if not self.is_initialized and not self._initialized_multilingual:
            logger.warning("[CHATTERBOX] Mod√®le non initialis√© pour pr√©parer conditionals")
            return None, None

        if not audio_path or not os.path.exists(audio_path):
            logger.warning(f"[CHATTERBOX] Audio non trouv√©: {audio_path}")
            return None, None

        try:
            # Prioriser le mod√®le multilingual s'il est disponible
            model = None
            if self._initialized_multilingual:
                model = self._get_model(self._model_id_multi)
            elif self._initialized:
                model = self._get_model(self._model_id)

            if not model:
                logger.warning("[CHATTERBOX] Aucun mod√®le disponible pour pr√©parer conditionals")
                return None, None

            loop = asyncio.get_event_loop()

            def _prepare():
                model.prepare_conditionals(audio_path, exaggeration=exaggeration)
                return model.conds

            conditionals = await loop.run_in_executor(None, _prepare)
            logger.info(f"[CHATTERBOX] ‚úÖ Conditionals pr√©par√©s depuis {audio_path}")

            # S√©rialiser si demand√©
            serialized = None
            if serialize and conditionals:
                serialized = await self.serialize_conditionals(conditionals)

            return conditionals, serialized

        except Exception as e:
            logger.error(f"[CHATTERBOX] ‚ùå Erreur pr√©paration conditionals: {e}")
            return None, None

    async def serialize_conditionals(self, conditionals) -> Optional[bytes]:
        """
        S√©rialise les conditionals Chatterbox en bytes pour stockage.

        Args:
            conditionals: Objet Conditionals Chatterbox

        Returns:
            Bytes s√©rialis√©s ou None si √©chec
        """
        if conditionals is None:
            return None

        try:
            import torch

            # Cr√©er un buffer en m√©moire
            buffer = io.BytesIO()

            # S√©rialiser avec torch.save (comme Conditionals.save())
            arg_dict = dict(
                t3=conditionals.t3.__dict__,
                gen=conditionals.gen
            )
            torch.save(arg_dict, buffer)

            # Retourner les bytes
            buffer.seek(0)
            serialized_bytes = buffer.read()

            logger.info(f"[CHATTERBOX] ‚úÖ Conditionals s√©rialis√©s ({len(serialized_bytes)} bytes)")
            return serialized_bytes

        except Exception as e:
            logger.error(f"[CHATTERBOX] ‚ùå Erreur s√©rialisation conditionals: {e}")
            import traceback
            traceback.print_exc()
            return None

    async def deserialize_conditionals(self, data: bytes, device: str = "cpu"):
        """
        D√©s√©rialise les conditionals Chatterbox depuis bytes.

        Args:
            data: Bytes s√©rialis√©s
            device: Device cible (cpu, cuda, mps)

        Returns:
            Objet Conditionals ou None si √©chec
        """
        if data is None or len(data) == 0:
            return None

        try:
            import torch
            from chatterbox.tts import Conditionals
            from chatterbox.models.t3.modules.cond_enc import T3Cond

            # Charger depuis le buffer
            buffer = io.BytesIO(data)
            map_location = torch.device(device)

            kwargs = torch.load(buffer, map_location=map_location, weights_only=True)
            conditionals = Conditionals(T3Cond(**kwargs['t3']), kwargs['gen'])

            # D√©placer vers le device appropri√©
            conditionals = conditionals.to(device)

            logger.info(f"[CHATTERBOX] ‚úÖ Conditionals d√©s√©rialis√©s ({len(data)} bytes)")
            return conditionals

        except Exception as e:
            logger.error(f"[CHATTERBOX] ‚ùå Erreur d√©s√©rialisation conditionals: {e}")
            import traceback
            traceback.print_exc()
            return None

    async def close(self):
        # NOTE: Les mod√®les sont g√©r√©s par le ModelManager centralis√©
        # Ils seront automatiquement √©vict√©s via LRU si m√©moire faible
        self._initialized = False
        self._initialized_multilingual = False
        logger.info("[TTS] Chatterbox ferm√© (mod√®les g√©r√©s par ModelManager)")
