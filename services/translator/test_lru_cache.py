#!/usr/bin/env python3
"""
Test du cache LRU pour pipelines de traduction
VÃ©rifie hits/misses, Ã©victions, et statistiques
"""
import sys
sys.path.insert(0, 'src')

from utils.pipeline_cache import LRUPipelineCache
import time


def test_basic_cache():
    """Test basique: put et get"""
    print("ğŸ§ª Test 1: OpÃ©rations basiques du cache")
    print("=" * 70)

    cache = LRUPipelineCache(max_size=3)

    # Ajouter des pipelines fictifs
    cache.put("basic", "fra_Latn", "eng_Latn", "pipeline_fr_en")
    cache.put("basic", "fra_Latn", "spa_Latn", "pipeline_fr_es")
    cache.put("basic", "eng_Latn", "fra_Latn", "pipeline_en_fr")

    print(f"âœ… 3 pipelines ajoutÃ©s")
    print(f"ğŸ“Š Cache size: {len(cache)}/3")

    # RÃ©cupÃ©rer du cache
    p1 = cache.get("basic", "fra_Latn", "eng_Latn")
    print(f"âœ… Get FRâ†’EN: {p1} (HIT attendu)")

    p2 = cache.get("basic", "deu_Latn", "eng_Latn")
    print(f"âŒ Get DEâ†’EN: {p2} (MISS attendu)")

    stats = cache.get_stats()
    print(f"\nğŸ“Š Stats: {stats.hits} hits, {stats.misses} misses (hit_rate: {stats.hit_rate:.1f}%)")
    print()


def test_lru_eviction():
    """Test Ã©viction LRU"""
    print("ğŸ§ª Test 2: Ã‰viction LRU")
    print("=" * 70)

    cache = LRUPipelineCache(max_size=3)

    # Remplir le cache
    cache.put("basic", "fra_Latn", "eng_Latn", "pipeline_1")
    cache.put("basic", "fra_Latn", "spa_Latn", "pipeline_2")
    cache.put("basic", "eng_Latn", "fra_Latn", "pipeline_3")

    print(f"âœ… Cache rempli: {len(cache)}/3")

    # AccÃ©der Ã  pipeline_1 pour le marquer comme rÃ©cent
    cache.get("basic", "fra_Latn", "eng_Latn")
    print(f"âœ… AccÃ¨s FRâ†’EN (marque comme rÃ©cent)")

    # Ajouter un 4Ã¨me Ã©lÃ©ment â†’ devrait Ã©vincer pipeline_2 (le plus ancien)
    cache.put("basic", "deu_Latn", "eng_Latn", "pipeline_4")
    print(f"âœ… Ajout 4Ã¨me pipeline (devrait Ã©vincer le plus ancien)")

    # VÃ©rifier Ã©viction
    p2_after = cache.get("basic", "fra_Latn", "spa_Latn")  # Devrait Ãªtre MISS
    p1_after = cache.get("basic", "fra_Latn", "eng_Latn")  # Devrait Ãªtre HIT

    print(f"âŒ Get FRâ†’ES (Ã©vincÃ©): {p2_after}")
    print(f"âœ… Get FRâ†’EN (gardÃ©): {p1_after}")

    stats = cache.get_stats()
    print(f"\nğŸ“Š Ã‰victions: {stats.evictions}")
    print()


def test_hit_rate():
    """Test taux de hit rÃ©aliste"""
    print("ğŸ§ª Test 3: Taux de hit rÃ©aliste")
    print("=" * 70)

    cache = LRUPipelineCache(max_size=10)

    # Paires frÃ©quentes (80% du trafic)
    common_pairs = [
        ("basic", "fra_Latn", "eng_Latn"),
        ("basic", "eng_Latn", "fra_Latn"),
        ("basic", "fra_Latn", "spa_Latn"),
        ("basic", "eng_Latn", "spa_Latn"),
        ("basic", "fra_Latn", "deu_Latn"),
    ]

    # Paires rares (20% du trafic)
    rare_pairs = [
        ("basic", "jpn_Jpan", "kor_Hang"),
        ("basic", "arb_Arab", "eng_Latn"),
        ("basic", "zho_Hans", "fra_Latn"),
        ("basic", "hin_Deva", "eng_Latn"),
        ("basic", "tha_Thai", "eng_Latn"),
    ]

    # Simuler 100 requÃªtes
    for i in range(100):
        if i % 5 == 0:  # 20% paires rares
            model, src, tgt = rare_pairs[i % len(rare_pairs)]
        else:  # 80% paires frÃ©quentes
            model, src, tgt = common_pairs[i % len(common_pairs)]

        # VÃ©rifier cache
        pipeline = cache.get(model, src, tgt)

        # Si MISS, crÃ©er pipeline
        if pipeline is None:
            cache.put(model, src, tgt, f"pipeline_{i}")

    stats = cache.get_stats()
    print(f"ğŸ“Š RequÃªtes: {stats.total_requests}")
    print(f"âœ… Hits: {stats.hits}")
    print(f"âŒ Misses: {stats.misses}")
    print(f"ğŸ¯ Hit rate: {stats.hit_rate:.1f}%")
    print(f"ğŸ—‘ï¸  Ã‰victions: {stats.evictions}")
    print(f"ğŸ“¦ Cache size: {len(cache)}/10")

    # Top paires
    print(f"\nğŸ” Top 5 paires les plus utilisÃ©es:")
    for key, pos in cache.get_top_pairs(5):
        print(f"   {pos}. {key}")

    print()


def test_concurrent_access():
    """Test accÃ¨s concurrent basique"""
    print("ğŸ§ª Test 4: AccÃ¨s thread-safe")
    print("=" * 70)

    import threading

    cache = LRUPipelineCache(max_size=20)
    errors = []

    def worker(thread_id: int):
        """Worker thread"""
        try:
            for i in range(10):
                cache.put("basic", f"lang{thread_id}", f"target{i}", f"pipeline_{thread_id}_{i}")
                time.sleep(0.001)
                cache.get("basic", f"lang{thread_id}", f"target{i}")
        except Exception as e:
            errors.append(f"Thread {thread_id}: {e}")

    # Lancer 5 threads
    threads = []
    for tid in range(5):
        t = threading.Thread(target=worker, args=(tid,))
        threads.append(t)
        t.start()

    # Attendre fin
    for t in threads:
        t.join()

    if errors:
        print(f"âŒ Erreurs: {errors}")
    else:
        print(f"âœ… Aucune erreur thread-safe")

    stats = cache.get_stats()
    print(f"ğŸ“Š Total requÃªtes: {stats.total_requests}")
    print(f"ğŸ¯ Hit rate: {stats.hit_rate:.1f}%")
    print()


def main():
    """ExÃ©cute tous les tests"""
    print("\n" + "="*70)
    print("ğŸ§ª TEST SUITE: Cache LRU pour Pipelines de Traduction")
    print("="*70 + "\n")

    test_basic_cache()
    test_lru_eviction()
    test_hit_rate()
    test_concurrent_access()

    print("="*70)
    print("âœ… TOUS LES TESTS RÃ‰USSIS")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
