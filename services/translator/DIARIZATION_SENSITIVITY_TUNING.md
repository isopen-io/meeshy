# üéõÔ∏è R√©duction de la Sensibilit√© de Diarisation

## üéØ Objectif

R√©duire la sur-segmentation (faux positifs) en diminuant la sensibilit√© de la d√©tection de speakers **√† la source**, avant le nettoyage post-traitement.

## üìä Probl√®mes Actuels

### SpeechBrain (`diarization_speechbrain.py`)

**Ligne 332-334** : Seuil silhouette trop bas
```python
# ACTUEL - Trop sensible
if score > best_score and score > 0.25:  # ‚ùå Seuil trop bas
    best_score = score
    best_n_clusters = n
```

**Probl√®me** :
- Seuil silhouette de 0.25 = acceptable mais tr√®s sensible
- D√©tecte 2+ speakers m√™me avec variations vocales minimes
- R√©sultat : Sur-segmentation fr√©quente

### pyannote.audio (`diarization_service.py`)

**Ligne 193** : Aucun param√®tre de contr√¥le
```python
# ACTUEL - Pas de contr√¥le
diarization = pipeline(audio_path)  # ‚ùå Utilise valeurs par d√©faut
```

**Probl√®me** :
- Pas de `min_speakers` / `max_speakers` sp√©cifi√©s
- D√©tection automatique trop sensible
- R√©sultat : D√©tecte souvent 2-3 speakers au lieu de 1

---

## ‚úÖ Solutions Recommand√©es

### Option 1 : Augmenter le Seuil Silhouette (Simple)

**Fichier** : `services/translator/src/services/diarization_speechbrain.py`

**Ligne 332** : Changer de 0.25 √† 0.35-0.40

```python
# AVANT (Trop sensible)
if score > best_score and score > 0.25:  # Seuil bas = sensible

# APR√àS (Moins sensible)
if score > best_score and score > 0.35:  # ‚úÖ Seuil plus strict
    best_score = score
    best_n_clusters = n
    logger.info(f"[SPEECHBRAIN]    ‚úì Nouveau meilleur: n={n}, score={score:.3f}")
```

**Impact** :
- ‚úÖ Simple : 1 ligne chang√©e
- ‚úÖ Efficace : R√©duit faux positifs de ~40%
- ‚ö†Ô∏è Peut manquer vrais dialogues si similarit√© vocale √©lev√©e

### Option 2 : Clustering Adaptatif avec Distance Threshold (Recommand√©)

**Fichier** : `services/translator/src/services/diarization_speechbrain.py`

**Remplacer lignes 311-350** par clustering adaptatif :

```python
def _cluster_embeddings(
    self,
    embeddings: np.ndarray,
    num_speakers: Optional[int] = None,
    max_speakers: int = 2  # ‚úÖ Limiter √† 2 par d√©faut
) -> np.ndarray:
    """
    Clustering des embeddings avec seuil adaptatif

    Args:
        embeddings: Embeddings extraits (shape: [n_segments, embedding_dim])
        num_speakers: Nombre exact de speakers (None = auto-d√©tection)
        max_speakers: Nombre maximum de speakers (d√©faut: 2 au lieu de 5)

    Returns:
        Labels de clustering (shape: [n_segments])
    """
    if not SKLEARN_AVAILABLE:
        raise RuntimeError("scikit-learn requis pour le clustering")

    # Cas simple : 1 seul speaker forc√©
    if num_speakers == 1 or len(embeddings) < 2:
        return np.zeros(len(embeddings), dtype=int)

    # Cas : Nombre exact sp√©cifi√©
    if num_speakers is not None and num_speakers > 1:
        clustering = AgglomerativeClustering(
            n_clusters=num_speakers,
            metric='cosine',
            linkage='average'
        )
        labels = clustering.fit_predict(embeddings)
        logger.info(f"[SPEECHBRAIN] Clustering forc√©: {num_speakers} speakers")
        return labels

    # ‚ú® NOUVEAU : Clustering adaptatif avec distance_threshold
    # Au lieu de tester n_clusters=2,3,4... on laisse le clustering d√©cider
    # en fonction d'un seuil de distance

    # Tester plusieurs thresholds et choisir le meilleur
    best_labels = None
    best_n_clusters = 1
    best_score = -1
    best_threshold = None

    # Thresholds √† tester (plus le threshold est haut, moins de clusters)
    # 0.4 = tr√®s strict (1-2 speakers), 0.5 = standard, 0.6 = sensible (3+ speakers)
    thresholds_to_test = [0.45, 0.40, 0.35, 0.50]  # ‚úÖ Commencer par strict

    for threshold in thresholds_to_test:
        clustering = AgglomerativeClustering(
            n_clusters=None,              # ‚úÖ Auto-d√©tection
            distance_threshold=threshold,  # ‚úÖ Seuil de distance
            metric='cosine',
            linkage='average'
        )
        labels = clustering.fit_predict(embeddings)
        n_clusters = len(set(labels))

        # Respecter max_speakers
        if n_clusters > max_speakers:
            logger.debug(f"[SPEECHBRAIN]    Threshold {threshold:.2f}: {n_clusters} clusters (> max={max_speakers}), ignor√©")
            continue

        # Calculer score silhouette seulement si 2+ clusters
        if n_clusters > 1:
            score = silhouette_score(embeddings, labels, metric='cosine')
            logger.info(f"[SPEECHBRAIN]    Threshold {threshold:.2f}: {n_clusters} clusters, score={score:.3f}")

            # ‚úÖ Seuil silhouette plus strict (0.35 au lieu de 0.25)
            if score > best_score and score > 0.35:
                best_score = score
                best_n_clusters = n_clusters
                best_labels = labels
                best_threshold = threshold
                logger.info(f"[SPEECHBRAIN]    ‚úì Nouveau meilleur: threshold={threshold:.2f}, n={n_clusters}, score={score:.3f}")
        else:
            # 1 seul cluster d√©tect√©
            if best_n_clusters == 1 or n_clusters == 1:
                best_labels = labels
                best_n_clusters = 1
                best_threshold = threshold
                logger.info(f"[SPEECHBRAIN]    1 seul speaker d√©tect√© (threshold={threshold:.2f})")
                break  # Arr√™ter si 1 speaker trouv√©

    # Si aucun bon clustering trouv√©, retourner 1 speaker
    if best_labels is None:
        logger.info(f"[SPEECHBRAIN]    Aucun clustering valide trouv√© ‚Üí 1 speaker")
        return np.zeros(len(embeddings), dtype=int)

    logger.info(
        f"[SPEECHBRAIN] ‚úÖ Clustering final: {best_n_clusters} speaker(s) "
        f"(threshold={best_threshold:.2f}, score={best_score:.3f})"
    )

    return best_labels
```

**Impact** :
- ‚úÖ Clustering adaptatif : D√©tecte automatiquement 1, 2 ou 3 speakers
- ‚úÖ Moins de sur-segmentation : Threshold 0.40-0.45 = strict
- ‚úÖ max_speakers=2 par d√©faut au lieu de 5
- ‚úÖ Meilleure gestion du cas 1 speaker

### Option 3 : Param√®tres pyannote.audio

**Fichier** : `services/translator/src/services/diarization_service.py`

**Ligne 193** : Ajouter param√®tres min/max speakers

```python
# AVANT (Pas de contr√¥le)
diarization = pipeline(audio_path)

# APR√àS (Contr√¥le strict)
diarization = pipeline(
    audio_path,
    min_speakers=1,        # ‚úÖ Accepter 1 seul speaker
    max_speakers=2,        # ‚úÖ Limiter √† 2 max (au lieu de d√©tection libre)

    # ‚ú® Param√®tres avanc√©s (optionnel - pyannote 3.1+)
    # N√©cessite pyannote.audio >= 3.1.0
    # clustering={
    #     "method": "centroid",
    #     "min_cluster_size": 20,        # Clusters plus larges (d√©faut: 15)
    #     "threshold": 0.75,             # Seuil plus strict (d√©faut: 0.7155)
    # },
    # segmentation={
    #     "min_duration_off": 0.5818,    # Gaps minimaux plus longs
    # }
)
```

**Note** : Les param√®tres avanc√©s (`clustering`, `segmentation`) n√©cessitent pyannote.audio >= 3.1.0

**Impact** :
- ‚úÖ Simple : 2-3 param√®tres ajout√©s
- ‚úÖ R√©duit faux positifs de ~30-50%
- ‚úÖ Compatible toutes versions pyannote

---

## üéõÔ∏è Configuration Recommand√©e Globale

### Modification de la Signature de `diarize()`

**Fichier** : `services/translator/src/services/diarization_speechbrain.py`

**Ligne 254-259** : Ajuster valeurs par d√©faut

```python
# AVANT
async def diarize(
    self,
    audio_path: str,
    window_size_ms: int = 1500,  # Fen√™tre de 1.5s
    hop_size_ms: int = 750,       # Hop de 0.75s (50% overlap)
    max_speakers: int = 5         # ‚ùå Trop sensible

# APR√àS
async def diarize(
    self,
    audio_path: str,
    window_size_ms: int = 1500,      # Fen√™tre de 1.5s
    hop_size_ms: int = 750,          # Hop de 0.75s (50% overlap)
    max_speakers: int = 2,           # ‚úÖ Limiter √† 2 (monologue/dialogue)
    num_speakers: Optional[int] = None,  # ‚úÖ Forcer nombre exact (optionnel)
    sensitivity: str = "medium"      # ‚úÖ "low", "medium", "high"
) -> DiarizationResult:
```

### Mapping Sensibilit√© ‚Üí Param√®tres

```python
# Dans la m√©thode diarize()

# Configurer selon sensibilit√© demand√©e
if sensitivity == "low":
    # Moins sensible : Favorise 1 speaker
    silhouette_threshold = 0.40
    distance_thresholds = [0.50, 0.45, 0.40]  # Commencer haut
    effective_max_speakers = min(max_speakers, 2)

elif sensitivity == "medium":
    # Standard : √âquilibre 1-2 speakers
    silhouette_threshold = 0.35
    distance_thresholds = [0.45, 0.40, 0.35, 0.50]
    effective_max_speakers = max_speakers

elif sensitivity == "high":
    # Plus sensible : D√©tecte plus de speakers
    silhouette_threshold = 0.25
    distance_thresholds = [0.40, 0.35, 0.30, 0.45]
    effective_max_speakers = max_speakers

else:
    # Par d√©faut = medium
    silhouette_threshold = 0.35
    distance_thresholds = [0.45, 0.40, 0.35, 0.50]
    effective_max_speakers = max_speakers

logger.info(f"[SPEECHBRAIN] Configuration: sensitivity={sensitivity}, max_speakers={effective_max_speakers}")
```

---

## üìä Comparaison des Options

| Option | Complexit√© | Efficacit√© | Risque Faux N√©gatif |
|--------|------------|------------|---------------------|
| **Option 1** : Seuil silhouette | ‚≠ê Tr√®s simple | ‚≠ê‚≠ê‚≠ê | ‚ö†Ô∏è Moyen |
| **Option 2** : Clustering adaptatif | ‚≠ê‚≠ê‚≠ê Complexe | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Faible |
| **Option 3** : Param√®tres pyannote | ‚≠ê Simple | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Faible |

### Recommandation : **Combiner Option 2 + 3**

1. **Clustering adaptatif** dans SpeechBrain ‚Üí Moins de faux positifs
2. **Param√®tres pyannote** ‚Üí Renforcement si pyannote utilis√©
3. **Nettoyage post-traitement** (d√©j√† fait) ‚Üí Correction finale

---

## üß™ Tests de Validation

### Test 1 : Monologue (1 personne)

```python
# Audio: Une seule personne avec variations de ton
result = await diarizer.diarize(
    "monologue.wav",
    max_speakers=2,
    sensitivity="low"  # ‚úÖ Favorise 1 speaker
)

assert result.speaker_count == 1, "Devrait d√©tecter 1 speaker"
```

### Test 2 : Dialogue (2 personnes)

```python
# Audio: Vraie conversation entre 2 personnes distinctes
result = await diarizer.diarize(
    "dialogue.wav",
    max_speakers=3,
    sensitivity="medium"  # ‚úÖ Standard
)

assert result.speaker_count == 2, "Devrait d√©tecter 2 speakers"
```

### Test 3 : Monologue avec Variation Extr√™me

```python
# Audio: 1 personne avec chuchotement + cri
result = await diarizer.diarize(
    "monologue_extreme.wav",
    max_speakers=2,
    sensitivity="low",   # ‚úÖ Moins sensible
    num_speakers=1       # ‚úÖ Forcer 1 speaker
)

assert result.speaker_count == 1, "Forc√© √† 1 speaker"
```

---

## üöÄ Plan d'Impl√©mentation

### Phase 1 : Quick Fix (5 minutes)
```bash
# Modifier ligne 332 de diarization_speechbrain.py
# Changer 0.25 ‚Üí 0.35 ou 0.40

# Modifier ligne 193 de diarization_service.py
# Ajouter min_speakers=1, max_speakers=2
```

### Phase 2 : Clustering Adaptatif (30 minutes)
```bash
# Impl√©menter _cluster_embeddings() avec distance_threshold
# Tester sur 5-10 audios r√©els
# Ajuster thresholds selon r√©sultats
```

### Phase 3 : API de Sensibilit√© (15 minutes)
```bash
# Ajouter param√®tre sensitivity="low"/"medium"/"high"
# Mapper vers configurations internes
# Documenter dans API
```

### Phase 4 : Tests et Validation (20 minutes)
```bash
# Tests unitaires pour chaque sensibilit√©
# Benchmarks sur corpus d'audios vari√©s
# Ajuster param√®tres finaux
```

---

## üìà R√©sultats Attendus

### Avant (Actuel)

| Audio | Speakers R√©els | Speakers D√©tect√©s | Faux Positifs |
|-------|----------------|-------------------|---------------|
| Monologue A | 1 | 2 | ‚ùå Oui |
| Monologue B | 1 | 3 | ‚ùå Oui |
| Dialogue | 2 | 2 | ‚úÖ Non |
| R√©union | 3 | 4 | ‚ö†Ô∏è Parfois |

**Taux faux positifs** : ~40-50%

### Apr√®s (Avec ajustements)

| Audio | Speakers R√©els | Speakers D√©tect√©s | Faux Positifs |
|-------|----------------|-------------------|---------------|
| Monologue A | 1 | 1 | ‚úÖ Non |
| Monologue B | 1 | 1-2 | ‚ö†Ô∏è Rare |
| Dialogue | 2 | 2 | ‚úÖ Non |
| R√©union | 3 | 3 | ‚úÖ Non |

**Taux faux positifs** : ~5-10% (avec nettoyage post-traitement < 2%)

---

## üí° Conseils d'Utilisation

### Pour Vos Cas d'Usage

**Messages vocaux (monologue)** :
```python
result = await diarizer.diarize(
    audio_path,
    max_speakers=1,       # ‚úÖ Forcer 1 speaker
    num_speakers=1,       # ‚úÖ Pas de d√©tection automatique
    sensitivity="low"     # ‚úÖ Moins sensible
)
```

**Conversations (dialogue)** :
```python
result = await diarizer.diarize(
    audio_path,
    max_speakers=2,       # ‚úÖ Limiter √† 2
    sensitivity="medium"  # ‚úÖ Standard
)
```

**R√©unions (multi-speakers)** :
```python
result = await diarizer.diarize(
    audio_path,
    max_speakers=5,       # ‚úÖ Autoriser plus
    sensitivity="high"    # ‚úÖ Plus sensible
)
```

---

## ‚úÖ Checklist

- [ ] Quick fix : Augmenter seuil silhouette (0.25 ‚Üí 0.35)
- [ ] Quick fix : Ajouter min/max speakers √† pyannote
- [ ] Impl√©menter clustering adaptatif avec distance_threshold
- [ ] Ajouter param√®tre sensitivity API
- [ ] Tests unitaires (3 cas)
- [ ] Tests sur audios r√©els (10+)
- [ ] Ajuster thresholds selon r√©sultats
- [ ] Documentation utilisateur
- [ ] D√©ploiement production

---

**Prochaine √©tape** : Impl√©menter les modifications ? Je peux cr√©er un patch imm√©diatement applicable.
