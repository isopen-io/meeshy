# Analyse Vocale des Speakers - Documentation

## üé§ Fonctionnalit√© Ajout√©e

Analyse automatique des caract√©ristiques vocales de chaque speaker d√©tect√© par la diarisation.

## üìä Caract√©ristiques Analys√©es

### 1. **Genre** (gender)
- `enfant` - Pitch > 250 Hz
- `femme` - Pitch 165-255 Hz
- `adolescent` - Pitch 140-165 Hz
- `homme` - Pitch 85-180 Hz

### 2. **Registre Vocal** (pitch_level)
- `tr√®s grave` - < 90 Hz
- `grave` - 90-120 Hz
- `medium` - 120-200 Hz
- `aigu` - 200-250 Hz
- `tr√®s aigu` - > 250 Hz

### 3. **Groupe d'√Çge** (age_group)
- `enfant` - Pitch > 250 Hz
- `adolescent` - Pitch 140-165 Hz
- `adulte` - Pitch 85-255 Hz
- `senior` - Pitch < 90 Hz

### 4. **Ton / Expressivit√©** (tone)
- `monotone` - Variance pitch < 20 Hz
- `expressif` - Variance pitch 20-40 Hz
- `tr√®s expressif` - Variance pitch > 40 Hz

### 5. **Rapidit√© de Parole** (speech_rate)
- `lent` - < 3 syllabes/seconde
- `normal` - 3-6 syllabes/seconde
- `rapide` - > 6 syllabes/seconde

## üî¨ M√©thode d'Analyse

### Extraction du Pitch (Fr√©quence Fondamentale)
```python
pitches, magnitudes = librosa.piptrack(
    y=speaker_audio,
    sr=sr,
    fmin=50,   # Hz minimum
    fmax=500   # Hz maximum
)
```

**Valeurs de r√©f√©rence:**
- Enfant: 250-400 Hz
- Femme adulte: 165-255 Hz
- Homme adulte: 85-180 Hz

### Analyse de la Rapidit√©
```python
# D√©tection d'onsets (attaques sonores)
onsets = librosa.onset.onset_detect(
    onset_envelope=onset_env,
    sr=sr,
    units='time'
)

syllables_per_second = len(onsets) / duration_s
```

**R√©f√©rence:** ~4-5 syllabes/sec = parole normale

### Analyse de l'Expressivit√©
```python
pitch_variance = np.std(valid_pitches)
```

La variance du pitch indique la variabilit√© de l'intonation:
- Faible variance ‚Üí ton monotone
- Haute variance ‚Üí ton expressif

## üìã Format des Logs

### Exemple de Sortie

```
================================================================================
[SPEECHBRAIN] üé≠ R√âSULTAT DIARISATION
[SPEECHBRAIN] Speakers d√©tect√©s: 2
[SPEECHBRAIN] Dur√©e totale: 16780ms
[SPEECHBRAIN] Speaker principal: s0
================================================================================
[SPEECHBRAIN] üé§ Analyse des caract√©ristiques vocales de s0...
[SPEECHBRAIN] üë§ s0 (PRINCIPAL): 9750ms (58.1%) | 11 segments
[SPEECHBRAIN]    ‚îú‚îÄ Voix: femme | Registre: aigu (215Hz) | √Çge: adulte
[SPEECHBRAIN]    ‚îî‚îÄ Ton: expressif | Rapidit√©: normal (4.3 syl/s)
[SPEECHBRAIN] üé§ Analyse des caract√©ristiques vocales de s1...
[SPEECHBRAIN] üë§ s1 (secondaire): 6750ms (40.2%) | 7 segments
[SPEECHBRAIN]    ‚îú‚îÄ Voix: homme | Registre: grave (105Hz) | √Çge: adulte
[SPEECHBRAIN]    ‚îî‚îÄ Ton: monotone | Rapidit√©: rapide (6.8 syl/s)
================================================================================
```

### Dans transcription_service.py

```
================================================================================
[DIARIZATION] üé≠ R√âSUM√â D√âTAILL√â DE LA DIARISATION
[DIARIZATION] Nombre d'interlocuteurs d√©tect√©s: 2
[DIARIZATION] M√©thode utilis√©e: speechbrain
[DIARIZATION] Dur√©e totale: 16780ms
[DIARIZATION] Interlocuteur principal: s0
================================================================================
[DIARIZATION] üë§ Speaker s0 (PRINCIPAL):
             ‚îú‚îÄ Temps de parole: 9750ms (58.1%)
             ‚îú‚îÄ Nombre de segments: 11
             ‚îú‚îÄ Langue(s) d√©tect√©e(s): fr
             ‚îú‚îÄ Voix: femme | Registre: aigu (215Hz) | √Çge: adulte
             ‚îú‚îÄ Ton: expressif | Rapidit√©: normal (4.3 syl/s)
             ‚îî‚îÄ Exemples de segments:
                [1] 7.2s-7.9s | lang=fr | "d'accord mais"
                [2] 7.9s-8.3s | lang=fr | "ensuite"
                [3] 8.3s-9.5s | lang=fr | "une fois que tu"
                ... et 8 autres segments

[DIARIZATION] üë§ Speaker s1 (secondaire):
             ‚îú‚îÄ Temps de parole: 6750ms (40.2%)
             ‚îú‚îÄ Nombre de segments: 7
             ‚îú‚îÄ Langue(s) d√©tect√©e(s): fr
             ‚îú‚îÄ Voix: homme | Registre: grave (105Hz) | √Çge: adulte
             ‚îú‚îÄ Ton: monotone | Rapidit√©: rapide (6.8 syl/s)
             ‚îî‚îÄ Exemples de segments:
                [1] 0.6s-1.5s | lang=fr | "l√† je suis"
                [2] 1.5s-2.1s | lang=fr | "chez ma petite"
                [3] 2.1s-2.5s | lang=fr | "soeur"
                ... et 4 autres segments
================================================================================
```

## üîß Impl√©mentation Technique

### Fichiers Modifi√©s

#### 1. `diarization_speechbrain.py`

**Nouvelle dataclass:**
```python
@dataclass
class VoiceCharacteristics:
    """Caract√©ristiques vocales d'un speaker"""
    gender: str
    pitch_level: str
    age_group: str
    tone: str
    speech_rate: str
    avg_pitch_hz: float
    pitch_variance: float
    syllables_per_second: float
```

**Nouvelle m√©thode:**
```python
def _analyze_voice_characteristics(
    self,
    audio_path: str,
    segments: List[SpeakerSegment]
) -> Optional[VoiceCharacteristics]:
    """Analyse les caract√©ristiques vocales d'un speaker."""
    # 1. Extraction du pitch via librosa.piptrack()
    # 2. D√©termination genre/registre/√¢ge
    # 3. Analyse expressivit√© (variance pitch)
    # 4. Analyse rapidit√© (onsets)
    # 5. Retourne VoiceCharacteristics
```

**Int√©gration:**
```python
# Lors de la cr√©ation des SpeakerInfo
voice_chars = self._analyze_voice_characteristics(
    audio_path=audio_path,
    segments=data['segments']
)

speakers.append(SpeakerInfo(
    ...
    voice_characteristics=voice_chars
))
```

#### 2. `transcription_service.py`

**Ajout dans les logs:**
```python
if hasattr(speaker, 'voice_characteristics') and speaker.voice_characteristics:
    vc = speaker.voice_characteristics
    logger.info(
        f"             ‚îú‚îÄ Voix: {vc.gender} | "
        f"Registre: {vc.pitch_level} ({vc.avg_pitch_hz:.0f}Hz) | "
        f"√Çge: {vc.age_group}"
    )
    logger.info(
        f"             ‚îú‚îÄ Ton: {vc.tone} | "
        f"Rapidit√©: {vc.speech_rate} ({vc.syllables_per_second:.1f} syl/s)"
    )
```

## üì¶ D√©pendances

### D√©j√† Install√©es
- ‚úÖ `librosa` - Analyse audio (pitch, onsets)
- ‚úÖ `numpy` - Calculs statistiques
- ‚úÖ `soundfile` - Lecture audio

### Pas de Nouvelle D√©pendance Requise
Toutes les biblioth√®ques n√©cessaires sont d√©j√† pr√©sentes dans le projet.

## üéØ Cas d'Usage

### 1. Debug et Monitoring
Permet de v√©rifier visuellement si la diarisation a correctement identifi√© les speakers:
- "femme/aigu" vs "homme/grave" ‚Üí Probablement 2 personnes diff√©rentes ‚úÖ
- "homme/grave" et "homme/grave" ‚Üí Peut-√™tre la m√™me personne ‚ùå

### 2. Am√©lioration Future du Clonage Vocal
Les caract√©ristiques peuvent servir √†:
- Choisir automatiquement un mod√®le TTS appropri√©
- Ajuster les param√®tres de synth√®se (pitch, vitesse)
- Cr√©er des profils vocaux plus pr√©cis

### 3. Analyse Qualit√©
Permet de d√©tecter:
- Enfants vs adultes (pitch tr√®s diff√©rent)
- Parole rapide (difficile √† transcrire)
- Ton monotone (lecture vs conversation)

## ‚ö° Performance

### Impact Minimal
- Analyse sur **10 premiers segments** uniquement (limitation volontaire)
- Calculs l√©gers (pitch + onsets)
- Temps ajout√©: **~100-200ms par speaker**

### Optimisation
Si performance critique, possibilit√© de:
- R√©duire √† 5 segments au lieu de 10
- Analyser en parall√®le (asyncio.gather)
- Mettre en cache les r√©sultats

## üß™ Validation

### Tester avec diff√©rents audios:

**Audio 1**: Homme seul ‚Üí Devrait d√©tecter "homme/grave"
**Audio 2**: Femme seule ‚Üí Devrait d√©tecter "femme/aigu ou medium"
**Audio 3**: Conversation homme-femme ‚Üí Devrait d√©tecter les 2 correctement
**Audio 4**: Enfant ‚Üí Devrait d√©tecter "enfant/tr√®s aigu"

## üîÆ Am√©liorations Futures

### Pr√©cision Accrue
- Utiliser un mod√®le ML pour classification de genre (au lieu des seuils fixes)
- Analyser le timbre vocal (MFCC features)
- D√©tecter les √©motions (col√®re, joie, tristesse)

### M√©tadonn√©es Enrichies
- Accent d√©tect√© (fran√ßais, canadien, belge...)
- Environnement sonore (calme, bruyant)
- Qualit√© du micro (professionnel, t√©l√©phone)

## ‚úÖ Checklist d'Int√©gration

- ‚úÖ Dataclass `VoiceCharacteristics` ajout√©e
- ‚úÖ M√©thode `_analyze_voice_characteristics()` impl√©ment√©e
- ‚úÖ Int√©gration dans `diarize()` pour chaque speaker
- ‚úÖ Logs enrichis dans `diarization_speechbrain.py`
- ‚úÖ Logs enrichis dans `transcription_service.py`
- ‚úÖ Pas de nouvelle d√©pendance requise
- ‚úÖ Performance acceptable (~100-200ms/speaker)
- ‚úÖ Documentation compl√®te

## üéâ R√©sultat

Les logs de diarisation affichent maintenant **des d√©tails riches sur chaque speaker**:
- Genre vocal (homme/femme/enfant/adolescent)
- Registre (grave/medium/aigu)
- √Çge approximatif
- Ton (monotone/expressif)
- Rapidit√© de parole (lent/normal/rapide)

Ces informations facilitent le **debug**, am√©liorent la **compr√©hension** du syst√®me, et ouvrent la voie √† des **optimisations futures** du clonage vocal!
