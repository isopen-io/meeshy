# IntÃ©gration de la Nouvelle Architecture de Traduction Globale

## ğŸ“‹ Vue d'ensemble

La nouvelle architecture de traduction globale a Ã©tÃ© **implÃ©mentÃ©e** dans `multi_speaker_synthesis.py`. Ce document explique comment l'intÃ©grer dans le pipeline de traduction audio.

## âœ… Fonctions ImplÃ©mentÃ©es

### 1. **Dataclasses ajoutÃ©es**

```python
@dataclass
class SpeakerText:
    """Texte complet d'un speaker avec positions des segments"""
    speaker_id: str
    full_text: str
    segment_positions: List[Tuple[int, int, int]]  # (segment_index, char_start, char_end)
    original_segments: List[Dict[str, Any]]

@dataclass
class SpeakerTranslation:
    """Traduction complÃ¨te d'un speaker"""
    speaker_id: str
    source_text: str
    translated_text: str
    segment_positions: List[Tuple[int, int, int]]

@dataclass
class SpeakerAudio:
    """Audio complet synthÃ©tisÃ© pour un speaker"""
    speaker_id: str
    audio_path: str
    duration_ms: int
    word_timestamps: List[Dict[str, Any]]  # Timestamps au niveau des mots (Whisper)
```

### 2. **Fonctions principales**

#### `group_segments_by_speaker(segments: List[Dict]) â†’ Dict[str, SpeakerText]`
Regroupe TOUS les segments par speaker en conservant les positions.

#### `translate_speakers_globally(speakers_text, source_lang, target_lang, translation_service) â†’ Dict[str, SpeakerTranslation]`
Traduit le texte COMPLET de chaque speaker (2 appels au lieu de 34).

#### `synthesize_speakers_globally(speaker_translations, speaker_voice_maps, target_lang, message_id) â†’ Dict[str, SpeakerAudio]`
SynthÃ©tise l'audio COMPLET de chaque speaker avec extraction des word timestamps via Whisper.

#### `slice_speaker_audio_by_segments(speaker_audio, speaker_translation, original_segments) â†’ List[SegmentSynthesisResult]`
Re-dÃ©coupe l'audio synthÃ©tisÃ© selon les timestamps originaux en utilisant les word timestamps.

#### `reassemble_final_audio(all_segment_results, output_path) â†’ Tuple[str, int]`
RÃ©assemble tous les segments dans l'ordre original avec les silences.

#### `synthesize_multi_speaker_global(...)` **[FONCTION ORCHESTRATRICE]**
Orchestre toutes les phases de la nouvelle architecture.

## ğŸ”Œ IntÃ©gration dans translator_engine.py

### Fichier Ã  modifier
`src/services/translation_ml/translator_engine.py`

### Localisation
Chercher la fonction qui appelle `multi_speaker_synthesizer.synthesize_multi_speaker()`

### Modification proposÃ©e

**AVANT (architecture segment-by-segment):**
```python
# SynthÃ¨se multi-speaker (ancienne mÃ©thode)
result = await multi_speaker_synthesizer.synthesize_multi_speaker(
    segments=transcription_segments,
    translated_segments=translated_segments,
    speaker_voice_maps=speaker_voice_maps,
    target_language=target_language,
    output_path=output_audio_path,
    message_id=message_id
)
```

**APRÃˆS (nouvelle architecture globale):**
```python
# SynthÃ¨se multi-speaker avec traduction globale (NOUVELLE ARCHITECTURE)
result = await multi_speaker_synthesizer.synthesize_multi_speaker_global(
    segments=transcription_segments,  # Segments originaux avec timing
    speaker_voice_maps=speaker_voice_maps,
    source_language=source_language,  # âš ï¸ Ajouter ce paramÃ¨tre
    target_language=target_language,
    translation_service=translation_service,  # âš ï¸ Passer le service de traduction
    output_path=output_audio_path,
    message_id=message_id
)
```

### ParamÃ¨tres requis

La nouvelle fonction a besoin de **2 paramÃ¨tres supplÃ©mentaires**:

1. **`source_language`**: Langue source (ex: "en", "fr", "es")
2. **`translation_service`**: Instance du service de traduction

Ces paramÃ¨tres sont nÃ©cessaires car la traduction est maintenant effectuÃ©e **Ã  l'intÃ©rieur** du pipeline de synthÃ¨se (au lieu d'Ãªtre faite en amont).

## ğŸ“¦ DÃ©pendances supplÃ©mentaires

### faster-whisper (word timestamps)

La nouvelle architecture utilise **faster-whisper** pour extraire les timestamps au niveau des mots.

```bash
pip install faster-whisper
```

### ModÃ¨le Whisper

Le modÃ¨le `base` sera tÃ©lÃ©chargÃ© automatiquement lors de la premiÃ¨re utilisation (~140MB).

## ğŸ¯ Flux de la nouvelle architecture

```
ENTRÃ‰E: segments originaux (avec speaker_id, timing)
    â†“
1. Regroupement par speaker
   34 segments â†’ 2 textes complets (s0, s1)
    â†“
2. Traduction globale
   2 appels API (au lieu de 34)
   Contexte complet prÃ©servÃ©
    â†“
3. SynthÃ¨se globale
   2 longues synthÃ¨ses TTS (au lieu de 34 courtes)
   Intonations naturelles
    â†“
4. Extraction word timestamps
   Whisper analyse l'audio synthÃ©tisÃ©
   Positions prÃ©cises de chaque mot
    â†“
5. Re-dÃ©coupage par segments
   Utilise word timestamps pour mapper
   chaque segment original â†’ position audio
    â†“
6. RÃ©assemblage final
   Trie par index original + ajoute silences
    â†“
SORTIE: audio final multi-speaker (identique Ã  l'approche segment-by-segment)
```

## âš¡ Performances attendues

| MÃ©trique | Avant | AprÃ¨s | Gain |
|----------|-------|-------|------|
| **Appels API traduction** | 34 | 2 | **94% â†“** |
| **Appels TTS** | 34 | 2 | **94% â†“** |
| **Temps traduction** | 6.8s | 0.4s | **16Ã— plus rapide** |
| **Temps synthÃ¨se** | 25s | 4s | **6Ã— plus rapide** |
| **Temps total** | ~31s | ~6.4s | **79% plus rapide** |

## ğŸ” Logs de debug

La nouvelle architecture gÃ©nÃ¨re des logs dÃ©taillÃ©s:

```
================================================================================
[MULTI_SPEAKER_SYNTH] ğŸš€ NOUVELLE ARCHITECTURE: TRADUCTION GLOBALE
[MULTI_SPEAKER_SYNTH] Segments: 34
[MULTI_SPEAKER_SYNTH] Speakers: 2
[MULTI_SPEAKER_SYNTH] Langue: en â†’ fr
================================================================================
[MULTI_SPEAKER_SYNTH] ğŸ“ PHASE 1: Regroupement par speaker
[MULTI_SPEAKER_SYNTH]   â€¢ s0: 22 segments â†’ 1245 caractÃ¨res
[MULTI_SPEAKER_SYNTH]   â€¢ s1: 12 segments â†’ 678 caractÃ¨res
[MULTI_SPEAKER_SYNTH] âœ… 34 segments â†’ 2 speakers
[MULTI_SPEAKER_SYNTH] ğŸŒ PHASE 2: Traduction globale
[MULTI_SPEAKER_SYNTH]   â€¢ s0: 1245 chars...
[MULTI_SPEAKER_SYNTH]   âœ… s0: 1245 â†’ 1398 chars
[MULTI_SPEAKER_SYNTH]   â€¢ s1: 678 chars...
[MULTI_SPEAKER_SYNTH]   âœ… s1: 678 â†’ 756 chars
[MULTI_SPEAKER_SYNTH] âœ… Traduction globale terminÃ©e: 2 speakers
[MULTI_SPEAKER_SYNTH] ğŸ™ï¸ PHASE 3: SynthÃ¨se globale
[MULTI_SPEAKER_SYNTH]   â€¢ s0: synthÃ¨se de 1398 chars...
[MULTI_SPEAKER_SYNTH]   âœ… s0: audio de 18500ms gÃ©nÃ©rÃ©
[MULTI_SPEAKER_SYNTH] ğŸ” Extraction word timestamps: /tmp/speaker_s0.wav
[MULTI_SPEAKER_SYNTH] âœ… 234 mots dÃ©tectÃ©s
...
[MULTI_SPEAKER_SYNTH] âœ‚ï¸ PHASE 5: Re-dÃ©coupage par segments
[MULTI_SPEAKER_SYNTH] âœ… Re-dÃ©coupage terminÃ©: 22 segments extraits
[MULTI_SPEAKER_SYNTH] ğŸ”— PHASE 6: RÃ©assemblage final
[MULTI_SPEAKER_SYNTH] Segments rÃ©ussis: 34/34
[MULTI_SPEAKER_SYNTH] âœ… RÃ©assemblage terminÃ©: /output/final.mp3 (durÃ©e: 25480ms)
================================================================================
[MULTI_SPEAKER_SYNTH] âœ… SYNTHÃˆSE GLOBALE TERMINÃ‰E
[MULTI_SPEAKER_SYNTH]    â”œâ”€ Temps total: 6420ms (6.4s)
[MULTI_SPEAKER_SYNTH]    â”œâ”€ DurÃ©e audio: 25480ms (25.5s)
[MULTI_SPEAKER_SYNTH]    â”œâ”€ Segments: 34
[MULTI_SPEAKER_SYNTH]    â””â”€ Fichier: /output/final.mp3
================================================================================
```

## ğŸ§ª Test de validation

Pour tester la nouvelle architecture:

```python
from services.audio_pipeline.multi_speaker_synthesis import create_multi_speaker_synthesizer
from services.translation_ml.translation_service import TranslationService

# CrÃ©er les services
multi_speaker_synth = create_multi_speaker_synthesizer(
    tts_service=tts_service,
    voice_clone_service=voice_clone_service,
    preserve_silences=True
)

translation_service = TranslationService()

# Appeler la nouvelle fonction
result = await multi_speaker_synth.synthesize_multi_speaker_global(
    segments=transcription_segments,
    speaker_voice_maps=speaker_voice_maps,
    source_language="en",
    target_language="fr",
    translation_service=translation_service,
    output_path="/tmp/test_output.mp3",
    message_id="test_123"
)

if result:
    audio_path, duration_ms, segment_results = result
    print(f"âœ… SuccÃ¨s: {audio_path} ({duration_ms}ms)")
    print(f"   Segments: {len(segment_results)}")
else:
    print("âŒ Ã‰chec")
```

## âš ï¸ Points d'attention

### 1. CompatibilitÃ© ascendante
L'ancienne fonction `synthesize_multi_speaker()` est **toujours disponible** en fallback.

### 2. Word timestamps
Le mapping texte â†’ audio utilise les word timestamps de Whisper. Si Whisper Ã©choue, les segments ne seront pas re-dÃ©coupÃ©s correctement.

### 3. DÃ©pendance faster-whisper
Assurez-vous que `faster-whisper` est installÃ©:
```bash
pip install faster-whisper
```

### 4. Translation service
Le `translation_service` doit avoir une mÃ©thode async `translate(text, source_language, target_language) â†’ str`

## ğŸ”„ Migration progressive

### Option 1: Basculer complÃ¨tement (recommandÃ©)
Remplacer tous les appels Ã  `synthesize_multi_speaker()` par `synthesize_multi_speaker_global()`

### Option 2: Feature flag
Ajouter un flag pour tester progressivement:

```python
USE_GLOBAL_TRANSLATION = os.getenv("USE_GLOBAL_TRANSLATION", "true").lower() == "true"

if USE_GLOBAL_TRANSLATION:
    result = await multi_speaker_synth.synthesize_multi_speaker_global(...)
else:
    result = await multi_speaker_synth.synthesize_multi_speaker(...)
```

## ğŸ“Š MÃ©triques Ã  surveiller

AprÃ¨s l'intÃ©gration, surveiller:

1. **Temps de traduction total** (devrait diminuer de ~79%)
2. **Nombre d'appels API** (devrait Ãªtre = nombre de speakers, pas de segments)
3. **QualitÃ© audio** (devrait Ãªtre identique ou meilleure)
4. **Synchronisation** (vÃ©rifier que les silences sont prÃ©servÃ©s)

## ğŸ‰ Prochaines Ã©tapes

1. âœ… **ImplÃ©menter** les fonctions (FAIT)
2. â³ **IntÃ©grer** dans translator_engine.py
3. â³ **Tester** avec un audio rÃ©el multi-speaker
4. â³ **DÃ©ployer** en production
5. â³ **Monitorer** les performances

## ğŸ’¡ Optimisations futures

- **Cache des word timestamps**: Sauvegarder les word timestamps pour Ã©viter de re-transcrire
- **Parallel speaker synthesis**: SynthÃ©tiser tous les speakers en parallÃ¨le (dÃ©jÃ  fait!)
- **Streaming**: Support du streaming pour rÃ©duire la latence perÃ§ue
- **Time-stretching**: Aligner parfaitement les durÃ©es synthÃ©tisÃ©es avec les durÃ©es originales

## ğŸ“š Fichiers modifiÃ©s

```
services/translator/
â”œâ”€â”€ src/services/audio_pipeline/
â”‚   â””â”€â”€ multi_speaker_synthesis.py  âœ… MODIFIÃ‰ (nouvelles fonctions ajoutÃ©es)
â”‚
â”œâ”€â”€ INTEGRATION_TRADUCTION_GLOBALE.md  âœ… CRÃ‰Ã‰ (ce document)
â””â”€â”€ NOUVELLE_ARCHITECTURE_TRADUCTION_GLOBALE.md  âœ… EXISTE (documentation complÃ¨te)
```

## ğŸ”— Documentation complÃ¨te

Pour plus de dÃ©tails sur l'architecture et les dÃ©cisions de design:
â†’ `NOUVELLE_ARCHITECTURE_TRADUCTION_GLOBALE.md`

Pour l'historique des problÃ¨mes rÃ©solus:
â†’ `ANALYSE_PIPELINE_AUDIO_MULTI_SPEAKER.md`
